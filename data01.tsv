user_id	user_name	follower	following	tweet	date	arxiv_url	arxiv_title	arxiv_abstract	arxiv_p_subject	arxiv_s_subject
imenurok	那須音トウ:????	"1,970"	670	@maguroIsland 確かこちら https://t.co/NMaZpURHeL	2019/6/25 23:13	https://arxiv.org/abs/1804.00891	Hyperspherical Variational Auto-Encoders	"The Variational Auto-Encoder (VAE) is one of the most used unsupervisedmachine learning models. But although the default choice of a Gaussiandistribution for both the prior and posterior represents a mathematicallyconvenient distribution often leading to competitive results, we show that thisparameterization fails to model data with a latent hyperspherical structure. Toaddress this issue we propose using a von Mises-Fisher (vMF) distributioninstead, leading to a hyperspherical latent space. Through a series ofexperiments we show how such a hyperspherical VAE, or $\mathcal{S}$-VAE, ismore suitable for capturing data with a hyperspherical latent structure, whileoutperforming a normal, $\mathcal{N}$-VAE, in low dimensions on other datatypes."	Machine Learning (stat.ML)	Machine Learning (cs.LG)
tSato_as	T. Sato	124	150	これ、near-MCh が sub-MCh と半々とかそれ以上に見えるのは、もっとWD density あげたりとか、transition density 変えると印象変わってくるのかな？ https://t.co/ArtnwwbvOL	2019/6/26 6:24	https://arxiv.org/abs/1906.09980	New Type Ia supernova Yields and the Manganese and Nickel Problems in the Milky Way and Dwarf Spheroidal Galaxies	"In our quest to identify the progenitors of Type Ia supernovae (SNe Ia), wefirst update the nucleosynthesis yields both for Chandrasekhar (Ch) and sub-Chmass white dwarfs (WDs), for a wide range of metallicity, with ourtwo-dimensional hydrodynamical code and the latest nuclear reaction rates. Wethen include the yields in our galactic chemical evolution code to predict theevolution of elemental abundances in the solar neighborhood and dwarfspheroidal (dSph) galaxies. In the observations of the solar neighborhoodstars, Mn shows an opposite trend to alpha elements, showing an increase towardhigher metallicities, which is very well reproduced by deflagration-detonationtransition of Ch-mass WDs, but never by double detonations of sub-Ch-mass WDsalone. The problem of Ch-mass SNe Ia was the Ni over-production at highmetallicities. However, we found that Ni yields of Ch-mass SNe Ia are muchlower with the solar-scaled initial composition than in previous works, whichkeeps the predicted Ni abundance within the observational scatter. From theevolutionary trends of elemental abundances in the solar neighborhood, weconclude that the contribution of sub-Ch-mass SNe Ia is up to 25%. In dSphgalaxies, however, the contribution of sub-Ch-mass SNe Ia seems to be higherthan in the solar neighborhood. In dSphs, sub-Ch-mass SNe Ia cause a decreaseof [(alpha, Cr, Mn, Ni)/Fe], while so-called SNe Iax can increase Mn and Niabundances if they are pure deflagrations. Future observations of dSph starswill provide more stringent constraints on the progenitor systems and explosionmechanism of SNe Ia."	High Energy Astrophysical Phenomena (astro-ph.HE)	Astrophysics of Galaxies (astro-ph.GA)
dakuton	Yuji Tokuda	325	210	GPUが数の暴力でとても真似できないけど、ハッシュタグを足がかりに未ラベルの動画データで行動認識するというのはなかなか興味深い。 Large-scale weakly-supervised pre-training for video action recognition https://t.co/XoSPpv6m4V	2019/6/26 9:50	https://arxiv.org/abs/1905.00561	Large-scale weakly-supervised pre-training for video action recognition	"Current fully-supervised video datasets consist of only a few hundredthousand videos and fewer than a thousand domain-specific labels. This hindersthe progress towards advanced video architectures. This paper presents anin-depth study of using large volumes of web videos for pre-training videomodels for the task of action recognition. Our primary empirical finding isthat pre-training at a very large scale (over 65 million videos), despite onnoisy social-media videos and hashtags, substantially improves thestate-of-the-art on three challenging public action recognition datasets.Further, we examine three questions in the construction of weakly-supervisedvideo action datasets. First, given that actions involve interactions withobjects, how should one construct a verb-object pre-training label space tobenefit transfer learning the most? Second, frame-based models perform quitewell on action recognition; is pre-training for good image features sufficientor is pre-training for spatio-temporal features valuable for optimal transferlearning? Finally, actions are generally less well-localized in long videos vs.short videos; since action labels are provided at a video level, how should onechoose video clips for best performance, given some fixed budget of number orminutes of videos?"	Computer Vision and Pattern Recognition (cs.CV)	
tripdancer0916	Kohei Ichikawa	"2,664"	"2,122"	またすごいものが出てきた。148ページの大作。  A free energy principle for a particular physics - Karl Friston https://t.co/0GlJZvgn2n	2019/6/26 10:49	https://arxiv.org/abs/1906.10184	A free energy principle for a particular physics	"This monograph attempts a theory of every 'thing' that can be distinguishedfrom other things in a statistical sense. The ensuing statisticalindependencies, mediated by Markov blankets, speak to a recursive compositionof ensembles (of things) at increasingly higher spatiotemporal scales. Thisdecomposition provides a description of small things; e.g., quantum mechanics -via the Schrodinger equation, ensembles of small things - via statisticalmechanics and related fluctuation theorems, through to big things - viaclassical mechanics. These descriptions are complemented with a Bayesianmechanics for autonomous or active things. Although this work provides aformulation of every thing, its main contribution is to examine theimplications of Markov blankets for self-organisation to nonequilibriumsteady-state. In brief, we recover an information geometry and accompanyingfree energy principle that allows one to interpret the internal states ofsomething as representing or making inferences about its external states. Theensuing Bayesian mechanics is compatible with quantum, statistical andclassical mechanics and may offer a formal description of lifelike particles."	Neurons and Cognition (q-bio.NC)	
Kenji_Sugisaki	杉﨑 研司 (Kenji Sugisaki)	360	127	Machine learning methods in quantum computing theory https://t.co/D0JrcYkzqL あとで読む	2019/6/26 12:14	https://arxiv.org/abs/1906.10175	Machine learning methods in quantum computing theory	"Classical machine learning theory and theory of quantum computations areamong of the most rapidly developing scientific areas in our days. In recentyears, researchers investigated if quantum computing can help to improveclassical machine learning algorithms. The quantum machine learning includeshybrid methods that involve both classical and quantum algorithms. Quantumapproaches can be used to analyze quantum states instead of classical data. Onother side, quantum algorithms can exponentially improve classical data sciencealgorithm. Here, we show basic ideas of quantum machine learning. We presentseveral new methods that combine classical machine learning algorithms andquantum computing methods. We demonstrate multiclass tree tensor networkalgorithm, and its approbation on IBM quantum processor. Also, we introduceneural networks approach to quantum tomography problem. Our tomography methodallows us to predict quantum state excluding noise influence. Suchclassical-quantum approach can be applied in various experiments to reveallatent dependence between input data and output measurement results."	Quantum Physics (quant-ph)	
yutakashino	Yuta Kashino	"9,885"	186	XLNet: Generalized Autoregressive Pretraining for Language Understanding https://t.co/smBZWVZx1R ほんとですね，512 TPU 2.5日だと，Cloud TPU v3は一つあたり$8/hだから，2654万円かかる…．もうNLPの研究も圧倒的な計算力で殴る時代になってますね… https://t.co/K55jMrXKlI	2019/6/26 12:20	https://arxiv.org/abs/1906.08237	XLNet: Generalized Autoregressive Pretraining for Language Understanding	"With the capability of modeling bidirectional contexts, denoisingautoencoding based pretraining like BERT achieves better performance thanpretraining approaches based on autoregressive language modeling. However,relying on corrupting the input with masks, BERT neglects dependency betweenthe masked positions and suffers from a pretrain-finetune discrepancy. In lightof these pros and cons, we propose XLNet, a generalized autoregressivepretraining method that (1) enables learning bidirectional contexts bymaximizing the expected likelihood over all permutations of the factorizationorder and (2) overcomes the limitations of BERT thanks to its autoregressiveformulation. Furthermore, XLNet integrates ideas from Transformer-XL, thestate-of-the-art autoregressive model, into pretraining. Empirically, XLNetoutperforms BERT on 20 tasks, often by a large margin, and achievesstate-of-the-art results on 18 tasks including question answering, naturallanguage inference, sentiment analysis, and document ranking."	Computation and Language (cs.CL)	Machine Learning (cs.LG)
tripdancer0916	Kohei Ichikawa	"2,664"	"2,122"	ネットワークが生み出す情報量とそれを人が受け取る時の効率性を情報理論の枠組みで定義した上で実際の情報伝達システム（文章や音楽など）のネットワークが高い情報量と効率性を達成していることを示した。 また階層性とモジュール性からそれが実現することも明らかにした。 https://t.co/0j2T50naRS https://t.co/zOj1j9uxL3	2019/6/26 12:20	https://arxiv.org/abs/1906.00926	Human information processing in complex networks	"Humans communicate using systems of interconnected stimuli or concepts --from language and music to literature and science -- yet it remains unclearhow, if at all, the structure of these networks supports the communication ofinformation. Although information theory provides tools to quantify theinformation produced by a system, traditional metrics do not account for theinefficient and biased ways that humans process this information. Here wedevelop an analytical framework to study the information generated by a systemas perceived by a human observer. We demonstrate experimentally that thisperceived information depends critically on a system's network topology.Applying our framework to several real networks, we find that they communicatea large amount of information (having high entropy) and do so efficiently(maintaining low divergence from human expectations). Moreover, we show thatsuch efficient communication arises in networks that are simultaneouslyheterogeneous, with high-degree hubs, and clustered, with tightly-connectedmodules -- the two defining features of hierarchical organization. Together,these results suggest that many real networks are constrained by the pressuresof information transmission, and that these pressures select for specificstructural features."	Physics and Society (physics.soc-ph)	Biological Physics (physics.bio-ph);Neurons and Cognition (q-bio.NC)
Kenji_Sugisaki	杉﨑 研司 (Kenji Sugisaki)	360	127	Beyond the swap test: optimal estimation of quantum state overlap https://t.co/5HYS7cdVCF まだ中身読んでないけど気になる論文。あとで読む。	2019/6/26 12:21	https://arxiv.org/abs/1906.10639	Beyond the swap test: optimal estimation of quantum state overlap	"We study the estimation of the overlap between two Haar-random pure quantumstates in a finite-dimensional Hilbert space, given $M$ and $N$ copies of them.We compute the statistics of the optimal measurement, which is a projectiononto permutation-invariant subspaces, and provide lower bounds for the meansquare error for both local and Bayesian estimation. In the former case, thebound is asymptotically saturable by a maximum likelihood estimator, whereas inthe latter we give a simple exact formula for the optimal value. Furthermore,we introduce two LOCC strategies, relying on the estimation of one or both thestates, and show that, although they are suboptimal, they outperform thecommonly-used swap test. In particular, the swap test is extremely inefficientfor small values of the overlap, which become exponentially more likely as thedimension increases. Finally, we show that the optimal measurement is lessinvasive than the swap test and study the robustness to depolarizing noise forqubit states."	Quantum Physics (quant-ph)	
autumn_good_35	Autumn Good	"1,755"	271	"奇虎360による論文。  『While theprimitive (fully homomorphic encryption) itself is secure, protocols and applications can easily be completelyinsecure.』  Danger of using fully homomorphic encryption: A look at Microsoft SEAL [PDF] https://t.co/2l6ykSt5BZ https://t.co/71rIgA0ygw"	2019/6/26 12:31	https://arxiv.org/abs/1906.07127	Danger of using fully homomorphic encryption: A look at Microsoft SEAL	"Fully homomorphic encryption is a promising crypto primitive to encrypt yourdata while allowing others to compute on the encrypted data. But there are manywell-known problems with fully homomorphic encryption such as CCA security andcircuit privacy problem. Despite these problems, there are still many companiesare currently using or preparing to use fully homomorphic encryption to builddata security applications. It seems that the full homomorphic encryption isvery close to practicality and these problems can be easily mitigated inimplementation. Although the those problems are well known in theory, there isno public discussion of their actual impact on real application. Our researchshows that there are many security pitfalls in fully homomorphic encryptionfrom the perspective of practical application. The security problems of a fullyhomomorphic encryption in a real application is more severe than imagined. Inthis paper, we will take Microsoft SEAL as an examples to introduce thesecurity pitfalls of fully homomorphic encryption from the perspective ofimplementation and practical application"	Cryptography and Security (cs.CR)	
U1KURI	くりりん（Yuichi KRHR）	70	148	甘利先生  Jacot et al. Neural Tangent Kernel  関数空間での解析 https://t.co/2LcMX5aeLz  カーネル学習、ガウシアンプロセスに出来る。 ※ 距離空間のパラメータ数が無限である、という条件  どんな局所解も、ほぼ最適解になる！  →　実は学習は線形問題！！！   #wba_sympo4	2019/6/26 14:02	https://arxiv.org/abs/1806.07572	Neural Tangent Kernel: Convergence and Generalization in Neural Networks	"At initialization, artificial neural networks (ANNs) are equivalent toGaussian processes in the infinite-width limit, thus connecting them to kernelmethods. We prove that the evolution of an ANN during training can also bedescribed by a kernel: during gradient descent on the parameters of an ANN, thenetwork function $f_\theta$ (which maps input vectors to output vectors)follows the kernel gradient of the functional cost (which is convex, incontrast to the parameter cost) w.r.t. a new kernel: the Neural Tangent Kernel(NTK). This kernel is central to describe the generalization features of ANNs.While the NTK is random at initialization and varies during training, in theinfinite-width limit it converges to an explicit limiting kernel and it staysconstant during training. This makes it possible to study the training of ANNsin function space instead of parameter space. Convergence of the training canthen be related to the positive-definiteness of the limiting NTK. We prove thepositive-definiteness of the limiting NTK when the data is supported on thesphere and the non-linearity is non-polynomial.We then focus on the setting of least-squares regression and show that in theinfinite-width limit, the network function $f_\theta$ follows a lineardifferential equation during training. The convergence is fastest along thelargest kernel principal components of the input data with respect to the NTK,hence suggesting a theoretical motivation for early stopping.Finally we study the NTK numerically, observe its behavior for wide networks,and compare it to the infinite-width limit."	Machine Learning (cs.LG)	Neural and Evolutionary Computing (cs.NE);Probability (math.PR);Machine Learning (stat.ML)
shion_honda	Shion Honda	"1,234"	242	"Deep learning for molecular design [Elton+, 2019, Mol. Syst. Des. Eng.] 過去2年間のDLによる分子設計手法に関する論文45本をまとめたサーベイ。RNN、GANなど機械学習一般の話が手厚いが、最後に強化学習の報酬設計などドメイン固有の議論もある。 https://t.co/RruXfCPFPF #NowReading https://t.co/QY3Cpv0Ug7"	2019/6/26 15:29	https://arxiv.org/abs/1903.04388	Deep learning for molecular design - a review of the state of the art	"In the space of only a few years, deep generative modeling has revolutionizedhow we think of artificial creativity, yielding autonomous systems whichproduce original images, music, and text. Inspired by these successes,researchers are now applying deep generative modeling techniques to thegeneration and optimization of molecules - in our review we found 45 papers onthe subject published in the past two years. These works point to a futurewhere such systems will be used to generate lead molecules, greatly reducingresources spent downstream synthesizing and characterizing bad leads in thelab. In this review we survey the increasingly complex landscape of models andrepresentation schemes that have been proposed. The four classes of techniqueswe describe are recursive neural networks, autoencoders, generative adversarialnetworks, and reinforcement learning. After first discussing some of themathematical fundamentals of each technique, we draw high level connections andcomparisons with other techniques and expose the pros and cons of each. Severalimportant high level themes emerge as a result of this work, including theshift away from the SMILES string representation of molecules towards moresophisticated representations such as graph grammars and 3D representations,the importance of reward function design, the need for better standards forbenchmarking and testing, and the benefits of adversarial training andreinforcement learning over maximum likelihood based training."	Machine Learning (cs.LG)	Chemical Physics (physics.chem-ph);Machine Learning (stat.ML)
TomiyaAkio	3刷出ます「ディープラーニングと物理学」 A.Tomiya	"1,262"	504	個人的には、https://t.co/Ltq63t7B3K の続きの話がおもしろかったな	2019/6/26 17:32	https://arxiv.org/abs/1811.12688	Exploring the phase diagram of finite density QCD at low temperature by the complex Langevin method	"Monte Carlo studies of QCD at finite density suffer from the sign problem,which becomes easily uncontrollable as the chemical potential $\mu$ isincreased even for a moderate lattice size. In this work we make an attempt toapproach the high density low temperature region by the complex Langevin method(CLM) using four-flavor staggered fermions with reasonably small quark mass ona $8^3 \times 16$ lattice. Unlike the previous work on a $4^3 \times 8$lattice, the criterion for correct convergence is satisfied within a wide rangeof $\mu$ without using the deformation technique. In particular, the baryonnumber density exhibits a plateau behavior consistent with the formation ofeight baryons, and it starts to grow gradually at some $\mu$."	High Energy Physics - Lattice (hep-lat)	High Energy Physics - Theory (hep-th)
overleo	overleo	189	0	BERTを超えたXLNetの紹介 - akihiro_f - Medium: 概要https://t.co/khdHR0GZWP XLNetは2019/6/19に、”XLNet: Generalized Autoregressive Pretraining for Language Understanding”と題してArxivに投稿された論文です。一言(?)でいうと… https://t.co/p03Aej2nmw [ml]	2019/6/26 17:35	https://arxiv.org/abs/1906.08237	XLNet: Generalized Autoregressive Pretraining for Language Understanding	"With the capability of modeling bidirectional contexts, denoisingautoencoding based pretraining like BERT achieves better performance thanpretraining approaches based on autoregressive language modeling. However,relying on corrupting the input with masks, BERT neglects dependency betweenthe masked positions and suffers from a pretrain-finetune discrepancy. In lightof these pros and cons, we propose XLNet, a generalized autoregressivepretraining method that (1) enables learning bidirectional contexts bymaximizing the expected likelihood over all permutations of the factorizationorder and (2) overcomes the limitations of BERT thanks to its autoregressiveformulation. Furthermore, XLNet integrates ideas from Transformer-XL, thestate-of-the-art autoregressive model, into pretraining. Empirically, XLNetoutperforms BERT on 20 tasks, often by a large margin, and achievesstate-of-the-art results on 18 tasks including question answering, naturallanguage inference, sentiment analysis, and document ranking."	Computation and Language (cs.CL)	Machine Learning (cs.LG)
m3yrin	typo	127	276	"宝くじ券仮説、NNの中で初期値と相性?の良い有効な構造のみが生き残っていく話(らしい)  |The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks | https://t.co/FQOgC7cDml"	2019/6/26 17:37	https://arxiv.org/abs/1803.03635	"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"	"Neural network pruning techniques can reduce the parameter counts of trainednetworks by over 90%, decreasing storage requirements and improvingcomputational performance of inference without compromising accuracy. However,contemporary experience is that the sparse architectures produced by pruningare difficult to train from the start, which would similarly improve trainingperformance.We find that a standard pruning technique naturally uncovers subnetworkswhose initializations made them capable of training effectively. Based on theseresults, we articulate the ""lottery ticket hypothesis:"" dense,randomly-initialized, feed-forward networks contain subnetworks (""winningtickets"") that - when trained in isolation - reach test accuracy comparable tothe original network in a similar number of iterations. The winning tickets wefind have won the initialization lottery: their connections have initialweights that make training particularly effective.We present an algorithm to identify winning tickets and a series ofexperiments that support the lottery ticket hypothesis and the importance ofthese fortuitous initializations. We consistently find winning tickets that areless than 10-20% of the size of several fully-connected and convolutionalfeed-forward architectures for MNIST and CIFAR10. Above this size, the winningtickets that we find learn faster than the original network and reach highertest accuracy."	Machine Learning (cs.LG)	Artificial Intelligence (cs.AI);Neural and Evolutionary Computing (cs.NE)
qard_t	T-QARD channel	516	0	https://t.co/3IVdpQF3wQ  展望としては2Dもいけるぞ！とのこと。 https://t.co/Xs7ihnvjAy	2019/6/26 18:47	https://arxiv.org/abs/1905.05721	Generation and manipulation of Schr?dinger cat states in Rydberg atom arrays	"Quantum entanglement involving coherent superpositions of macroscopicallydistinct states is among the most striking features of quantum theory, but itsrealization is challenging, since such states are extremely fragile. Using aprogrammable quantum simulator based on neutral atom arrays with interactionsmediated by Rydberg states, we demonstrate the deterministic generation of'Schr?dinger cat' states of the Greenberger-Horne-Zeilinger (GHZ) type withup to 20 qubits. Our approach is based on engineering the energy spectrum andusing optimal control of the many-body system. We further demonstrateentanglement manipulation by using GHZ states to distribute entanglement todistant sites in the array, establishing important ingredients for quantuminformation processing and quantum metrology."	Quantum Physics (quant-ph)	Quantum Gases (cond-mat.quant-gas);Atomic Physics (physics.atom-ph)
SeURa_Nue	せゆーら / Se-U-Ra	"3,667"	420	@takumiwish https://t.co/IkpmVNd6Uu  この辺じゃないですかね(推察)	2019/6/26 20:06	https://arxiv.org/abs/1708.05031	Neural Collaborative Filtering	"In recent years, deep neural networks have yielded immense success on speechrecognition, computer vision and natural language processing. However, theexploration of deep neural networks on recommender systems has receivedrelatively less scrutiny. In this work, we strive to develop techniques basedon neural networks to tackle the key problem in recommendation -- collaborativefiltering -- on the basis of implicit feedback. Although some recent work hasemployed deep learning for recommendation, they primarily used it to modelauxiliary information, such as textual descriptions of items and acousticfeatures of musics. When it comes to model the key factor in collaborativefiltering -- the interaction between user and item features, they stillresorted to matrix factorization and applied an inner product on the latentfeatures of users and items. By replacing the inner product with a neuralarchitecture that can learn an arbitrary function from data, we present ageneral framework named NCF, short for Neural network-based CollaborativeFiltering. NCF is generic and can express and generalize matrix factorizationunder its framework. To supercharge NCF modelling with non-linearities, wepropose to leverage a multi-layer perceptron to learn the user-item interactionfunction. Extensive experiments on two real-world datasets show significantimprovements of our proposed NCF framework over the state-of-the-art methods.Empirical evidence shows that using deeper layers of neural networks offersbetter recommendation performance."	Information Retrieval (cs.IR)	
yu__ya4	Yuya Matsumura	"1,642"	"1,037"	論文 https://t.co/pR58iCGQvA  サービスの性質上，ユーザ間の取引が A-&gt;B-&gt;C-&gt;A ってふうに循環してたら怪しいって仮説おいてそれを特徴量にしてるの面白い（最終，そこまで効いてなさげやったけど）。 こういうドメイン知識あるからこそのってやつ好き。	2019/6/26 20:28	https://arxiv.org/abs/1906.07974	Detecting problematic transactions in a consumer-to-consumer e-commerce network	"Providers of online marketplaces are constantly combatting againstproblematic transactions, such as selling illegal items and posting fictiveitems, exercised by some of their users. A typical approach to detect fraudactivity has been to analyze registered user profiles, user's behavior, andtexts attached to individual transactions and the user. However, thistraditional approach may be limited because malicious users can easily concealtheir information. Given this background, network indices have been exploitedfor detecting frauds in various online transaction platforms. In the presentstudy, we analyzed networks of users of an online consumer-to-consumermarketplace in which a seller and the corresponding buyer of a transaction areconnected by a directed edge. We constructed egocentric networks of each ofseveral hundreds of fraudulent users and those of a similar number of normalusers. We calculated eight local network indices based on up to connectivitybetween the neighbors of the focal node. Based on the present descriptiveanalysis of these network indices, we fed twelve features that we constructedfrom the eight network indices to random forest classifiers with the aim ofdistinguishing between normal users and fraudulent users engaged in each one ofthe four types of problematic transactions. We found that the classifieraccurately distinguished the fraudulent users from normal users and that theclassification performance did not depend on the type of problematictransaction."	Social and Information Networks (cs.SI)	
Nextremer_nb_o	nb.o	51	113	もとの論文とおなじことがかいてあるってことか。  https://t.co/2ufSUdfWLS	2019/6/26 21:53	https://arxiv.org/abs/1712.07136	Low-Shot Learning with Imprinted Weights	"Human vision is able to immediately recognize novel visual categories afterseeing just one or a few training examples. We describe how to add a similarcapability to ConvNet classifiers by directly setting the final layer weightsfrom novel training examples during low-shot learning. We call this processweight imprinting as it directly sets weights for a new category based on anappropriately scaled copy of the embedding layer activations for that trainingexample. The imprinting process provides a valuable complement to training withstochastic gradient descent, as it provides immediate good classificationperformance and an initialization for any further fine-tuning in the future. Weshow how this imprinting process is related to proxy-based embeddings. However,it differs in that only a single imprinted weight vector is learned for eachnovel category, rather than relying on a nearest-neighbor distance to traininginstances as typically used with embedding methods. Our experiments show thatusing averaging of imprinted weights provides better generalization than usingnearest-neighbor instance embeddings."	Computer Vision and Pattern Recognition (cs.CV)	
hir_kurashige	Hiroki Kurashige	225	80	Fristonの例の論文(というかモノグラフ)、最終的には自分の研究に関わるだろうし、読んで(解読して)みようと思う。その上でせっかくだからこじんまりとした報告会でも開くか。これは輪読には向かないから、私が解読して、私が説明して、他の人がそれにツッコミ入れる会。  https://t.co/CMQnxJUf2o	2019/6/26 22:05	https://arxiv.org/abs/1906.10184	A free energy principle for a particular physics	"This monograph attempts a theory of every 'thing' that can be distinguishedfrom other things in a statistical sense. The ensuing statisticalindependencies, mediated by Markov blankets, speak to a recursive compositionof ensembles (of things) at increasingly higher spatiotemporal scales. Thisdecomposition provides a description of small things; e.g., quantum mechanics -via the Schrodinger equation, ensembles of small things - via statisticalmechanics and related fluctuation theorems, through to big things - viaclassical mechanics. These descriptions are complemented with a Bayesianmechanics for autonomous or active things. Although this work provides aformulation of every thing, its main contribution is to examine theimplications of Markov blankets for self-organisation to nonequilibriumsteady-state. In brief, we recover an information geometry and accompanyingfree energy principle that allows one to interpret the internal states ofsomething as representing or making inferences about its external states. Theensuing Bayesian mechanics is compatible with quantum, statistical andclassical mechanics and may offer a formal description of lifelike particles."	Neurons and Cognition (q-bio.NC)	
re_hako_moon	はこつき＠VR	43	49	https://t.co/Vpv23Ke83J 単眼カメラ画像から物体の三次元メッシュを再構成する。面と線によるSkeltonを一度構成し、3DCNNによって高解像度なVolume表現を得る。さらにMarching Cubesでメッシュに変換し、GCNNでRefinementしてきれいなメッシュを出力。	2019/6/26 22:16	https://arxiv.org/abs/1903.04704	A Skeleton-bridged Deep Learning Approach for Generating Meshes of Complex Topologies from Single RGB Images	"This paper focuses on the challenging task of learning 3D object surfacereconstructions from single RGB images. Existing methods achieve varyingdegrees of success by using different geometric representations. However, theyall have their own drawbacks, and cannot well reconstruct those surfaces ofcomplex topologies. To this end, we propose in this paper a skeleton-bridged,stage-wise learning approach to address the challenge. Our use of skeleton isdue to its nice property of topology preservation, while being of lowercomplexity to learn. To learn skeleton from an input image, we design a deeparchitecture whose decoder is based on a novel design of parallel streamsrespectively for synthesis of curve- and surface-like skeleton points. We usedifferent shape representations of point cloud, volume, and mesh in ourstage-wise learning, in order to take their respective advantages. We alsopropose multi-stage use of the input image to correct prediction errors thatare possibly accumulated in each stage. We conduct intensive experiments toinvestigate the efficacy of our proposed approach. Qualitative and quantitativeresults on representative object categories of both simple and complextopologies demonstrate the superiority of our approach over existing ones. Wewill make our ShapeNet-Skeleton dataset publicly available."	Computer Vision and Pattern Recognition (cs.CV)	
nicklaw296	ニクロー	316	321	@puni_kyopro https://t.co/JDUF973x7O とりあえずいろんな分野で使えそうな感じの	2019/6/26 22:44	https://arxiv.org/abs/1703.03400	Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks	"We propose an algorithm for meta-learning that is model-agnostic, in thesense that it is compatible with any model trained with gradient descent andapplicable to a variety of different learning problems, includingclassification, regression, and reinforcement learning. The goal ofmeta-learning is to train a model on a variety of learning tasks, such that itcan solve new learning tasks using only a small number of training samples. Inour approach, the parameters of the model are explicitly trained such that asmall number of gradient steps with a small amount of training data from a newtask will produce good generalization performance on that task. In effect, ourmethod trains the model to be easy to fine-tune. We demonstrate that thisapproach leads to state-of-the-art performance on two few-shot imageclassification benchmarks, produces good results on few-shot regression, andaccelerates fine-tuning for policy gradient reinforcement learning with neuralnetwork policies."	Machine Learning (cs.LG)	Artificial Intelligence (cs.AI);Computer Vision and Pattern Recognition (cs.CV);Neural and Evolutionary Computing (cs.NE)
kogomi21361	kogomi	311	334	ベシ圏の原著が公開されてると聞いて..... ふふふ…英語を勉強できる素材が増えたな…（建前） https://t.co/ZXXMFKXZTx	2019/6/26 22:52	https://arxiv.org/abs/1612.09375	Basic Category Theory	"This short introduction to category theory is for readers with relativelylittle mathematical background. At its heart is the concept of a universalproperty, important throughout mathematics. After a chapter introducing thebasic definitions, separate chapters present three ways of expressing universalproperties: via adjoint functors, representable functors, and limits. A finalchapter ties the three together.For each new categorical concept, a generous supply of examples is provided,taken from different parts of mathematics. At points where the leap inabstraction is particularly great (such as the Yoneda lemma), the reader willfind careful and extensive explanations."	Category Theory (math.CT)	Algebraic Topology (math.AT);Logic (math.LO)
Yukihiro0036	YukihiroMasuoka	125	211	これのことですかね https://t.co/fzkDrDp7ql	2019/6/26 22:55	https://arxiv.org/abs/1902.00032	Categorical Semantics for Time Travel	"We introduce a general categorical framework to reason about quantum theoryand other process theories living in spacetimes where Closed Timelike Curves(CTCs) are available, allowing resources to travel back in time and providecomputational speedups. Our framework is based on a weakening of the definitionof traced symmetric monoidal categories, obtained by dropping the yanking axiomand the requirement that the trace be defined on all morphisms. We show thatthe two leading models for quantum theory with closed timelike curves---namelythe P-CTC model of Lloyd et al. and the D-CTC model of Deutsch---are capturedby our framework, and in doing so we provide the first compositionaldescription of the D-CTC model. Our description of the D-CTC model results in aprocess theory which respects the constraints of relativistic causality: thisis in direct contrast to the P-CTC model, where CTCs are implemented by a traceand allow post-selection to be performed deterministically."	Quantum Physics (quant-ph)	
hhhhhhaaaaaa2	h.a.	339	524	Spin-split band hybridization in graphene proximitized with α-RuCl3 nanosheets https://t.co/VEQxfqrDFS グラフェンとαCuClのシート重ねたらスピン散乱によって 量子振動が減衰するらしい こんな研究があるんやね	2019/6/26 23:04	https://arxiv.org/abs/1906.10405	Spin-split band hybridization in graphene proximitized with $α$-RuCl$_3$ nanosheets	"Proximity effects induced in the 2D Dirac material graphene potentially openaccess to novel and intriguing physical phenomena. Thus far, the couplingbetween graphene and ferromagnetic insulators has been experimentallyestablished. However, only very little is known about graphene's interactionwith antiferromagnetic insulators. Here, we report a low temperature study ofthe electronic properties of high quality van der Waals heterostructurescomposed of a single graphene layer proximitized with $\alpha$-RuCl$_3$. Thelatter is known to become antiferromagnetically ordered below 10 K. Shubnikovde Haas oscillations in the longitudinal resistance together with Hallresistance measurements provide clear evidence for a band realignment that isaccompanied by a transfer of electrons originally occupying the graphene's spindegenerate Dirac cones into $\alpha$-RuCl$_3$ band states with in-plane spinpolarization. Left behind are holes in two separate Fermi pockets, only thedispersion of one of which is distorted near the Fermi energy due to spinselective hybridization with these spin polarized $\alpha$-RuCl$_3$ bandstates. This interpretation is supported by our DFT calculations. An unexpecteddamping of the quantum oscillations as well as a zero field resistance upturnclose to the N$?$el temperature of $\alpha$-RuCl$_3$ suggests the onset ofadditional spin scattering due to spin fluctuations in the $\alpha$-RuCl$_3$."	Materials Science (cond-mat.mtrl-sci)	Strongly Correlated Electrons (cond-mat.str-el)
triwave33	triwave	807	726	強化学習タスクで、人間の生体信号を内発的な報酬（系から付与されない報酬）として扱うもの。  強化学習に限らず、自動運転のプランニング問題に対して安全を定義・評価するのは極めて難しい問題。生体情報を取り込めたら面白いがそんなにうまくいくの？しっかり読む  https://t.co/wZR0OMV9dr	2019/6/26 23:32	https://arxiv.org/abs/1805.09975	Visceral Machines: Risk-Aversion in Reinforcement Learning with Intrinsic Physiological Rewards	"As people learn to navigate the world, autonomic nervous system (e.g., ""fightor flight"") responses provide intrinsic feedback about the potentialconsequence of action choices (e.g., becoming nervous when close to a cliffedge or driving fast around a bend.) Physiological changes are correlated withthese biological preparations to protect one-self from danger. We present anovel approach to reinforcement learning that leverages a task-independentintrinsic reward function trained on peripheral pulse measurements that arecorrelated with human autonomic nervous system responses. Our hypothesis isthat such reward functions can circumvent the challenges associated with sparseand skewed rewards in reinforcement learning settings and can help improvesample efficiency. We test this in a simulated driving environment and showthat it can increase the speed of learning and reduce the number of collisionsduring the learning stage."	Artificial Intelligence (cs.AI)	
kadamasaru	嘉田 勝	"2,896"	318	ほぉ。 https://t.co/m7SQeRIWC6	2019/6/26 23:41	https://arxiv.org/abs/1801.02517	On the cofinality of the splitting number	"The splitting number can be singular. The key method is to construct aforcing poset with finite support matrix iterations of ccc posets introduced byBlass and the second author ""Ultrafilters with small generating sets"", IsraelJ. Math., 65, (1989)"	Logic (math.LO)	
QU00h	は	540	466	この論文、ためしに実験で確かめてみようかな  https://t.co/vUEEohidgg	2019/6/27 0:37	https://arxiv.org/abs/1708.05509	Towards the Automatic Anime Characters Creation with Generative Adversarial Networks	"Automatic generation of facial images has been well studied after theGenerative Adversarial Network (GAN) came out. There exists some attemptsapplying the GAN model to the problem of generating facial images of animecharacters, but none of the existing work gives a promising result. In thiswork, we explore the training of GAN models specialized on an anime facialimage dataset. We address the issue from both the data and the model aspect, bycollecting a more clean, well-suited dataset and leverage proper, empiricalapplication of DRAGAN. With quantitative analysis and case studies wedemonstrate that our efforts lead to a stable and high-quality model. Moreover,to assist people with anime character design, we build a website(http://make.girls.moe) with our pre-trained model available online, whichmakes the model easily accessible to general public."	Computer Vision and Pattern Recognition (cs.CV)	
alterakey	Takahiro Yoshimura	817	907	おお、華麗だ… #メモ  From IP ID to Device ID and KASLR Bypass (Extended Version) https://t.co/KUdi5nxkPV https://t.co/KUdi5nxkPV	2019/6/27 0:37	"https://arxiv.org/abs/1906.10478, https://arxiv.org/abs/1906.10478"	"From IP ID to Device ID and KASLR Bypass (Extended Version), From IP ID to Device ID and KASLR Bypass (Extended Version)"	"IP headers include a 16-bit ID field. Our work examines the generation ofthis field in Windows (versions 8 and higher), Linux and Android, and showsthat the IP ID field enables remote servers to assign a unique ID to eachdevice and thus be able to identify subsequent transmissions sent from thatdevice. This identification works across all browsers and over network changes.In modern Linux and Android versions, this field leaks a kernel address, thuswe also break KASLR.Our work includes reverse-engineering of the Windows IP ID generation code,and a cryptanalysis of this code and of the Linux kernel IP ID generation code.It provides practical techniques to partially extract the key used by each ofthese algorithms, overcoming different implementation issues, and observingthat this key can identify individual devices. We deployed a demo (for Windows)showing that key extraction and machine fingerprinting works in the wild, andtested it from networks around the world., IP headers include a 16-bit ID field. Our work examines the generation ofthis field in Windows (versions 8 and higher), Linux and Android, and showsthat the IP ID field enables remote servers to assign a unique ID to eachdevice and thus be able to identify subsequent transmissions sent from thatdevice. This identification works across all browsers and over network changes.In modern Linux and Android versions, this field leaks a kernel address, thuswe also break KASLR.Our work includes reverse-engineering of the Windows IP ID generation code,and a cryptanalysis of this code and of the Linux kernel IP ID generation code.It provides practical techniques to partially extract the key used by each ofthese algorithms, overcoming different implementation issues, and observingthat this key can identify individual devices. We deployed a demo (for Windows)showing that key extraction and machine fingerprinting works in the wild, andtested it from networks around the world."	"Cryptography and Security (cs.CR), Cryptography and Security (cs.CR)"	
petrucci1993	TKC(物理)	62	110	https://t.co/Ez4jgbxdtz 修正版あげました	2019/6/27 0:51	https://arxiv.org/abs/1906.05009	Partner formula for an arbitrary moving mirror in $1+1$ dimensions	"In the information loss problem in black hole evaporation, investigation ofthe purification partner of a Hawking particle is crucial. It is a well-knownfact that 3+1 dimensional spherically symmetric gravitational collapse can beapproximately described by 1+1 dimensional moving mirror models. Since adetected particle in field theory is defined by what a particle detectorobserves, the diversity of detector designs yields a variety of particles andtheir partners. We provide a formula of generalized partners of detectedparticles emitted out of mirrors in arbitrary motion in a free massless scalarfield theory. Using the formula, we directly demonstrate information storageabout pre-thermal information in a pure state of a Hawking particle and itspartner. The partner form drastically changes depending on the detailed designsof particle detectors for the Hawking radiation. In a case of the Hawkingparticle and its partner sensitive to information about pre-thermal era,spatial configurations of the partner has long tails in a stage where onlyzero-point fluctuation is emitted out of the mirror."	General Relativity and Quantum Cosmology (gr-qc)	High Energy Physics - Theory (hep-th);Quantum Physics (quant-ph)
q9ac	將籠林檎 / ??	278	228	超伝導体を二つ持ってきてカシミール効果の温度依存性を調べる。二つが十分に近い領域(vdW regeme)だと超伝導相転移はカシミール効果に不連続性をもたらさないが、二つが離れていると(Casimir regeme)超伝導転移点でカシミールフォースが不連続になるらしい。 https://t.co/9n2fupxScD	2019/6/27 1:06	https://arxiv.org/abs/1906.07898	Casimir forces and high-Tc superconductors	"We investigate the Casimir forces between high-$T_c$ superconductors asfunction of the distance and temperature, focusing on optimally-dopedYBa$_2$Cu$_3$O$_{6.95}$. We consider formerly studied configurations in normalmetals lying in the short-distance (50 nm - 600 nm), and long-distance (600 nm- 10 microns) regimes. The dielectric properties of the material are describedin terms of weakly-interacting, short-correlated conducting pairs transportedalong quasi-2D layers. In the short-range regime, a continuous behavior of theCasimir forces arises, with no significant discontinuity at the transitiontemperature. This behavior also follows in the equivalent the normal conductorconfiguration. In the long-range regime, the forces show an abrupt increment atthe critical temperature. Simultaneously, the Casimir entropy and the specificheat develop a strong discontinuous behavior, characteristic of the SC-normalphase transition. In every situation, the entropy vanishes at extremely lowtemperatures."	Superconductivity (cond-mat.supr-con)	Mesoscale and Nanoscale Physics (cond-mat.mes-hall)
GenerateTaiyaki	taiyaki	14	0	DeepVoxels (CVPR2019 oral https://t.co/2bBGcktVrs) 物体を様々な方向から撮影した2D画像から3Dの埋め込み表現を学習する手法.各方向からの画像特徴の三次元的・逐次的な統合+埋め込みを2Dに射影した特徴からの訓練データの再構成+敵対的ロス.物体を未知の方向から見た画像を高解像度で生成可能. https://t.co/VEGCybiazv	2019/6/27 1:48	https://arxiv.org/abs/1812.01024	DeepVoxels: Learning Persistent 3D Feature Embeddings	"In this work, we address the lack of 3D understanding of generative neuralnetworks by introducing a persistent 3D feature embedding for view synthesis.To this end, we propose DeepVoxels, a learned representation that encodes theview-dependent appearance of a 3D scene without having to explicitly model itsgeometry. At its core, our approach is based on a Cartesian 3D grid ofpersistent embedded features that learn to make use of the underlying 3D scenestructure. Our approach combines insights from 3D geometric computer visionwith recent advances in learning image-to-image mappings based on adversarialloss functions. DeepVoxels is supervised, without requiring a 3D reconstructionof the scene, using a 2D re-rendering loss and enforces perspective andmulti-view geometry in a principled manner. We apply our persistent 3D scenerepresentation to the problem of novel view synthesis demonstratinghigh-quality results for a variety of challenging scenes."	Computer Vision and Pattern Recognition (cs.CV)	
Q7Xf5U4TpGCMDjG	ほ(研究)	0	0	https://t.co/EubJn4Hyo0 … https://t.co/FFPh73L2j2 CVSports(CVPR2019)ゴルフのスウィングのシークエンスを８種類に分類し、それぞれの検出を行う研究。同時にゴルフのスウィングに関するデータセットGolfDBの提案。 https://t.co/G0TpYt2QZf	2019/6/27 2:12	https://arxiv.org/abs/1903.06528	GolfDB: A Video Database for Golf Swing Sequencing	"The golf swing is a complex movement requiring considerable full-bodycoordination to execute proficiently. As such, it is the subject of frequentscrutiny and extensive biomechanical analyses. In this paper, we introduce thenotion of golf swing sequencing for detecting key events in the golf swing andfacilitating golf swing analysis. To enable consistent evaluation of golf swingsequencing performance, we also introduce the benchmark database GolfDB,consisting of 1400 high-quality golf swing videos, each labeled with eventframes, bounding box, player name and sex, club type, and view type.Furthermore, to act as a reference baseline for evaluating golf swingsequencing performance on GolfDB, we propose a lightweight deep neural networkcalled SwingNet, which possesses a hybrid deep convolutional and recurrentneural network architecture. SwingNet correctly detects eight golf swing eventsat an average rate of 76.1%, and six out of eight events at a rate of 91.8%. Inline with the proposed baseline SwingNet, we advocate the use ofcomputationally efficient models in future research to promote in-the-fieldanalysis via deployment on readily-available mobile devices."	Computer Vision and Pattern Recognition (cs.CV)	
yasuokajihei	宮島正	380	132	(Google DeepMind) https://t.co/u5e1OsKHnQ 他者の心を類推し、理解する能力についての「心の理論」に基づいた振る舞いが出来るようなモデルを深層強化学習で実現．	2019/6/27 3:41	https://arxiv.org/abs/1802.07740	Machine Theory of Mind	"Theory of mind (ToM; Premack & Woodruff, 1978) broadly refers to humans'ability to represent the mental states of others, including their desires,beliefs, and intentions. We propose to train a machine to build such modelstoo. We design a Theory of Mind neural network -- a ToMnet -- which usesmeta-learning to build models of the agents it encounters, from observations oftheir behaviour alone. Through this process, it acquires a strong prior modelfor agents' behaviour, as well as the ability to bootstrap to richerpredictions about agents' characteristics and mental states using only a smallnumber of behavioural observations. We apply the ToMnet to agents behaving insimple gridworld environments, showing that it learns to model random,algorithmic, and deep reinforcement learning agents from varied populations,and that it passes classic ToM tasks such as the ""Sally-Anne"" test (Wimmer &Perner, 1983; Baron-Cohen et al., 1985) of recognising that others can holdfalse beliefs about the world. We argue that this system -- which autonomouslylearns how to model other agents in its world -- is an important step forwardfor developing multi-agent AI systems, for building intermediating technologyfor machine-human interaction, and for advancing the progress on interpretableAI."	Artificial Intelligence (cs.AI)	
Kashalpha	かしゃるふぁ	697	823	VanQver (Variational and Adiabatically Navigated Quantum Eigensolver)は名前がおしゃれなのでお気に入り https://t.co/yKPKWn4xj4	2019/6/27 6:16	https://arxiv.org/abs/1810.11511	VanQver: The Variational and Adiabatically Navigated Quantum Eigensolver	"The accelerated progress in manufacturing noisy intermediate-scale quantum(NISQ) computing hardware has opened the possibility of exploring itsapplication in transforming approaches to solving computationally challengingproblems. The important limitations common among all NISQ computingtechnologies are the absence of error correction and the short coherence time,which limit the computational power of these systems. Shortening the requiredtime of a single run of a quantum algorithm is essential for reducingenvironment-induced errors and for the efficiency of the computation. We haveinvestigated the ability of a variational version of adiabatic quantumcomputation (AQC) to generate an accurate state more efficiently compared toexisting adiabatic methods. The standard AQC method uses a time-dependentHamiltonian, connecting the initial Hamiltonian with the final Hamiltonian. Inthe current approach, a navigator Hamiltonian is introduced which has anon-zero amplitude only in the middle of the annealing process. Both theinitial and navigator Hamiltonians are determined using variational methods. Ahermitian cluster operator, inspired by coupled-cluster theory and truncated tosingle and double excitations/de-excitations, is used as a navigatorHamiltonian. A comparative study of our variational algorithm (VanQver) withthat of standard AQC, starting with a Hartree--Fock Hamiltonian, is presented.The results indicate that the introduction of the navigator Hamiltoniansignificantly improves the annealing time required to achieve chemical accuracyby two to three orders of magnitude. The efficiency of the method isdemonstrated in the ground-state energy estimation of molecular systems,namely, H$_2$, P4, and LiH."	Quantum Physics (quant-ph)	
infoseeker18	verbatim	887	"1,952"	期限付助手時代、（古典的な）情報理論の演習を持たされたことがあって、基本的なことを一通り勉強したんだけど、全然面白いと思わなかった。しかし、Wittenの量子情報理論のショートイントロダクションを見てかなり印象が変わった。案外面白い。https://t.co/abDL0EtlwM	2019/6/27 8:13	https://arxiv.org/abs/1805.11965	A Mini-Introduction To Information Theory	"This article consists of a very short introduction to classical and quantuminformation theory. Basic properties of the classical Shannon entropy and thequantum von Neumann entropy are described, along with related concepts such asclassical and quantum relative entropy, conditional entropy, and mutualinformation. A few more detailed topics are considered in the quantum case."	High Energy Physics - Theory (hep-th)	Quantum Physics (quant-ph)
yu4u	Yusuke Uchida	"4,447"	950	AutoAugmentの物体検出版だよー＾＾ / “[1906.11172] Learning Data Augmentation Strategies for Object Detection” https://t.co/s5CA9SZ8bh	2019/6/27 9:57	https://arxiv.org/abs/1906.11172	Learning Data Augmentation Strategies for Object Detection	"Data augmentation is a critical component of training deep learning models.Although data augmentation has been shown to significantly improve imageclassification, its potential has not been thoroughly investigated for objectdetection. Given the additional cost for annotating images for objectdetection, data augmentation may be of even greater importance for thiscomputer vision task. In this work, we study the impact of data augmentation onobject detection. We first demonstrate that data augmentation operationsborrowed from image classification may be helpful for training detectionmodels, but the improvement is limited. Thus, we investigate how learned,specialized data augmentation policies improve generalization performance fordetection models. Importantly, these augmentation policies only affect trainingand leave a trained model unchanged during evaluation. Experiments on the COCOdataset indicate that an optimized data augmentation policy improves detectionaccuracy by more than +2.3 mAP, and allow a single inference model to achieve astate-of-the-art accuracy of 50.7 mAP. Importantly, the best policy found onCOCO may be transferred unchanged to other detection datasets and models toimprove predictive accuracy. For example, the best augmentation policyidentified with COCO improves a strong baseline on PASCAL-VOC by +2.7 mAP. Ourresults also reveal that a learned augmentation policy is superior tostate-of-the-art architecture regularization methods for object detection, evenwhen considering strong baselines. Code for training with the learned policy isavailable online atthis https URL"	Computer Vision and Pattern Recognition (cs.CV)	Machine Learning (cs.LG)
ueda_physics	Shu	"1,116"	"1,148"	PBH 由来の 511 keV ガンマ線の観測から PBH がダークマターに占める割合に 1 % 以下の制限がつく https://t.co/PxqWBWR6BD	2019/6/27 10:48	https://arxiv.org/abs/1906.09994	Primordial black holes as dark matter candidate are severely constrained by the Galactic Center 511 keV gamma-ray line	"We derive the strongest constraint on the fraction of dark matter that can becomposed of low mass primordial black holes by using the observation of theGalactic Center 511 keV gamma-ray line. Primordial black holes of masses$\lesssim$ 10$^{15}$ kg will evaporate to produce $e^\pm$ pairs. The positronswill lose energy in the Galactic Center, become non-relativistic, and thenannihilate with the ambient electrons. We derive robust and conservative boundsby assuming that the rate of positron injection via primordial black holeevaporation is less than what is required to explain the SPI/ INTEGRALobservation of the Galactic Center 511 keV gamma-ray line. Depending on theprimordial black hole mass function and other astrophysical uncertainties,these constraints are the most stringent in the literature and show thatprimordial black holes contribute to less than 1\% of the dark matter density.Our technique also probes part of the mass range which was completelyunconstrained by previous studies."	High Energy Astrophysical Phenomena (astro-ph.HE)	Cosmology and Nongalactic Astrophysics (astro-ph.CO);General Relativity and Quantum Cosmology (gr-qc);High Energy Physics - Phenomenology (hep-ph);High Energy Physics - Theory (hep-th)
karino2012	karino2@貴族階級	651	81	少し古いがPixelRNNの論文はなかなか示唆に富むな。 https://t.co/FIyaAWE11i	2019/6/27 11:08	https://arxiv.org/abs/1601.06759	Pixel Recurrent Neural Networks	"Modeling the distribution of natural images is a landmark problem inunsupervised learning. This task requires an image model that is at onceexpressive, tractable and scalable. We present a deep neural network thatsequentially predicts the pixels in an image along the two spatial dimensions.Our method models the discrete probability of the raw pixel values and encodesthe complete set of dependencies in the image. Architectural novelties includefast two-dimensional recurrent layers and an effective use of residualconnections in deep recurrent networks. We achieve log-likelihood scores onnatural images that are considerably better than the previous state of the art.Our main results also provide benchmarks on the diverse ImageNet dataset.Samples generated from the model appear crisp, varied and globally coherent."	Computer Vision and Pattern Recognition (cs.CV)	Machine Learning (cs.LG);Neural and Evolutionary Computing (cs.NE)
esXFdfOJxiGBFLx	人工知能 Deep Learning AI image medical machine learni	858	"1,901"	女子ワールドカップと機械学習に関するarxivです。 過去のデータやFIFAランキングデータから優勝予測を行うものです。 今現在、女子ワールドカップが行われているため読んでみました。 日本が低いのが気になりますね。 https://t.co/8nCfZqPPyK	2019/6/27 11:08	https://arxiv.org/abs/1906.01131	Hybrid Machine Learning Forecasts for the FIFA Women's World Cup 2019	"In this work, we combine two different ranking methods together with severalother predictors in a joint random forest approach for the scores of soccermatches. The first ranking method is based on the bookmaker consensus, thesecond ranking method estimates adequate ability parameters that reflect thecurrent strength of the teams best. The proposed combined approach is thenapplied to the data from the two previous FIFA Women's World Cups 2011 and2015. Finally, based on the resulting estimates, the FIFA Women's World Cup2019 is simulated repeatedly and winning probabilities are obtained for allteams. The model clearly favors the defending champion USA before the hostFrance."	Machine Learning (stat.ML)	Machine Learning (cs.LG);Applications (stat.AP)
hillbig	Daisuke Okanohara	"15,910"	254	一部しか観測できない環境下（POMDPs）では過去の観測列から現在の状態信念を計算する。この信念からの長期の予測タスクを解くことで時間的に一貫性がある信念が得られ、地図や自己位置も復元可能。この信念を元にした強化学習はデータ効率がよい https://t.co/zbkyaMlSbB https://t.co/HqyL8zkIBQ	2019/6/27 11:30	https://arxiv.org/abs/1906.09237	Shaping Belief States with Generative Environment Models for RL	"When agents interact with a complex environment, they must form and maintainbeliefs about the relevant aspects of that environment. We propose a way toefficiently train expressive generative models in complex environments. We showthat a predictive algorithm with an expressive generative model can form stablebelief-states in visually rich and dynamic 3D environments. More precisely, weshow that the learned representation captures the layout of the environment aswell as the position and orientation of the agent. Our experiments show thatthe model substantially improves data-efficiency on a number of reinforcementlearning (RL) tasks compared with strong model-free baseline agents. We findthat predicting multiple steps into the future (overshooting), in combinationwith an expressive generative model, is critical for stable representations toemerge. In practice, using expressive generative models in RL iscomputationally expensive and we propose a scheme to reduce this computationalburden, allowing us to build agents that are competitive with model-freebaselines."	Machine Learning (cs.LG)	Artificial Intelligence (cs.AI);Machine Learning (stat.ML)
tonets	大上雅史｜M Ohue	"4,605"	"1,769"	Dror、ディープもやってるのか（って前も言った気も） [1807.01297] Transferrable End-to-End Learning for Protein Interface Prediction https://t.co/0DfbvZJLgx	2019/6/27 12:29	https://arxiv.org/abs/1807.01297	Transferrable End-to-End Learning for Protein Interface Prediction	"While there has been an explosion in the number of experimentally determined,atomically detailed structures of proteins, how to represent these structuresin a machine learning context remains an open research question. In this workwe demonstrate that representations learned from raw atomic coordinates canoutperform hand-engineered structural features while displaying a much higherdegree of transferrability. To do so, we focus on a central problem in biology:predicting how proteins interact with one another--that is, which surfaces ofone protein bind to which surfaces of another protein. We present SiameseAtomic Surfacelet Network (SASNet), the first end-to-end learning method forprotein interface prediction. Despite using only spatial coordinates andidentities of atoms as inputs, SASNet outperforms state-of-the-art methods thatrely on hand-engineered, high-level features. These results are particularlystriking because we train the method entirely on a significantly biased dataset that does not account for the fact that proteins deform when binding to oneanother. Demonstrating the first successful application of transfer learning toatomic-level data, our network maintains high performance, without retraining,when tested on real cases in which proteins do deform."	Biomolecules (q-bio.BM)	Machine Learning (cs.LG);Machine Learning (stat.ML)
taketo1024	さのたけと	"6,347"	243	@kyow_Q また東京に来られる機会にでも是非??   量子群の表現とも関連があるようで分かりたいと思ってます??こちらの Section6 に概説があります?? https://t.co/YhNH9S4dE1	2019/6/27 12:36	https://arxiv.org/abs/1409.6442	A hitchhiker's guide to Khovanov homology	These notes from the 2014 summer school Quantum Topology at the CIRM inLuminy attempt to provide a rough guide to a selection of developments inKhovanov homology over the last fifteen years.	Geometric Topology (math.GT)	Algebraic Topology (math.AT);Quantum Algebra (math.QA)
CharStream	カオナシ(T.MATSUMOTO)	349	412	@hyuki 原書の.pdf版ならこちら（https://t.co/NtqT2pmKIH）から無償でダウンロードできますから、英語版は簡単に入手できますよ。 #ベーシック圏論	2019/6/27 13:14	https://arxiv.org/abs/1612.09375	Basic Category Theory	"This short introduction to category theory is for readers with relativelylittle mathematical background. At its heart is the concept of a universalproperty, important throughout mathematics. After a chapter introducing thebasic definitions, separate chapters present three ways of expressing universalproperties: via adjoint functors, representable functors, and limits. A finalchapter ties the three together.For each new categorical concept, a generous supply of examples is provided,taken from different parts of mathematics. At points where the leap inabstraction is particularly great (such as the Yoneda lemma), the reader willfind careful and extensive explanations."	Category Theory (math.CT)	Algebraic Topology (math.AT);Logic (math.LO)
q9ac	將籠林檎 / ??	278	228	Weyl型分散を持つ物質をメカニカルに変形したり非慣性系に乗せたり。曲がった時空の上のワイル粒子のダイナミクスみたいなのを考えるフレームワークらしい。 https://t.co/IUBxUfVk8E	2019/6/27 14:31	https://arxiv.org/abs/1906.07540	Curved spacetime theory of inhomogeneous Weyl materials	"We show how the universal low-energy properties of Weyl semimetals withspatially varying time-reversal (TR) or inversion (I) symmetry breaking aredescribed in terms of chiral fermions experiencing curved-\emph{spacetime}geometry and synthetic gauge fields. By employing Clifford representations andSchrieffer-Wolff transformations, we present a systematic derivation of aneffective curved-space Weyl theory with rich geometric and gauge structure. Toillustrate the utility of the formalism, we give a concrete prescription of howto fabricate nontrivial curved spacetimes and event horizons in topologicalinsulators with magnetic textures. Our theory can also account forstrain-induced effects, providing a powerful unified framework for studying anddesigning inhomogeneous Weyl materials."	Mesoscale and Nanoscale Physics (cond-mat.mes-hall)	Strongly Correlated Electrons (cond-mat.str-el);Quantum Physics (quant-ph)
q9ac	將籠林檎 / ??	278	228	量子カルノーエンジン。調和ポテンシャル下にある量子系が熱浴とひっついてる設定を考えて、マスター方程式を書き下す→古典的なカルノーサイクルに対応するプロセスを考えて、その中でエネルギーやコヒーレンスがどう消費されていくかを調べてる。 https://t.co/VjK19MdQKf	2019/6/27 14:46	https://arxiv.org/abs/1906.06946	Quantum Signatures in the Quantum Carnot Cycle	"The Carnot cycle combines reversible isothermal and adiabatic strokes toobtain optimal efficiency, at the expense of a vanishing power output. Here, weconstruct quantum Carnot-analog cycles, operating irreversibly at non-vanishingpower. Swift thermalization is obtained utilizing shortcut to equilibriumprotocols and the isolated strokes employ frictionless shortcut to adiabaticityprotocols. We solve the dynamics for a working medium composed of a particle ina driven Harmonic trap. A complete description of the state is obtained,incorporating both changes in energy and coherence. In the limit of finitecycle-time, coherence disappears and the efficiency converges to the idealCarnot efficiency. Thus, demonstrating the trade-off between power andefficiency. At short cycle-times, generation of coherence is necessary toachieve power. To evaluate the importance of quantum coherence, we comparethree types of cycles, Carnot-shortcut, Endo-shortcut and Endo-global. In thefirst two, the coherence is limited to the interior of the strokes, while forthe last cycle the coherence never vanishes. This allows the Endo-global engineto operate at shorter cycle-times relative to the shortcut cycles. Introducingpure-dephasing to the Endo-global engine terminates the quantum coherence, andwith it, the power output. This phenomena can be identified by evaluating thecycle performance, therefore indicating a quantum signature."	Quantum Physics (quant-ph)	
SMBKRHYT	?Hayato Shimabukuro?	923	628	moriwakiさんたちの21cm-OIII cross correlation論文出たんだ。  https://t.co/VGq06l1wfN	2019/6/27 15:47	https://arxiv.org/abs/1906.10863	Cross-correlation between the 21-cm signal and [Oiii] emitters during early cosmic reionisation	"We study statistics of the 21-cm signal from the epoch of reionisation. Wepropose to use [OIII] line emitting galaxies to cross-correlate with the 21-cmsignal from $z = 7 - 10$. To this aim, we employ simulations of reionisationobtained post-processing the high-resolution cosmological hydrodynamicssimulation Massive Black-II with the 3D radiative transfer code CRASH to followthe propagation of ionising photons from a variety of sources. We show that,during the early phases of reionisation, the 21-cm signal is positivelycorrelated with the spatial distribution of the [OIII] emitters on large scales$(k < 1h~\rm cMpc^{-1})$. This positive correlation is generated by thetemperature - galaxy correlation and it is a few times larger than when weassume that the heating is saturated. As the reionised regions expand, thecorrelation changes its sign to negative from $z = 10$ to 8. The signals atthis epoch can be detected by combining the Square Kilometre Array (SKA) and awide-field [OIII] emitter survey. We also calculate the cross-power spectrumwith a three-dimensional [OIII] intensity field, aiming at exploiting futureintensity mapping observations. We conclude that high-redshift [OIII] lineemitters provide a promising and unique method to probe the reionisationprocess when the inter-galactic medium is largely neutral."	Astrophysics of Galaxies (astro-ph.GA)	Cosmology and Nongalactic Astrophysics (astro-ph.CO)
bbr_bbq	Isao Takaesu	"1,111"	80	FuzzingをMLに応用する研究動向の纏め。 A Review of Machine Learning Applications in Fuzzing https://t.co/hwLPeONvnV	2019/6/27 16:01	https://arxiv.org/abs/1906.11133	A Review of Machine Learning Applications in Fuzzing	"Fuzzing has played an important role in improving software development andtesting over the course of several decades. Recent research in fuzzing hasfocused on applications of machine learning (ML), offering useful tools toovercome challenges in the fuzzing process. This review surveys the currentresearch in applying ML to fuzzing. Specifically, this review discussessuccessful applications of ML to fuzzing, briefly explores challengesencountered, and motivates future research to address fuzzing bottlenecks."	Cryptography and Security (cs.CR)	Artificial Intelligence (cs.AI);Machine Learning (cs.LG);Machine Learning (stat.ML)
bbr_bbq	Isao Takaesu	"1,111"	80	DNNの学習時に使用される勾配から訓練データを復元する手法「Deep Leakage」。訓練データに機微情報が含まれていた場合、情報漏洩となる。 Deep Leakage from Gradients https://t.co/q8zOw4z4OM	2019/6/27 16:11	https://arxiv.org/abs/1906.08935	Deep Leakage from Gradients	"Exchanging gradients is a widely used method in modern multi-node machinelearning system (e.g., distributed training, collaborative learning). For along time, people believed that gradients are safe to share: i.e., the trainingdata will not be leaked by gradient exchange. However, we show that it ispossible to obtain the private training data from the publicly sharedgradients. We name this leakage as Deep Leakage from Gradient and empiricallyvalidate the effectiveness on both computer vision and natural languageprocessing tasks. Experimental results show that our attack is much strongerthan previous approaches: the recovery is pixel-wise accurate for images andtoken-wise matching for texts. We want to raise people's awareness to rethinkthe gradient's safety. Finally, we discuss several possible strategies toprevent such deep leakage. The most effective defense method is gradientpruning."	Machine Learning (cs.LG)	Cryptography and Security (cs.CR);Machine Learning (stat.ML)
mjmiyama	観山正道	745	601	昨日の配信でも話題に出た山城くんの論文  https://t.co/00grdqaMhR	2019/6/27 16:29	https://arxiv.org/abs/1906.10889	Dynamics of reverse annealing for the fully-connected $p$-spin model	"Reverse annealing is a relatively new variant of quantum annealing, in whichone starts from a classical state and increases and then decreases theamplitude of the transverse field, in the hope of finding a better classicalstate than the initial state for a given optimization problem. We numericallystudy the unitary quantum dynamics of reverse annealing for the mean-field-type$p$-spin model and show that the results are consistent with the predictions ofequilibrium statistical mechanics. In particular, we corroborate theequilibrium analysis prediction that reverse annealing provides an exponentialspeedup over conventional quantum annealing in terms of solving the $p$-spinmodel. This lends support to the expectation that equilibrium analyses areeffective at revealing essential aspects of the dynamics of quantum annealing.We also compare the results of quantum dynamics with the correspondingclassical dynamics, to reveal their similarities and differences. Wedistinguish between two reverse annealing protocols we call adiabatic anditerated reverse annealing. We further show that iterated reverse annealing, ashas been realized in the D-Wave device, is ineffective in the case of the$p$-spin model, but note that a recently-introduced protocol (""$h$-gain""),which implements adiabatic reverse annealing, may lead to improved performance."	Quantum Physics (quant-ph)	
CQC_0702	緋井悠里	11	13	雷雲の下での地上のガンマ線バーストの観測 https://t.co/azjCIlOXph ちょっと待って。これ完全にシルヴァリオの総統閣下なんだけど。	2019/6/27 17:36	https://arxiv.org/abs/1601.06349	Observation of gamma ray bursts at ground level under the thunderclouds	"We observed three $\gamma$-ray bursts related to thunderclouds in winterusing the prototype of anti-neutrino detector PANDA made of 360-kg plasticscintillator deployed at Ohi Power Station at the coastal area of the JapanSea. The maximum rate of the events which deposited the energy higher than$3\,$MeV was $(5.5 \pm 0.1) \times 10^2 {\rm /s}$.Monte Carlo simulation showed that electrons with approximately monochromaticenergy falling downwards from altitudes of order $100\,$m roughly produced theobserved total energy spectra of the bursts. It is supposed that secondarycosmic-ray electrons, which act as seed, were accelerated in electric field ofthunderclouds and multiplied by relativistic runaway electron avalanche. Weactually found that the $\gamma$-rays of the bursts entered into the detectorfrom the direction close to the zenith. The direction stayed constant duringthe burst within the detector resolution.In addition, taking advantage of the delayed coincidence detection of thedetector, we found neutron events in one of the bursts at the maximum rate of$\sim 14\pm5\,{\rm /s}$."	High Energy Astrophysical Phenomena (astro-ph.HE)	High Energy Physics - Experiment (hep-ex);Instrumentation and Detectors (physics.ins-det)
NH_M_	Nm?m	"1,131"	427	"Chigusa, Moroi, Shoji; Bounce Configuration from Gradient Flow https://t.co/7vWyIUpExL グラディエントフロー方程式を用いることで、真空崩壊確率の新しい計算手法を発見した。従来の方法ではパラメータスキャンをしなければならずかなり大変な計算だったが、この新手法ではより単純に計算できる"	2019/6/27 17:52	https://arxiv.org/abs/1906.10829	Bounce Configuration from Gradient Flow	"Based on the gradient flow, we propose a new method to determine the bounceconfiguration for false vacuum decay. Our method is applicable to a large classof models with multiple fields. Since the bounce configuration is a saddlepoint of an action, a naive gradient flow method does not work. We point outthat a simple modification of the flow equation can make the bounceconfiguration its stable fixed point while the false vacuum configuration anunstable one. Consequently, the bounce configuration can be obtained simply byfollowing the flow without a careful choice of an initial configuration. Withnumerical analysis, we confirm the validity of our claim, checking that theflow equation we propose indeed has solutions that flow into the bounceconfiguration."	High Energy Physics - Phenomenology (hep-ph)	Cosmology and Nongalactic Astrophysics (astro-ph.CO);High Energy Physics - Theory (hep-th);Nuclear Theory (nucl-th)
akihiro_akichan	akihiro_f	122	118	https://t.co/63t23UbL2r  ピザのトッピングを追加・除去できるGAN。両モデルともに対象物の画像とマスクを生成して元画像にかぶせる構造になっている。トッピングをのclassification lossとcycle consictency lossを使用。著者のうちMITはともかく、カタールの大学もピザへの熱い情熱をもっている模様	2019/6/27 19:12	https://arxiv.org/abs/1906.02839	How to make a pizza: Learning a compositional layer-based GAN model	"A food recipe is an ordered set of instructions for preparing a particulardish. From a visual perspective, every instruction step can be seen as a way tochange the visual appearance of the dish by adding extra objects (e.g., addingan ingredient) or changing the appearance of the existing ones (e.g., cookingthe dish). In this paper, we aim to teach a machine how to make a pizza bybuilding a generative model that mirrors this step-by-step procedure. To do so,we learn composable module operations which are able to either add or remove aparticular ingredient. Each operator is designed as a Generative AdversarialNetwork (GAN). Given only weak image-level supervision, the operators aretrained to generate a visual layer that needs to be added to or removed fromthe existing image. The proposed model is able to decompose an image into anordered sequence of layers by applying sequentially in the right order thecorresponding removing modules. Experimental results on synthetic and realpizza images demonstrate that our proposed model is able to: (1) segment pizzatoppings in a weaklysupervised fashion, (2) remove them by revealing what isoccluded underneath them (i.e., inpainting), and (3) infer the ordering of thetoppings without any depth ordering supervision. Code, data, and models areavailable online."	Computer Vision and Pattern Recognition (cs.CV)	
lukasberns	Lukas Berns	367	402	@QFTlover Complex Probability Theory → Quantum Theory https://t.co/ThbBB8JpUr  Quaternionic quantum theory に関しては https://t.co/ghLBeJ8ix8	2019/6/27 20:57	https://arxiv.org/abs/hep-th/9307019	[hep-th/9307019] Quantum Mechanics as Complex Probability Theory	"Realistic quantum mechanics based on complex probability theory is shown tohave a frequency interpretation, to coexist with Bell's theorem, to be linear,to include wavefunctions which are expansions in eigenfunctions of Hermitianoperators and to describe both pure and mixed systems. Illustrative examplesare given. The quantum version of Bayesian inference is discussed. Postscriptversion of hep-th/9307019."	High Energy Physics - Theory (hep-th)	Condensed Matter (cond-mat);General Relativity and Quantum Cosmology (gr-qc)
QFTlover	T duality	243	188	@lukasberns なるほど、ありがとうございます。 ちなみにこのことを考えたきっかけはこの論文でした https://t.co/CuPi4BJ0mX	2019/6/27 21:34	https://arxiv.org/abs/1811.03116	A post-quantum theory of classical gravity?	"We present a consistent theory of classical gravity coupled to quantum fieldtheory. The dynamics is linear in the density matrix, completely positive andtrace-preserving, and reduces to Einstein's equations in the classical limit.The constraints of general relativity are imposed as a symmetry on theequations of motion. The assumption that gravity is classical necessarilymodifies the dynamical laws of quantum mechanics -- the theory must befundamentally stochastic involving finite sized and probabilistic jumps inspace-time and in the quantum field. Nonetheless the quantum state of thesystem can remain pure conditioned on the classical degrees of freedom. Themeasurement postulate of quantum mechanics is not needed since the interactionof the quantum degrees of freedom with classical space-time necessarily causescollapse of the wave-function. More generally, we derive a form ofclassical-quantum dynamics using a non-commuting divergence which has as itslimit deterministic classical Hamiltonian evolution, and which doesn't sufferfrom the pathologies of the semi-classical theory."	High Energy Physics - Theory (hep-th)	Quantum Physics (quant-ph)
qard_t	T-QARD channel	516	0	勾配法ベース https://t.co/lKV8snqXax 勾配フリー https://t.co/RgOimdbFRM https://t.co/bWAgFyrJ9F	2019/6/27 21:47	https://arxiv.org/abs/1903.12166	Sequential minimal optimization for quantum-classical hybrid algorithms	"We propose a sequential minimal optimization method for quantum-classicalhybrid algorithms, which converges faster, is robust against statistical error,and is hyperparameter-free. Specifically, the optimization problem of theparameterized quantum circuits is divided into solvable subproblems byconsidering only a subset of the parameters. In fact, if we choose a singleparameter, the cost function becomes a simple sine curve with period $2\pi$,and hence we can exactly minimize with respect to the chosen parameter.Furthermore, even in general cases, the cost function is given by a simple sumof trigonometric functions with certain periods and hence can be minimized byusing a classical computer. By repeatedly performing this procedure, we canoptimize the parameterized quantum circuits so that the cost function becomesas small as possible. We perform numerical simulations and compare the proposedmethod with existing gradient-free and gradient-based optimization algorithms.We find that the proposed method substantially outperforms the existingoptimization algorithms and converges to a solution almost independent of theinitial choice of the parameters. This accelerates almost all quantum-classicalhybrid algorithms readily and would be a key tool for harnessing near-termquantum devices."	Quantum Physics (quant-ph)	Computational Physics (physics.comp-ph)
re_hako_moon	はこつき＠VR	43	49	https://t.co/ZzrPPfEiJ5 三次元形状を二次元平面を集めて再構成する。Latent Spape Representationと単位平面上のサンプル点を入力として、いくつかのMLPがそれぞれ対応する三次元点を出力。三次元表面と二次元平面のマッピングを学習するため、歪みの少ないUVマップの作成などにも使える。	2019/6/27 23:12	https://arxiv.org/abs/1802.05384	AtlasNet: A Papier-M?ch? Approach to Learning 3D Surface Generation	"We introduce a method for learning to generate the surface of 3D shapes. Ourapproach represents a 3D shape as a collection of parametric surface elementsand, in contrast to methods generating voxel grids or point clouds, naturallyinfers a surface representation of the shape. Beyond its novelty, our new shapegeneration framework, AtlasNet, comes with significant advantages, such asimproved precision and generalization capabilities, and the possibility togenerate a shape of arbitrary resolution without memory issues. We demonstratethese benefits and compare to strong baselines on the ShapeNet benchmark fortwo applications: (i) auto-encoding shapes, and (ii) single-view reconstructionfrom a still image. We also provide results showing its potential for otherapplications, such as morphing, parametrization, super-resolution, matching,and co-segmentation."	Computer Vision and Pattern Recognition (cs.CV)	
QFTlover	T duality	243	188	後で読む。T\barT変形  Moving the CFT into the bulk with $Tbar T$ https://t.co/W9JEwNKY6G	2019/6/28 0:07	https://arxiv.org/abs/1611.03470	Moving the CFT into the bulk with $T\bar T$	"Recent work by Zamolodchikov and others has uncovered a solvable irrelevantdeformation of general 2D CFTs, defined by turning on the dimension 4 operator$T \bar T$, the product of the left- and right-moving stress tensor. We proposethat in the holographic dual, this deformation represents a geometric cutoffthat removes the asymptotic region of AdS and places the QFT on a Dirichletwall at finite radial distance $r = r_c$ in the bulk. As a quantitative checkof the proposed duality, we compute the signal propagation speed, energyspectrum, and thermodynamic relations on both sides. In all cases, we obtain aprecise match. We derive an exact RG flow equation for the metric dependence ofthe effective action of the $T \bar T$ deformed theory, and find that itcoincides with the Hamilton-Jacobi equation that governs the radial evolutionof the classical gravity action in AdS."	High Energy Physics - Theory (hep-th)	
shion_honda	Shion Honda	"1,234"	242	"Graphonomy [Gong+, 2019, CVPR] データセットによってクラスの種類や粒度が異なるhuman parsingを統一的に学習する方法を提案。クラスをノード、クラスの隣接・階層関係をエッジとするグラフを考えて、GNNを転移学習した。ラベルを活用することでSOTAを達成。 https://t.co/vddA3j1DmW #NowReading https://t.co/K0pcXpByeX"	2019/6/28 1:04	https://arxiv.org/abs/1904.04536	Graphonomy: Universal Human Parsing via Graph Transfer Learning	"Prior highly-tuned human parsing models tend to fit towards each dataset in aspecific domain or with discrepant label granularity, and can hardly be adaptedto other human parsing tasks without extensive re-training. In this paper, weaim to learn a single universal human parsing model that can tackle all kindsof human parsing needs by unifying label annotations from different domains orat various levels of granularity. This poses many fundamental learningchallenges, e.g. discovering underlying semantic structures among differentlabel granularity, performing proper transfer learning across different imagedomains, and identifying and utilizing label redundancies across related tasks.To address these challenges, we propose a new universal human parsing agent,named ""Graphonomy"", which incorporates hierarchical graph transfer learningupon the conventional parsing network to encode the underlying label semanticstructures and propagate relevant semantic information. In particular,Graphonomy first learns and propagates compact high-level graph representationamong the labels within one dataset via Intra-Graph Reasoning, and thentransfers semantic information across multiple datasets via Inter-GraphTransfer. Various graph transfer dependencies (\eg, similarity, linguisticknowledge) between different datasets are analyzed and encoded to enhance graphtransfer capability. By distilling universal semantic graph representation toeach specific task, Graphonomy is able to predict all levels of parsing labelsin one system without piling up the complexity. Experimental results showGraphonomy effectively achieves the state-of-the-art results on three humanparsing benchmarks as well as advantageous universal human parsing performance."	Computer Vision and Pattern Recognition (cs.CV)	
KBiostats	KingBiostats	22	188	"U統計量(MVU, minimum-variance unbiasedな推定量を考えるときによく出てくる)の集中不等式を沢山網羅。便利。 https://t.co/MDoYcP7O2Z"	2019/6/28 1:16	https://arxiv.org/abs/1712.06160	A Note on Concentration Inequalities for U-Statistics	"The aim of this paper is to discuss various concentration inequalities forU-statistics and most recent results. A special focus will be on providingproofs for bounds on the U-statistics using classical concentrationinequalities, which, although the results well known, the proofs are not foundin the literature."	Statistics Theory (math.ST)	
GenerateTaiyaki	taiyaki	14	0	"DeepView (CVPR2019oral https://t.co/QfzXEBIwke) 複数視点画像からのシーンのmultiplane image (MPI) の生成でSOTA.損失関数に対する勾配を用いてMPIを直接最適化すると収束が遅い上過学習するが,勾配からMPIの更新量を推定するCNNを用いて更新すると過学習せず高速に収束. https://t.co/zSb0nBQG6R https://t.co/BqvSOYMW7p"	2019/6/28 1:39	https://arxiv.org/abs/1906.07316	DeepView: View Synthesis with Learned Gradient Descent	"We present a novel approach to view synthesis using multiplane images (MPIs).Building on recent advances in learned gradient descent, our algorithmgenerates an MPI from a set of sparse camera viewpoints. The resulting methodincorporates occlusion reasoning, improving performance on challenging scenefeatures such as object boundaries, lighting reflections, thin structures, andscenes with high depth complexity. We show that our method achieveshigh-quality, state-of-the-art results on two datasets: the Kalantari lightfield dataset, and a new camera array dataset, Spaces, which we make publiclyavailable."	Computer Vision and Pattern Recognition (cs.CV)	Graphics (cs.GR);Machine Learning (cs.LG);Image and Video Processing (eess.IV)
q9ac	將籠林檎 / ??	278	228	プラズマ振動の輻射緩和を記述するための場の量子化の方法について．有限系も無限系も取り扱っている．ナノ粒子に閉じ込められたプラズマ振動の量子化は実用的にも基礎的にも重要な話だと思うし，いい学位論文な気がするー． https://t.co/hs9nRZjw9o	2019/6/28 4:58	https://arxiv.org/abs/1906.08775	Field Quantization for Radiative Decay of Plasmons in Finite and Infinite Geometries	"We investigate field quantization in high-curvature geometries. The modelsand calculations can help with understanding the elastic and inelasticscattering of photons and electrons in nanostructures and probe-like metallicdomains. The results find important applications in high-resolution photonicand electronic modalities of scanning probe microscopy, nano-optics,plasmonics, and quantum sensing. Quasistatic formulation, leading tononretarded quantities, is employed and justified on the basis of thenanoscale, here subwavelength, dimensions of the considered domains ofinterest. Within the quasistatic framework, we represent the nanostructurematerial domains with frequency-dependent dielectric functions. Quantitiesassociated with the normal modes of the electronic systems, the nonretardedplasmon dispersion relations, eigenmodes, and fields are then calculated forseveral geometric entities of use in nanoscience and nanotechnology. From theclassical energy of the charge density oscillations in the modelednanoparticle, we then derive the Hamiltonian of the system, which is used forquantization. The quantized plasmon field is obtained and, employing aninteraction Hamiltonian derived from the first-order perturbation theory withinthe hydrodynamic model of the electron gas, we obtain an analytical expressionfor the radiative decay rate of the plasmons. The established treatment isapplied to multiple geometries to investigate the quantized charge densityoscillations on their bounding surfaces. Specifically, using one sheet of atwo-sheeted hyperboloid of revolution, paraboloid of revolution, andcylindrical domains, all with one infinite dimension, and the finite spheroidaland toroidal domains are treated. ..."	Mesoscale and Nanoscale Physics (cond-mat.mes-hall)	
q9ac	將籠林檎 / ??	278	228	アクシオンがある電磁気学からはカシミールフォースが引力だけではなく斥力になる領域が存在することが導かれるらしい。シータ項わからん(´･ω･｀) https://t.co/iI9hvOHg53	2019/6/28 5:47	https://arxiv.org/abs/1906.08975	Anomalous Casimir effect in axion electrodynamics	"We study the Casimir effect in axion electrodynamics. A finite $\theta$-termaffects the energy dispersion relation of photon if $\theta$ is time and/orspace dependent. We focus on a special case with linearly inhomogeneous$\theta$ along the $z$-axis. Then we demonstrate that the Casimir force betweentwo parallel plates perpendicular to the $z$-axis can be either attractive orrepulsive, dependent on the gradient of $\theta$. We call this repulsivecomponent in the Casimir force induced by inhomogeneous $\theta$ the anomalousCasimir effect."	High Energy Physics - Theory (hep-th)	Mesoscale and Nanoscale Physics (cond-mat.mes-hall);High Energy Physics - Phenomenology (hep-ph);Quantum Physics (quant-ph)
q9ac	將籠林檎 / ??	278	228	ワイル点を実現するフォトニック構造中では、電磁場の異常分散のお陰で、2つの量子系が長距離相互作用できるようになる。 https://t.co/vLiBNEyibZ	2019/6/28 5:52	https://arxiv.org/abs/1906.08389	Long-range interactions in Weyl photonic crystals	"The interaction between quantum two-level systems is typically short-range infree space and most photonic environments. Here we show that Weyl photoniccrystals can create significantly extended long-range interaction betweendistant quantum systems because of their diminishing momentum isosurfaces withequal frequencies around isolated Weyl points. The extended range ofinteraction is robust and does not rely on specific location or orientation ofthe transition dipoles. A general relation between the interaction range andproperties of the isosurface is described, which provides a recipe to identifyother photonic environments for that enable long-range interaction. This worklays the foundation to use Weyl photonic crystals as a platform to mediatequantum behavior."	Optics (physics.optics)	Mesoscale and Nanoscale Physics (cond-mat.mes-hall)
doiken_	どいけん	201	214	時代の流れ的にうまくいけば 今の暗号化って量子コンピュータにやられるよね → 量子暗号化しようよ！ → ブロックチェーンやびくない？ → 量子ブロックチェーン みたいな感じの流れで たぶん15年は先になるとは思うんだけど もう論文出てて時代なんだなぁと思ったわけ https://t.co/iQQiIpoYxu	2019/6/28 8:14	https://arxiv.org/abs/1804.05979	Quantum Blockchain using entanglement in time	"We propose a conceptual design for a quantum blockchain. Our method involvesencoding the blockchain into a temporal GHZ (Greenberger-Horne-Zeilinger) stateof photons that do not simultaneously coexist. It is shown that theentanglement in time, as opposed to an entanglement in space, provides thecrucial quantum advantage. All the subcomponents of this system have alreadybeen shown to be experimentally realized. Furthermore, our encoding procedurecan be interpreted as nonclassically influencing the past."	Quantum Physics (quant-ph)	Cryptography and Security (cs.CR);General Finance (q-fin.GN)
K00TSUKA	大塚一輝	671	541	"50KのCOCOの入力画像を部位でセグメンテーションしマーキングを施したDensePose-COCOを出力.GTX1080で240x320画像を20-26フレーム,800x1100を4-5フレームでリアルタイム処理.Deeplab,Mask-RCNNからのアーキテクチャ. -「DensePose: Dense Human Pose Estimation In The Wild」 https://t.co/mlEivOCbBo"	2019/6/28 8:32	https://arxiv.org/abs/1802.00434	DensePose: Dense Human Pose Estimation In The Wild	"In this work, we establish dense correspondences between RGB image and asurface-based representation of the human body, a task we refer to as densehuman pose estimation. We first gather dense correspondences for 50K personsappearing in the COCO dataset by introducing an efficient annotation pipeline.We then use our dataset to train CNN-based systems that deliver densecorrespondence 'in the wild', namely in the presence of background, occlusionsand scale variations. We improve our training set's effectiveness by trainingan 'inpainting' network that can fill in missing groundtruth values and reportclear improvements with respect to the best results that would be achievable inthe past. We experiment with fully-convolutional networks and region-basedmodels and observe a superiority of the latter; we further improve accuracythrough cascading, obtaining a system that delivers highly0accurate results inreal time. Supplementary materials and videos are provided on the project pagethis http URL"	Computer Vision and Pattern Recognition (cs.CV)	
MasWag	Masaki Waga	508	628	これ、PPLで可逆計算みたいだって僕とかが言っていた仕事っぽい [1906.11422] Stepping OCaml https://t.co/VQ3gGPjIg7	2019/6/28 10:21	https://arxiv.org/abs/1906.11422	Stepping OCaml	"Steppers, which display all the reduction steps of a given program, are anovice-friendly tool for understanding program behavior. Unfortunately,steppers are not as popular as they ought to be; indeed, the tool is onlyavailable in the pedagogical languages of the DrRacket programming environment.We present a stepper for a practical fragment of OCaml. Similarly to theDrRacket stepper, we keep track of evaluation contexts in order to reconstructthe whole program at each reduction step. The difference is that we supporteffectful constructs, such as exception handling and printing primitives,allowing the stepper to assist a wider range of users. In this paper, wedescribe the implementation of the stepper, share the feedback from ourstudents, and show an attempt at assessing the educational impact of ourstepper."	Programming Languages (cs.PL)	
necrophilism	きゃりーねくねく	605	449	熱力学不確定性関係は何度 unify されるんだ？  https://t.co/D8MIRBUXuy	2019/6/28 10:46	https://arxiv.org/abs/1906.11360	Unifying Thermodynamic Uncertainty Relations	"We introduce a new technique to bound the fluctuations exhibited by aphysical system, based on the Euclidean geometry of the space of observables.Through a simple unifying argument, we derive a sweeping generalization ofso-called Thermodynamic Uncertainty Relations (TURs). We not only strengthenthe bounds but extend their realm of applicability and in many cases provetheir optimality, without resorting to large deviation theory orinformation-theoretic techniques. In particular, we find the best TUR based onentropy production alone and also derive a novel bound for stationary Markovprocesses, which surpasses previous known bounds. Our results derive from thenon-invariance of the system under a symmetry which can be other than timereversal and thus open a wide new spectrum of applications."	Statistical Mechanics (cond-mat.stat-mech)	
tomonoritotani	"戸谷友則 (TOTANI, Tomonori)"	352	0	https://t.co/R33mIkIBEq 謎の高速電波バースト(FRB)、繰り返すものと一回きりのものがあり、これまで母銀河が判明していたのは繰り返すFRBの一例だけでした。今回初めて、一回きりの種族で母銀河が特定されました。しかもその銀河は、繰り返すFRBの母銀河とは全く異なるタイプでした	2019/6/28 12:41	https://arxiv.org/abs/1906.11476	A single fast radio burst localized to a massive galaxy at cosmological distance	"Fast Radio Bursts (FRBs) are brief radio emissions from distant astronomicalsources. Some are known to repeat, but most are single bursts. Non-repeatingFRB observations have had insufficient positional accuracy to localize them toan individual host galaxy. We report the interferometric localization of thesingle pulse FRB 180924 to a position 4 kpc from the center of a luminousgalaxy at redshift 0.3214. The burst has not been observed to repeat. Theproperties of the burst and its host are markedly different from the only otheraccurately localized FRB source. The integrated electron column density alongthe line of sight closely matches models of the intergalactic medium,indicating that some FRBs are clean probes of the baryonic component of thecosmic web."	High Energy Astrophysical Phenomena (astro-ph.HE)	Cosmology and Nongalactic Astrophysics (astro-ph.CO)
q9ac	將籠林檎 / ??	278	228	物質波(原子)がグラフェンの表面で反射される際の磁気光学効果の影響について。原子はグラフェンとの間にCasimir-Polder forceを感じるが、これの媒介役のグラフェン上の電磁場は外から磁場をかけると磁気光学効果を感じる。これがC-P force、ひいては物質波の反射をモジュる https://t.co/8n4OlPsq72	2019/6/28 12:59	https://arxiv.org/abs/1906.10174	Tuning quantum reflection in graphene with an external magnetic field	"We theoretically demonstrate that an external magnetic field can be used tocontrol quantum reflection of matter waves in graphene due to its extraordinarymagneto-optical properties. We calculate the quantum reflection probabilitiesin graphene for three experimentally relevant atomic species (He, Na, and Rb)using the full Casimir-Polder potential computed by Lifshitz formula valid atall distance regimes, going beyond the traditional approach to quantumreflection, based on power law potentials, which are known to be valid only inthe short distance (non-retarded van der Waals) or in the large distance(retarded) regimes. We predict the energy range for which quantum reflection ismore likely to occur as a function of the magnetic field, and show that thequantum reflection probabilities exhibit discontinuities that reflect thestructure of Landau levels in graphene. Altogether our findings suggest analternative way to control quantum reflection at the nanoscale, and pave theway for the design of alternative, magnetically tuned reflective diffractionelements for matter waves."	Quantum Physics (quant-ph)	Mesoscale and Nanoscale Physics (cond-mat.mes-hall)
wayama_ryousuke	Ryousuke_Wayama	198	194	これ他のタスクにも応用できそうな気がする。　https://t.co/clh2DmAbIf	2019/6/28 13:09	https://arxiv.org/abs/1904.04536	Graphonomy: Universal Human Parsing via Graph Transfer Learning	"Prior highly-tuned human parsing models tend to fit towards each dataset in aspecific domain or with discrepant label granularity, and can hardly be adaptedto other human parsing tasks without extensive re-training. In this paper, weaim to learn a single universal human parsing model that can tackle all kindsof human parsing needs by unifying label annotations from different domains orat various levels of granularity. This poses many fundamental learningchallenges, e.g. discovering underlying semantic structures among differentlabel granularity, performing proper transfer learning across different imagedomains, and identifying and utilizing label redundancies across related tasks.To address these challenges, we propose a new universal human parsing agent,named ""Graphonomy"", which incorporates hierarchical graph transfer learningupon the conventional parsing network to encode the underlying label semanticstructures and propagate relevant semantic information. In particular,Graphonomy first learns and propagates compact high-level graph representationamong the labels within one dataset via Intra-Graph Reasoning, and thentransfers semantic information across multiple datasets via Inter-GraphTransfer. Various graph transfer dependencies (\eg, similarity, linguisticknowledge) between different datasets are analyzed and encoded to enhance graphtransfer capability. By distilling universal semantic graph representation toeach specific task, Graphonomy is able to predict all levels of parsing labelsin one system without piling up the complexity. Experimental results showGraphonomy effectively achieves the state-of-the-art results on three humanparsing benchmarks as well as advantageous universal human parsing performance."	Computer Vision and Pattern Recognition (cs.CV)	
aki_room	aki_room	"1,301"	489	ingappabilitiesって言うのね  https://t.co/dsjZ2IkBxp A generalized boundary condition applied to Lieb-Schultz-Mattis type ingappabilities Y. Yao and M. Oshikawa	2019/6/28 13:12	https://arxiv.org/abs/1906.11662	A generalized boundary condition applied to Lieb-Schultz-Mattis type ingappabilities	"We introduce a new boundary condition which renders the flux-insertionargument for the Lieb-Schultz-Mattis type theorems in two or higher dimensionsfree from the specific choice of system sizes. It also enables a formulation ofthe Lieb-Schultz-Mattis type theorems in arbitrary dimensions in terms ofanomaly in field theory of $1+1$ dimensions. Furthermore, we apply theanomaly-based formulation to the constraints on a half-filled spinless fermionon a square lattice with $\pi$ flux, utilizing time-reversal, the magnetictranslation and on-site internal $U(N)$ symmetries. This demonstrates the roleof time-reversal anomaly on the ingappabilities of a lattice model."	Strongly Correlated Electrons (cond-mat.str-el)	Statistical Mechanics (cond-mat.stat-mech);High Energy Physics - Theory (hep-th);Mathematical Physics (math-ph)
32mao	良き隣人	34	70	これマジ?  https://t.co/mP5JO0mnr7	2019/6/28 13:14	https://arxiv.org/abs/1906.05634	Observation of a first order phase transition to metal hydrogen near 425 GPa	"Hydrogen has been the essential element in the development of atomic andmolecular physics1). Moving to the properties of dense hydrogen has appeared agood deal more complex than originally thought by Wigner and Hungtinton intheir seminal paper predicting metal hydrogen2): the electrons and the protonsare strongly coupled to each other and ultimately must be treated equally3)4).The determination of how and when molecular solid hydrogen will transform intoa metal is the stepping stone towards a full understanding of the quantum-manybody properties of dense hydrogen. The quest for metal hydrogen has pushedmajor developments of modern experimental high pressure physics, yet thevarious claims of its observation over the past 30 years have remainedcontroversial5)6)7). Here we show a first order phase transition near 425 GPafrom insulator molecular solid hydrogen to metal hydrogen. Pressure in excessof 400 GPa could be achieved by using the recently developed Toroidal DiamondAnvil Cell (T-DAC)8). The structural and electronic properties of dense solidhydrogen at 80 K have been characterized by synchrotron infrared spectroscopy.The continuous vibron frequency shift and the electronic band gap closure downto 0.5 eV, both linearly evolving with pressure, point to the stability of theinsulator C2/c-24 phase up to the metallic transition. Upon pressure release,the metallic state transforms back to the C2/c-24 phase with almost nohysteresis, hence suggesting that the metallization proceeds through astructural transformation within the molecular solid, presumably to the Cmca-12structure. Our results are in good agreement with the scenario recentlydisclosed by an advanced calculation able to capture many-body electroniccorrelations9)."	Materials Science (cond-mat.mtrl-sci)	
ueda_physics	Shu	"1,116"	"1,148"	PBH からの重力波を 3 次まで計算したら LISA とかで見える確率と範囲が大きくなったので PBH DM の可能性を消せるかもしれない https://t.co/DquRDqM4na	2019/6/28 14:51	https://arxiv.org/abs/1906.11549	Probing Primordial-Black-Hole Dark Matter with Scalar Induced Gravitational Waves	"The possibility that primordial black holes (PBHs) represent all of the darkmatter (DM) in the Universe and explain the coalescences of binary black holesdetected by LIGO/Virgo has attracted a lot of attention. PBHs are generated bythe enhancement of scalar perturbations which inevitably produce the inducedgravitational waves (GWs). We calculate the induced GWs up to the third-ordercorrection which not only enhances the amplitude of induced GWs, but alsoextends the cutoff frequency from $2k_*$ to $3k_*$. Such effects of thethird-order correction lead to an around $10\%$ increase of the signal-to-noiseratio (SNR) for both LISA and pulsar timing array (PTA) observations, andsignificantly widen the mass range of PBHs in the stellar mass windowaccompanying detectable induced GWs for PTA observations including IPTA, FASTand SKA. And hence the null detections of the induced GWs by LISA and PTAexperiments will exclude the possibility that all of the DM is comprised ofPBHs and the GW events detected by LIGO/Virgo are generated by PBHs."	Cosmology and Nongalactic Astrophysics (astro-ph.CO)	General Relativity and Quantum Cosmology (gr-qc);High Energy Physics - Phenomenology (hep-ph);High Energy Physics - Theory (hep-th)
sir24de3	A.N.	147	175	金属水素の存在を示す論文が公開されている。量子閉じ込めの確認も行なっているようだし、今度は本当かもしれない。 古くから予言されてはいたが、最近の硫化水素の超高圧下における高温超伝導の発見と繋げてみると、現在進行する科学史を感じられる。  https://t.co/xXBE849YYN	2019/6/28 16:38	https://arxiv.org/abs/1906.05634	Observation of a first order phase transition to metal hydrogen near 425 GPa	"Hydrogen has been the essential element in the development of atomic andmolecular physics1). Moving to the properties of dense hydrogen has appeared agood deal more complex than originally thought by Wigner and Hungtinton intheir seminal paper predicting metal hydrogen2): the electrons and the protonsare strongly coupled to each other and ultimately must be treated equally3)4).The determination of how and when molecular solid hydrogen will transform intoa metal is the stepping stone towards a full understanding of the quantum-manybody properties of dense hydrogen. The quest for metal hydrogen has pushedmajor developments of modern experimental high pressure physics, yet thevarious claims of its observation over the past 30 years have remainedcontroversial5)6)7). Here we show a first order phase transition near 425 GPafrom insulator molecular solid hydrogen to metal hydrogen. Pressure in excessof 400 GPa could be achieved by using the recently developed Toroidal DiamondAnvil Cell (T-DAC)8). The structural and electronic properties of dense solidhydrogen at 80 K have been characterized by synchrotron infrared spectroscopy.The continuous vibron frequency shift and the electronic band gap closure downto 0.5 eV, both linearly evolving with pressure, point to the stability of theinsulator C2/c-24 phase up to the metallic transition. Upon pressure release,the metallic state transforms back to the C2/c-24 phase with almost nohysteresis, hence suggesting that the metallization proceeds through astructural transformation within the molecular solid, presumably to the Cmca-12structure. Our results are in good agreement with the scenario recentlydisclosed by an advanced calculation able to capture many-body electroniccorrelations9)."	Materials Science (cond-mat.mtrl-sci)	
R_O_R_I_J_O	?ろりじょ?	"1,212"	909	これ面白そう https://t.co/BItvkLAqed	2019/6/28 16:41	https://arxiv.org/abs/1211.6576	Noncommutative stable homotopy and stable infinity categories	"The noncommutative stable homotopy category $\mathtt{NSH}$ is a triangulatedcategory that is the universal receptacle for triangulated homology theories onseparable $C^*$-algebras. We show that the triangulated category $\mathtt{NSH}$is topological as defined by Schwede using the formalism of (stable) infinitycategories. More precisely, we construct a stable presentable infinity categoryof noncommutative spectra and show that $\mathtt{NSH}^{op}$ sits inside itshomotopy category as a full triangulated subcategory, from which the aboveresult can be deduced. We also introduce a presentable infinity category ofnoncommutative pointed spaces that subsumes $C^*$-algebras and define thenoncommutative stable (co)homotopy groups of such noncommutative spacesgeneralizing earlier definitions for separable $C^*$-algebras. The triangulatedhomotopy category of noncommutative spectra admits (co)products and satisfiesBrown representability. These properties enable us to analyse neatly thebehaviour of the noncommutative stable (co)homotopy groups with respect tocertain (co)limits. Along the way we obtain infinity categorical models forsome well-known bivariant homology theories like $\mathrm{KK}$-theory,$\mathrm{E}$-theory, and connective $\mathrm{E}$-theory via suitable(co)localizations. The stable infinity category of noncommutative spectra canalso be used to produce new examples of generalized (co)homology theories fornoncommutative spaces."	Operator Algebras (math.OA)	Algebraic Topology (math.AT)
qard_t	T-QARD channel	516	0	"今回の岡田さんの発表に関する論文はこちら。  The efficient quantum and simulated annealing of Potts models using a half-hot constraint  Shuntaro Okada, Masayuki Ohzeki, Kazuyuki Tanaka  https://t.co/TVrTaecNwR https://t.co/ThGEDdrDd2"	2019/6/28 17:14	https://arxiv.org/abs/1904.01522	The efficient quantum and simulated annealing of Potts models using a half-hot constraint	"The Potts model is a generalized Ising model with $Q>2$ components. In thefully connected ferromagnetic Potts model, a first-order phase transition isinduced by varying thermal fluctuations. Therefore, the computational timerequired for obtaining the ground states by simulated annealing increasesexponentially with the system size. This study analytically verifies that thetransverse magnetic-field quantum annealing also induces a first-order phasetransition. This result implies that the quantum annealing does not show anexponential acceleration for the ferromagnetic Potts model. In order to avoidthe first-order phase transition, we propose an iterative optimization methodusing a half-hot constraint that is applicable to both quantum and simulatedannealing. In the limit of $Q \to \infty$, a saddle point equation under thehalf-hot constraint is observed to be identical to that of the fully connectedferromagnetic Ising model, confirming a second-order phase transition. Wefurther denote a same relation between the fully connected Potts glass modeland the Sherrington-Kirkpatrick model under assumptions of the staticapproximation and the replica symmetric solution. The proposed method isexpected to be utilized to efficiently obtain low-energy states of Potts modelsusing Ising-type computers such as the D-Wave quantum annealer and the FujitsuDigital Annealer."	Quantum Physics (quant-ph)	
jan_zde	Jan Zdenek丨ズデニェク・ヤン	2	33	ExtremeNet https://t.co/mwNPZQ8KUu CornerNetインスパイアのモデル。Cornerポイントの代わりに四方のextremeポイントと中心点を予測する。予測されたポイントで通常のbboxが決まって、更に全extremeポイント繋げるとマスクっぽいもっと細かいbboxを出力できる。 https://t.co/RZWfGqhyjp	2019/6/28 17:17	https://arxiv.org/abs/1901.08043	Bottom-up Object Detection by Grouping Extreme and Center Points	"With the advent of deep learning, object detection drifted from a bottom-upto a top-down recognition problem. State of the art algorithms enumerate anear-exhaustive list of object locations and classify each into: object or not.In this paper, we show that bottom-up approaches still perform competitively.We detect four extreme points (top-most, left-most, bottom-most, right-most)and one center point of objects using a standard keypoint estimation network.We group the five keypoints into a bounding box if they are geometricallyaligned. Object detection is then a purely appearance-based keypoint estimationproblem, without region classification or implicit feature learning. Theproposed method performs on-par with the state-of-the-art region baseddetection methods, with a bounding box AP of 43.2% on COCO test-dev. Inaddition, our estimated extreme points directly span a coarse octagonal mask,with a COCO Mask AP of 18.9%, much better than the Mask AP of vanilla boundingboxes. Extreme point guided segmentation further improves this to 34.6% MaskAP."	Computer Vision and Pattern Recognition (cs.CV)	
re_hako_moon	はこつき＠VR	43	49	https://t.co/NUuhXULTcm 三次元点群のセマンティックセグメンテーションとインスタンスセグメンテーションを同時に行う。点ごとのEmbeddingがインスタンスごとに近くなるように学習し、CRFを使ってセグメンテーション結果をRefineする。大規模な点群に対してWindowを走査させることで対応。	2019/6/28 18:05	https://arxiv.org/abs/1904.00699	JSIS3D: Joint Semantic-Instance Segmentation of 3D Point Clouds with Multi-Task Pointwise Networks and Multi-Value Conditional Random Fields	"Deep learning techniques have become the to-go models for most vision-relatedtasks on 2D images. However, their power has not been fully realised on severaltasks in 3D space, e.g., 3D scene understanding. In this work, we jointlyaddress the problems of semantic and instance segmentation of 3D point clouds.Specifically, we develop a multi-task pointwise network that simultaneouslyperforms two tasks: predicting the semantic classes of 3D points and embeddingthe points into high-dimensional vectors so that points of the same objectinstance are represented by similar embeddings. We then propose a multi-valueconditional random field model to incorporate the semantic and instance labelsand formulate the problem of semantic and instance segmentation as jointlyoptimising labels in the field model. The proposed method is thoroughlyevaluated and compared with existing methods on different indoor scene datasetsincluding S3DIS and SceneNN. Experimental results showed the robustness of theproposed joint semantic-instance segmentation scheme over its singlecomponents. Our method also achieved state-of-the-art performance on semanticsegmentation."	Computer Vision and Pattern Recognition (cs.CV)	
life_wont_wait	Q	"2,170"	57	前に出すぎだ！戻れ！と言いたくなるな/Can Neutron-Star Mergers Explain the r-process Enrichment in Globular Clusters? https://t.co/WcfOjV9HtM	2019/6/28 18:47	https://arxiv.org/abs/1906.11299	Can Neutron-Star Mergers Explain the r-process Enrichment in Globular Clusters?	"Star-to-star dispersion of r-process elements has been observed in asignificant number of old, metal-poor globular clusters. We investigateearly-time neutron-star mergers as the mechanism for this enrichment. We showthat neutron-star mergers cannot be induced through dynamical interactionsearly in the history of the cluster, even when the most liberal assumptionsabout neutron-star segregation are assumed. Therefore, if neutron-star mergersare the primary mechanism for r-process dispersion in globular clusters, theylikely result from the evolution of isolated, primordial binaries in theclusters. Through population modeling, we find that only models where asignificant number of double neutron-star progenitors undergo a phase of masstransfer involving a naked He-star donor give rise to enrichment fractions thatare comparable to the observed number of enriched globular clusters. Undervarious assumptions for the initial properties of globular clusters, we find ifthe secondary phase of mass transfer from a naked He-star donor proceeds stably(unstably), a neutron-star merger with the potential for enrichment will occurin ~2-12% (~4-25%) of globular clusters. The strong anti-correlation betweenthe pre-supernova orbital separation and post-supernova systemic velocity dueto mass loss in the supernova leads to efficient ejection of most enrichmentcandidates from their host clusters. Thus, most enrichment events occur shortlyafter the double neutron stars are born. This requires star-forming gas thatcan absorb the r-process ejecta to be present in the globular cluster 30-50 Myrafter the initial burst of star formation. If scenarios for redistributing gasin globular clusters cannot act on these timescales, the number of neutron-starmerger enrichment candidates drops severely, and it is likely that anothermechanism, such as r-process enrichment from collapsars, is at play."	High Energy Astrophysical Phenomena (astro-ph.HE)	Astrophysics of Galaxies (astro-ph.GA)
life_wont_wait	Q	"2,170"	57	そんなことホントにできるのかorできたんだという素直な驚き/A single fast radio burst localized to a massive galaxy at cosmological distance https://t.co/W2ovZa6AUl	2019/6/28 19:04	https://arxiv.org/abs/1906.11476	A single fast radio burst localized to a massive galaxy at cosmological distance	"Fast Radio Bursts (FRBs) are brief radio emissions from distant astronomicalsources. Some are known to repeat, but most are single bursts. Non-repeatingFRB observations have had insufficient positional accuracy to localize them toan individual host galaxy. We report the interferometric localization of thesingle pulse FRB 180924 to a position 4 kpc from the center of a luminousgalaxy at redshift 0.3214. The burst has not been observed to repeat. Theproperties of the burst and its host are markedly different from the only otheraccurately localized FRB source. The integrated electron column density alongthe line of sight closely matches models of the intergalactic medium,indicating that some FRBs are clean probes of the baryonic component of thecosmic web."	High Energy Astrophysical Phenomena (astro-ph.HE)	Cosmology and Nongalactic Astrophysics (astro-ph.CO)
qard_t	T-QARD channel	516	0	その二例とは  リクルートさんのアイテムリスト最適化 DENSOさんの工場内AGV運行最適化  です！  どちらもT-QARDの共同研究の成果です。数ある応用事例から取り上げられたことを光栄に思います。真にビジネス的価値を生む点が注目を集めています。  https://t.co/E6yvjjCI8N https://t.co/1zb4s8pylF https://t.co/ExaOJmhyoS https://t.co/4jXPRbMrcu	2019/6/28 19:09	"https://arxiv.org/abs/1903.12478, https://arxiv.org/abs/1812.01532"	"Item Listing Optimization for E-commerce Websites based on Diversity, Control of automated guided vehicles without collision by quantum annealer and digital devices"	"For e-commerce websites, deciding the manner in which items are listed onwebpages is an important issue because it can dramatically affect item sales.One of the simplest strategies of listing items to improve the overall sales isto do so in a descending order of sales or sales numbers. However, in listsgenerated using this strategy, items with high similarity are often placedconsecutively. In other words, the generated item list might be biased toward aspecific preference. Therefore, this study employs penalties for items withhigh similarity being placed next to each other in the list and transforms theitem listing problem to a quadratic assignment problem (QAP). The QAP iswell-known as an NP-hard problem that cannot be solved in polynomial time. Tosolve the QAP, we employ quantum annealing (QA), which exploits the quantumtunneling effect to efficiently solve an optimization problem. In addition, wepropose a problem decomposition method based on the structure of the itemlisting problem because the quantum annealer we use (i.e., D-Wave 2000Q) has alimited number of quantum bits. Our experimental results indicate that we cancreate an item list that considers both sales and diversity. In addition, weobserve that using the problem decomposition method based on a problemstructure can lead to a better solution with the quantum annealer in comparisonwith the existing problem decomposition method., We formulate an optimization problem to control a large number of automatedguided vehicles in a plant without collision. The formulation consists ofbinary variables. A quadratic cost function over these variables enables us toutilize certain solvers on digital computers and recently developedpurpose-specific hardware such as D-Wave 2000Q and the Fujitsu digitalannealer. In the present study, we consider an actual plant in Japan, in whichvehicles run, and assess efficiency of our formulation for optimizing thevehicles via several solvers. We confirm that our formulation can be a powerfulapproach for performing smooth control while avoiding collisions betweenvehicles, as compared to a conventional method. In addition, comparativeexperiments performed using several solvers reveal that D-Wave 2000Q can beuseful as a rapid solver for generating a plan for controlling the vehicles ina short time although it deals only with a small number of vehicles, while adigital computer can rapidly solve the corresponding optimization problem evenwith a large number of binary variables."	"Quantum Physics (quant-ph), Quantum Physics (quant-ph)"	"Optimization and Control (math.OC), Disordered Systems and Neural Networks (cond-mat.dis-nn);Multiagent Systems (cs.MA);Robotics (cs.RO);Systems and Control (eess.SY)"
cucumislily	jurilynn	116	185	実行時間も比較的速そうで良いな。ソースソードあるのかしら。 https://t.co/XDhK7LUvtJ	2019/6/28 19:27	https://arxiv.org/abs/1906.10313	DensePeds: Pedestrian Tracking in Dense Crowds Using Front-RVO and Sparse Features	"We present a pedestrian tracking algorithm, DensePeds, that tracksindividuals in highly dense crowds (greater than 2 pedestrians per squaremeter). Our approach is designed for videos captured from front-facing orelevated cameras. We present a new motion model called Front-RVO (FRVO) forpredicting pedestrian movements in dense situations using collision avoidanceconstraints and combine it with state-of-the-art Mask R-CNN to compute sparsefeature vectors that reduce the loss of pedestrian tracks (false negatives). Weevaluate DensePeds on the standard MOT benchmarks as well as a new dense crowddataset. In practice, our approach is 4.5 times faster than prior trackingalgorithms on the MOT benchmark and we are state-of-the-art in dense crowdvideos by over 2.6% on the absolute scale on average."	Robotics (cs.RO)	
yjmtsmt	(っ'-')? =????◯本	225	200	https://t.co/YBtuHypFKy Toroidal Diamond Anvil Cell で400 GPa over出したのすごそう	2019/6/28 19:32	https://arxiv.org/abs/1906.05634	Observation of a first order phase transition to metal hydrogen near 425 GPa	"Hydrogen has been the essential element in the development of atomic andmolecular physics1). Moving to the properties of dense hydrogen has appeared agood deal more complex than originally thought by Wigner and Hungtinton intheir seminal paper predicting metal hydrogen2): the electrons and the protonsare strongly coupled to each other and ultimately must be treated equally3)4).The determination of how and when molecular solid hydrogen will transform intoa metal is the stepping stone towards a full understanding of the quantum-manybody properties of dense hydrogen. The quest for metal hydrogen has pushedmajor developments of modern experimental high pressure physics, yet thevarious claims of its observation over the past 30 years have remainedcontroversial5)6)7). Here we show a first order phase transition near 425 GPafrom insulator molecular solid hydrogen to metal hydrogen. Pressure in excessof 400 GPa could be achieved by using the recently developed Toroidal DiamondAnvil Cell (T-DAC)8). The structural and electronic properties of dense solidhydrogen at 80 K have been characterized by synchrotron infrared spectroscopy.The continuous vibron frequency shift and the electronic band gap closure downto 0.5 eV, both linearly evolving with pressure, point to the stability of theinsulator C2/c-24 phase up to the metallic transition. Upon pressure release,the metallic state transforms back to the C2/c-24 phase with almost nohysteresis, hence suggesting that the metallization proceeds through astructural transformation within the molecular solid, presumably to the Cmca-12structure. Our results are in good agreement with the scenario recentlydisclosed by an advanced calculation able to capture many-body electroniccorrelations9)."	Materials Science (cond-mat.mtrl-sci)	
daikiyamanaka	daikiyamanaka	325	458	Voxblox++ きましたね https://t.co/76FNl8evru A volumetric object-level semantic mapping framework. https://t.co/60Iq4ypvvV	2019/6/28 20:03	https://arxiv.org/abs/1903.00268	Volumetric Instance-Aware Semantic Mapping and 3D Object Discovery	"To autonomously navigate and plan interactions in real-world environments,robots require the ability to robustly perceive and map complex, unstructuredsurrounding scenes. Besides building an internal representation of the observedscene geometry, the key insight toward a truly functional understanding of theenvironment is the usage of higher-level entities during mapping, such asindividual object instances. We propose an approach to incrementally buildvolumetric object-centric maps during online scanning with a localized RGB-Dcamera. First, a per-frame segmentation scheme combines an unsupervisedgeometric approach with instance-aware semantic object predictions. This allowsus to detect and segment elements both from the set of known classes and fromother, previously unseen categories. Next, a data association step tracks thepredicted instances across the different frames. Finally, a map integrationstrategy fuses information about their 3D shape, location, and, if available,semantic class into a global volume. Evaluation on a publicly available datasetshows that the proposed approach for building instance-level semantic maps iscompetitive with state-of-the-art methods, while additionally able to discoverobjects of unseen categories. The system is further evaluated within areal-world robotic mapping setup, for which qualitative results highlight theonline nature of the method."	Robotics (cs.RO)	
shion_honda	Shion Honda	"1,234"	242	"AtomNet [Wallach+, 2015] 3Dグリッド上に配置したタンパク質と小分子化合物の組に、3D-CNNを適用して活性を予測した。負例サンプリングに工夫があり、正例と記述子(分子量など)は近いが構造が似ていないものを不活性と仮定した。DUDE、ChEMBLなどで評価した。 https://t.co/ewsAVZoU7Z #NowReading https://t.co/RsBCqLebdd"	2019/6/28 20:17	https://arxiv.org/abs/1510.02855	AtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction in Structure-based Drug Discovery	"Deep convolutional neural networks comprise a subclass of deep neuralnetworks (DNN) with a constrained architecture that leverages the spatial andtemporal structure of the domain they model. Convolutional networks achieve thebest predictive performance in areas such as speech and image recognition byhierarchically composing simple local features into complex models. AlthoughDNNs have been used in drug discovery for QSAR and ligand-based bioactivitypredictions, none of these models have benefited from this powerfulconvolutional architecture. This paper introduces AtomNet, the firststructure-based, deep convolutional neural network designed to predict thebioactivity of small molecules for drug discovery applications. We demonstratehow to apply the convolutional concepts of feature locality and hierarchicalcomposition to the modeling of bioactivity and chemical interactions. Infurther contrast to existing DNN techniques, we show that AtomNet's applicationof local convolutional filters to structural target information successfullypredicts new active molecules for targets with no previously known modulators.Finally, we show that AtomNet outperforms previous docking approaches on adiverse set of benchmarks by a large margin, achieving an AUC greater than 0.9on 57.8% of the targets in the DUDE benchmark."	Machine Learning (cs.LG)	Neural and Evolutionary Computing (cs.NE);Biomolecules (q-bio.BM);Machine Learning (stat.ML)
tocom242242	tocom	57	62	【マルチエージェント深層強化学習】Value-Decomposition Networkについて 1706.05296.pdf https://t.co/XW33BEO1Ju	2019/6/28 20:29	https://arxiv.org/abs/1706.05296	Value-Decomposition Networks For Cooperative Multi-Agent Learning	"We study the problem of cooperative multi-agent reinforcement learning with asingle joint reward signal. This class of learning problems is difficultbecause of the often large combined action and observation spaces. In the fullycentralized and decentralized approaches, we find the problem of spuriousrewards and a phenomenon we call the ""lazy agent"" problem, which arises due topartial observability. We address these problems by training individual agentswith a novel value decomposition network architecture, which learns todecompose the team value function into agent-wise value functions. We performan experimental evaluation across a range of partially-observable multi-agentdomains and show that learning such value-decompositions leads to superiorresults, in particular when combined with weight sharing, role information andinformation channels."	Artificial Intelligence (cs.AI)	
esumii	Eijiro Sumii	"3,461"	"1,120"	https://t.co/8SXowpyJiS をよろしくお願いします！（想定お約束陽マ https://t.co/yzlln4vUE3	2019/6/28 21:04	https://arxiv.org/abs/1512.01898	A Simple and Practical Linear Algebra Library Interface with Static Size Checking	"Linear algebra is a major field of numerical computation and is widelyapplied. Most linear algebra libraries (in most programming languages) do notstatically guarantee consistency of the dimensions of vectors and matrices,causing runtime errors. While advanced type systems--specifically, dependenttypes on natural numbers--can ensure consistency among the sizes of collectionssuch as lists and arrays, such type systems generally require non-trivialchanges to existing languages and application programs, or tricky type-levelprogramming.We have developed a linear algebra library interface that verifies theconsistency (with respect to dimensions) of matrix operations by means ofgenerative phantom types, implemented via fairly standard ML types and modulesystem. To evaluate its usability, we ported to it a practical machine learninglibrary from a traditional linear algebra library. We found that most of thechanges required for the porting could be made mechanically, and changes thatneeded human thought are minor."	Programming Languages (cs.PL)	
candidusflumen	Toshihico　Shiracawa	"1,501"	"2,013"	「Machine Learning as Statistical Data Assimilation」 機械学習も統計的データ同化も深い所では、統計力学の問題だと主張している文書 → https://t.co/FlqABJJnLp	2019/6/28 21:57	https://arxiv.org/abs/1710.07276	Machine Learning as Statistical Data Assimilation	"We identify a strong equivalence between neural network based machinelearning (ML) methods and the formulation of statistical data assimilation(DA), known to be a problem in statistical physics. DA, as used widely inphysical and biological sciences, systematically transfers information inobservations to a model of the processes producing the observations. Thecorrespondence is that layer label in the ML setting is the analog of time inthe data assimilation setting. Utilizing aspects of this equivalence we discusshow to establish the global minimum of the cost functions in the ML context,using a variational annealing method from DA. This provides a design method foroptimal networks for ML applications and may serve as the basis forunderstanding the success of ""deep learning"". Results from an ML example arepresented.When the layer label is taken to be continuous, the Euler-Lagrange equationfor the ML optimization problem is an ordinary differential equation, and wesee that the problem being solved is a two point boundary value problem. Theuse of continuous layers is denoted ""deepest learning"". The Hamiltonian versionprovides a direct rationale for back propagation as a solution method for thecanonical momentum; however, it suggests other solution methods are to bepreferred."	Machine Learning (cs.LG)	Machine Learning (stat.ML)
rarara_brahmin	ブラフ	34	86	そしてワイはこいつを実装するんや…（まだよく分かってない）  https://t.co/PFTFfBxkXJ	2019/6/28 22:01	https://arxiv.org/abs/1804.02391	Learn To Pay Attention	"We propose an end-to-end-trainable attention module for convolutional neuralnetwork (CNN) architectures built for image classification. The module takes asinput the 2D feature vector maps which form the intermediate representations ofthe input image at different stages in the CNN pipeline, and outputs a 2Dmatrix of scores for each map. Standard CNN architectures are modified throughthe incorporation of this module, and trained under the constraint that aconvex combination of the intermediate 2D feature vectors, as parameterised bythe score matrices, must \textit{alone} be used for classification.Incentivised to amplify the relevant and suppress the irrelevant or misleading,the scores thus assume the role of attention values. Our experimentalobservations provide clear evidence to this effect: the learned attention mapsneatly highlight the regions of interest while suppressing background clutter.Consequently, the proposed function is able to bootstrap standard CNNarchitectures for the task of image classification, demonstrating superiorgeneralisation over 6 unseen benchmark datasets. When binarised, our attentionmaps outperform other CNN-based attention maps, traditional saliency maps, andtop object proposals for weakly supervised segmentation as demonstrated on theObject Discovery dataset. We also demonstrate improved robustness against thefast gradient sign method of adversarial attack."	Computer Vision and Pattern Recognition (cs.CV)	Artificial Intelligence (cs.AI)
SO880	ドラミギ	"1,319"	"1,302"	https://t.co/4t8rYR79Dc とりあえずφ(..)メモメモ	2019/6/28 22:11	https://arxiv.org/abs/0911.0087	Free Probability Theory	"Free probability theory was created by Dan Voiculescu around 1985, motivatedby his efforts to understand special classes of von Neumann algebras. Hisdiscovery in 1991 that also random matrices satisfy asymptotically the freenessrelation transformed the theory dramatically. Not only did this yieldspectacular results about the structure of operator algebras, but it alsobrought new concepts and tools into the realm of random matrix theory. In thefollowing we will give, mostly from the random matrix point of view, a surveyon some of the basic ideas and results of free probability theory."	Probability (math.PR)	Operator Algebras (math.OA)
deepchiji	D.C.	5	25	ちょっと前のこの論文にも、ImageNetタスクの精度に反比例して AlexNet &gt; VGG &gt; ResNet の順にテクスチャ耐性が強くなる(物の表面ではなくちゃんと全体的な形まで考慮して判断できるようになる)傾向があると書かれてあり、考えさせられた https://t.co/yViI8QKr7l https://t.co/VwKh7xlBu2	2019/6/29 0:12	https://arxiv.org/abs/1811.12231	ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness	"Convolutional Neural Networks (CNNs) are commonly thought to recogniseobjects by learning increasingly complex representations of object shapes. Somerecent studies suggest a more important role of image textures. We here putthese conflicting hypotheses to a quantitative test by evaluating CNNs andhuman observers on images with a texture-shape cue conflict. We show thatImageNet-trained CNNs are strongly biased towards recognising textures ratherthan shapes, which is in stark contrast to human behavioural evidence andreveals fundamentally different classification strategies. We then demonstratethat the same standard architecture (ResNet-50) that learns a texture-basedrepresentation on ImageNet is able to learn a shape-based representationinstead when trained on ""Stylized-ImageNet"", a stylized version of ImageNet.This provides a much better fit for human behavioural performance in ourwell-controlled psychophysical lab setting (nine experiments totalling 48,560psychophysical trials across 97 observers) and comes with a number ofunexpected emergent benefits such as improved object detection performance andpreviously unseen robustness towards a wide range of image distortions,highlighting advantages of a shape-based representation."	Computer Vision and Pattern Recognition (cs.CV)	Artificial Intelligence (cs.AI);Machine Learning (cs.LG);Neurons and Cognition (q-bio.NC);Machine Learning (stat.ML)
Seiki_KOMIYA	Seiki KOMIYA	53	231	そういや機械学習で超伝導体探索するのはT野さんもやってるって言ってたな。これかな。計算はT倉先生にかなり手伝ってもらってるんだろうか。https://t.co/390iEPmD3Y	2019/6/29 1:50	https://arxiv.org/abs/1902.09770	Data-driven Exploration of Pressure-Induced Superconductivity in AgIn$_{5}$Se$_{8}$	"Candidates compounds for new thermoelectric and superconducting materials,which have narrow band gap and flat bands near band edges, were exhaustivelysearched by a high-throughput first-principles calculation from an inorganicmaterials database named AtomWork. We focused on AgIn$_{5}$Se$_{8}$ which hashigh density of state near the Fermi level. AgIn$_{5}$Se$_{8}$ was successfullysynthesized as single crystals using a melt and slow cooling method. Thesingle-crystal X-ray diffraction analysis revealed the obtained crystal is highquality without deficiencies. The valence states in AgIn$_{5}$Se$_{8}$ weredetermined to be Ag1+, In3+ and Se2- in accordance with a formal charge by thecore level X-ray photoelectron spectroscopy analysis. The electrical resistancewas evaluated under high pressure using a diamond anvil cell with boron-dopeddiamond electrodes. Although the sample was insulator with a resistance ofabove 40 M{\Omega} at ambient pressure, the resistance markedly decreased withincrease of the pressure, and a pressure-induced superconducting transition wasdiscovered at 3.4 K under 52.5 GPa. The transition temperature increased up to3.7 K under further pressure of 74.0 GPa."	Superconductivity (cond-mat.supr-con)	
yasu00327	yasu	138	136	結局卒研は https://t.co/oFQhOLxIjY これもじって プリページングに適応させたらどうなるかやってみようと思う	2019/6/29 5:36	https://arxiv.org/abs/1803.02329	Learning Memory Access Patterns	"The explosion in workload complexity and the recent slow-down in Moore's lawscaling call for new approaches towards efficient computing. Researchers arenow beginning to use recent advances in machine learning in softwareoptimizations, augmenting or replacing traditional heuristics and datastructures. However, the space of machine learning for computer hardwarearchitecture is only lightly explored. In this paper, we demonstrate thepotential of deep learning to address the von Neumann bottleneck of memoryperformance. We focus on the critical problem of learning memory accesspatterns, with the goal of constructing accurate and efficient memoryprefetchers. We relate contemporary prefetching strategies to n-gram models innatural language processing, and show how recurrent neural networks can serveas a drop-in replacement. On a suite of challenging benchmark datasets, we findthat neural networks consistently demonstrate superior performance in terms ofprecision and recall. This work represents the first step towards practicalneural-network based prefetching, and opens a wide range of exciting directionsfor machine learning in computer architecture research."	Machine Learning (cs.LG)	Machine Learning (stat.ML)
ballforest	mat	"3,466"	"4,111"	論文 https://t.co/jV9oSingll	2019/6/29 10:19	https://arxiv.org/abs/1906.08977	Singing Voice Synthesis Using Deep Autoregressive Neural Networks for Acoustic Modeling	"This paper presents a method of using autoregressive neural networks for theacoustic modeling of singing voice synthesis (SVS). Singing voice differs fromspeech and it contains more local dynamic movements of acoustic features, e.g.,vibratos. Therefore, our method adopts deep autoregressive (DAR) models topredict the F0 and spectral features of singing voice in order to betterdescribe the dependencies among the acoustic features of consecutive frames.For F0 modeling, discretized F0 values are used and the influences of thehistory length in DAR are analyzed by experiments. An F0 post-processingstrategy is also designed to alleviate the inconsistency between the predictedF0 contours and the F0 values determined by music notes. Furthermore, we extendthe DAR model to deal with continuous spectral features, and a prenet modulewith self-attention layers is introduced to process historical frames.Experiments on a Chinese singing voice corpus demonstrate that our method usingDARs can produce F0 contours with vibratos effectively, and can achieve betterobjective and subjective performance than the conventional method usingrecurrent neural networks (RNNs)."	Sound (cs.SD)	Machine Learning (cs.LG);Audio and Speech Processing (eess.AS)
shunk031	しゅんけー	"1,701"	667	「Webを学ぶためにはまずSHAKAIとかSEKAIを学ぶ必要があるみたい」と研究室後輩が言ってたので、hardmaruさんのWorld Modelsを進める優しい研究室先輩になってしまった / [1803.10122] World Models https://t.co/DaUEsymFrh	2019/6/29 12:26	https://arxiv.org/abs/1803.10122	World Models	"We explore building generative neural network models of popular reinforcementlearning environments. Our world model can be trained quickly in anunsupervised manner to learn a compressed spatial and temporal representationof the environment. By using features extracted from the world model as inputsto an agent, we can train a very compact and simple policy that can solve therequired task. We can even train our agent entirely inside of its ownhallucinated dream generated by its world model, and transfer this policy backinto the actual environment.An interactive version of this paper is available atthis https URL"	Machine Learning (cs.LG)	Machine Learning (stat.ML)
691_7758337633	たけのこ赤軍@MSFロス	"1,930"	"1,911"	arXiv に上げたプレプリントです  https://t.co/rYurMkQ4Jk https://t.co/ZzqqNc9lCD	2019/6/29 13:23	"https://arxiv.org/abs/1905.08068, https://arxiv.org/abs/1906.00344"	"The $q$-multiple gamma functions of Barnes-Milnor type, Asymptotic Expansions for the multiple gamma functions of Barnes-Milnor type"	"The multiple gamma functions of BM (Barnes-Milnor) type and the $q$-multiplegamma functions have been studied independently. In this paper, we introduce anew generalization of the multiple gamma functions called the $q$-BM multiplegamma function including those functions and prove some properties the BMmultiple gamma functions satisfy for them., The classical Stirling's formula gives the asymptotic behavior of the gammafunction. Katayama and Ohtsuki generalized this formula for Barnes' multiplegamma functions. In this paper, we further generalize these formulas for themultiple gamma functions of BM (Barnes-Milnor) type."	"Number Theory (math.NT), Number Theory (math.NT)"	
grahamian2317	Grahamian@データ分析と機械学習	"1,413"	139	LIME完全に理解したいから読む https://t.co/oUgLUBEWZX	2019/6/29 14:19	https://arxiv.org/abs/1602.04938	"""Why Should I Trust You?"": Explaining the Predictions of Any Classifier"	"Despite widespread adoption, machine learning models remain mostly blackboxes. Understanding the reasons behind predictions is, however, quiteimportant in assessing trust, which is fundamental if one plans to take actionbased on a prediction, or when choosing whether to deploy a new model. Suchunderstanding also provides insights into the model, which can be used totransform an untrustworthy model or prediction into a trustworthy one. In thiswork, we propose LIME, a novel explanation technique that explains thepredictions of any classifier in an interpretable and faithful manner, bylearning an interpretable model locally around the prediction. We also proposea method to explain models by presenting representative individual predictionsand their explanations in a non-redundant way, framing the task as a submodularoptimization problem. We demonstrate the flexibility of these methods byexplaining different models for text (e.g. random forests) and imageclassification (e.g. neural networks). We show the utility of explanations vianovel experiments, both simulated and with human subjects, on various scenariosthat require trust: deciding if one should trust a prediction, choosing betweenmodels, improving an untrustworthy classifier, and identifying why a classifiershould not be trusted."	Machine Learning (cs.LG)	Artificial Intelligence (cs.AI);Machine Learning (stat.ML)
fluctuation326	AD	0	8	Concentration sensingにおいてMIMO問題を取り扱った。そこで、最尤推定法において対数尤度のヘッシアン行列の固有スペクトラムの性質が、Vandermonde行列の性質を備えていることを発見した。 https://t.co/a1SUf9524E	2019/6/29 17:53	https://arxiv.org/abs/1906.08881	Universal properties of concentration sensing in large ligand-receptor networks	"Cells estimate concentrations of chemical ligands in their environment usinga limited set of receptors. Recent work has shown that the temporal sequence ofbinding and unbinding events on just a single receptor can be used to estimatethe concentrations of multiple ligands. Here, for a network of many ligands andmany receptors, we show that such temporal sequences can be used to estimatethe concentration of a few times as many ligand species as there are receptors.Crucially, we show that the spectrum of the inverse covariance matrix of theseestimates has several universal properties, which we trace to properties ofVandermonde matrices. We argue that this can be used by cells in realisticbiochemical decoding networks."	Molecular Networks (q-bio.MN)	Biological Physics (physics.bio-ph)
tonagai	tomo	406	88	パンケーキの最適化論文のarXivはこちら。 Pancake making and surface coating: optimal control of a gravity-driven liquid film https://t.co/5FkDWgvdJc	2019/6/29 18:52	https://arxiv.org/abs/1901.06028	Pancake making and surface coating: optimal control of a gravity-driven liquid film	"This paper investigates the flow of a solidifying liquid film on a solidsurface subject to a complex kinematics, a process relevant to pancake makingand surface coating. The flow is modeled using the lubrication approximationwith a temperature-dependent viscosity and a gravity force whose magnitude anddirection depend on the time-dependent orientation of the surface. Because theflow eventually ceases as the liquid film solidifies, the key question thisstudy aims to address is: what is the optimal surface kinematics for spreadingthe liquid layer uniformly? Two methods are proposed to tackle this problem. Inthe first one, the surface kinematics is assumed a priori to be harmonic andparameterized. The optimal parameters are inferred using the Monte-Carlomethod. This ""brute-force"" approach leads to a moderate improvement of the filmuniformity compared to the reference case when no motion is imposed to thesurface. The second method is formulated as an optimal control problem,constrained by the governing partial differential equation, and solved with anadjoint equation. Key benefits of this method are that no assumption is made onthe form of the control, and that significant improvement in thicknessuniformity are achieved with a comparatively smaller number of evaluations ofthe objective function."	Fluid Dynamics (physics.flu-dyn)	
deltam	deltam?????♂???	520	738	"論文中で言及されてたのでTAOCPの4巻だけ衝動買いした。難易度高いとされてる問題を解決したらしい。 ""[1307.2549] Hamiltonicity of the Cayley Digraph on the Symmetric Group Generated by σ = (1 2 ... n) and τ = (1 2)"" https://t.co/aNfQscJeyT"	2019/6/29 20:51	https://arxiv.org/abs/1307.2549	Hamiltonicity of the Cayley Digraph on the Symmetric Group Generated by σ = (1 2 ... n) and τ = (1 2)	"The symmetric group is generated by {\sigma} = (1 2 ... n) and {\tau} = (12). We answer an open problem of Nijenhuis and Wilf by constructing a Hamiltonpath in the directed Cayley graph for all n, and a Hamilton cycle for odd n."	Combinatorics (math.CO)	
2StagePey	?????♂?じんぺちん	205	148	去年にも最高のピザの焼き方って論文が出たっけwww https://t.co/1GmCRq6dpB https://t.co/Ytxd38erSm	2019/6/29 22:40	https://arxiv.org/abs/1806.08790	The Physics of baking good Pizza	"Physical principles are involved in almost any aspect of cooking. Here weanalyze the specific process of baking pizzas, deriving in simple terms thebaking times for two different situations: For a brick oven in a pizzeria and amodern metallic oven at home. Our study is based on basic thermodynamicprinciples relevant to the cooking process and is accessible to undergraduatestudents. We start with a historical overview of the development and art ofpizza baking, illustrate the underlying physics by some simple common examples,and then apply them in detail to the example of baking pizza."	Popular Physics (physics.pop-ph)	
kazmuzik	Kaz Muzik	736	996	Transformer-XL https://t.co/KQndN7mVDc によって、BERTを超えたという噂のXLNet https://t.co/zRXG66hZBd のPythonの実装 https://t.co/McKw6O1QJ3 https://t.co/jKse9gORtu	2019/6/29 23:39	"https://arxiv.org/abs/1901.02860, https://arxiv.org/abs/1906.08237"	"Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context, XLNet: Generalized Autoregressive Pretraining for Language Understanding"	"Transformers have a potential of learning longer-term dependency, but arelimited by a fixed-length context in the setting of language modeling. Wepropose a novel neural architecture Transformer-XL that enables learningdependency beyond a fixed length without disrupting temporal coherence. Itconsists of a segment-level recurrence mechanism and a novel positionalencoding scheme. Our method not only enables capturing longer-term dependency,but also resolves the context fragmentation problem. As a result,Transformer-XL learns dependency that is 80% longer than RNNs and 450% longerthan vanilla Transformers, achieves better performance on both short and longsequences, and is up to 1,800+ times faster than vanilla Transformers duringevaluation. Notably, we improve the state-of-the-art results of bpc/perplexityto 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One BillionWord, and 54.5 on Penn Treebank (without finetuning). When trained only onWikiText-103, Transformer-XL manages to generate reasonably coherent, noveltext articles with thousands of tokens. Our code, pretrained models, andhyperparameters are available in both Tensorflow and PyTorch., With the capability of modeling bidirectional contexts, denoisingautoencoding based pretraining like BERT achieves better performance thanpretraining approaches based on autoregressive language modeling. However,relying on corrupting the input with masks, BERT neglects dependency betweenthe masked positions and suffers from a pretrain-finetune discrepancy. In lightof these pros and cons, we propose XLNet, a generalized autoregressivepretraining method that (1) enables learning bidirectional contexts bymaximizing the expected likelihood over all permutations of the factorizationorder and (2) overcomes the limitations of BERT thanks to its autoregressiveformulation. Furthermore, XLNet integrates ideas from Transformer-XL, thestate-of-the-art autoregressive model, into pretraining. Empirically, XLNetoutperforms BERT on 20 tasks, often by a large margin, and achievesstate-of-the-art results on 18 tasks including question answering, naturallanguage inference, sentiment analysis, and document ranking."	"Machine Learning (cs.LG), Computation and Language (cs.CL)"	"Computation and Language (cs.CL);Machine Learning (stat.ML), Machine Learning (cs.LG)"
daegon137	hsdk bd(炯淳)	"1,368"	"2,625"	最近見た中で一番面白い論文だな。「Magic: The Gathering is Turing Complete」https://t.co/hCIUYqH5X3	2019/6/29 23:53	https://arxiv.org/abs/1904.09828	Magic: The Gathering is Turing Complete	"$\textit{Magic: The Gathering}$ is a popular and famously complicated tradingcard game about magical combat. In this paper we show that optimal play inreal-world $\textit{Magic}$ is at least as hard as the Halting Problem, solvinga problem that has been open for a decade. To do this, we present a methodologyfor embedding an arbitrary Turing machine into a game of $\textit{Magic}$ suchthat the first player is guaranteed to win the game if and only if the Turingmachine halts. Our result applies to how real $\textit{Magic}$ is played, canbe achieved using standard-size tournament-legal decks, and does not rely onstochasticity or hidden information. Our result is also highly unusual in thatall moves of both players are forced in the construction. This shows that evenrecognising who will win a game in which neither player has a non-trivialdecision to make for the rest of the game is undecidable. We conclude with adiscussion of the implications for a unified computational theory of games andremarks about the playability of such a board in a tournament setting."	Artificial Intelligence (cs.AI)	Computational Complexity (cs.CC);Logic in Computer Science (cs.LO)
691_7758337633	たけのこ赤軍@MSFロス	"1,930"	"1,911"	@NegeLon あれ読んでないんですか？？？絶対に読むべきですこの論文はマジで頭おかしい最高  https://t.co/xHWlN6MTEM	2019/6/30 1:28	https://arxiv.org/abs/1806.04679	A new proof of the duality of multiple zeta values and its generalizations	"We give a new proof of the duality of multiple zeta values, which makes nouse of the iterated integrals. The same method is also applicable to Ohno'srelation for ($q$-)multiple zeta values."	Number Theory (math.NT)	
YamanamiBooks	やまなみ書房	141	152	Phys. Rev. Fluid に掲載された論文はこちら。 https://t.co/KQlDHY9RLy arXivにも上げられています。 https://t.co/S2eCKIVKG6  https://t.co/CCrQSNBaD5	2019/6/30 2:30	https://arxiv.org/abs/1901.06028	Pancake making and surface coating: optimal control of a gravity-driven liquid film	"This paper investigates the flow of a solidifying liquid film on a solidsurface subject to a complex kinematics, a process relevant to pancake makingand surface coating. The flow is modeled using the lubrication approximationwith a temperature-dependent viscosity and a gravity force whose magnitude anddirection depend on the time-dependent orientation of the surface. Because theflow eventually ceases as the liquid film solidifies, the key question thisstudy aims to address is: what is the optimal surface kinematics for spreadingthe liquid layer uniformly? Two methods are proposed to tackle this problem. Inthe first one, the surface kinematics is assumed a priori to be harmonic andparameterized. The optimal parameters are inferred using the Monte-Carlomethod. This ""brute-force"" approach leads to a moderate improvement of the filmuniformity compared to the reference case when no motion is imposed to thesurface. The second method is formulated as an optimal control problem,constrained by the governing partial differential equation, and solved with anadjoint equation. Key benefits of this method are that no assumption is made onthe form of the control, and that significant improvement in thicknessuniformity are achieved with a comparatively smaller number of evaluations ofthe objective function."	Fluid Dynamics (physics.flu-dyn)	
amasawa_seiji	ぬん。	"1,027"	467	論文はこちら。 ⇒/[1901.06028] Pancake making and surface coating: optimal control of a gravity-driven liquid film https://t.co/LssnBOJTfp	2019/6/30 2:42	https://arxiv.org/abs/1901.06028	Pancake making and surface coating: optimal control of a gravity-driven liquid film	"This paper investigates the flow of a solidifying liquid film on a solidsurface subject to a complex kinematics, a process relevant to pancake makingand surface coating. The flow is modeled using the lubrication approximationwith a temperature-dependent viscosity and a gravity force whose magnitude anddirection depend on the time-dependent orientation of the surface. Because theflow eventually ceases as the liquid film solidifies, the key question thisstudy aims to address is: what is the optimal surface kinematics for spreadingthe liquid layer uniformly? Two methods are proposed to tackle this problem. Inthe first one, the surface kinematics is assumed a priori to be harmonic andparameterized. The optimal parameters are inferred using the Monte-Carlomethod. This ""brute-force"" approach leads to a moderate improvement of the filmuniformity compared to the reference case when no motion is imposed to thesurface. The second method is formulated as an optimal control problem,constrained by the governing partial differential equation, and solved with anadjoint equation. Key benefits of this method are that no assumption is made onthe form of the control, and that significant improvement in thicknessuniformity are achieved with a comparatively smaller number of evaluations ofthe objective function."	Fluid Dynamics (physics.flu-dyn)	
q9ac	將籠林檎 / ??	278	228	ある断熱的な過程を考えたときそれに付随する幾何学的位相というものがあることはよく知られているが、その断熱過程をロスのある過程にしてみるという設定幾何学的位相を複素数にするとうまく説明できるらしい。 https://t.co/YT8yodCxCI	2019/6/30 7:13	https://arxiv.org/abs/1906.06404	Geometric decoherence in diffusive open quantum systems	"Based on a generic quantum open system model, we study the geometric natureof decoherence by defining a complex-valued geometric phase through stochasticpure states describing non-unitary, non-cyclic and non-adiabatic evolutions.The ensemble average of the complex geometric phases for the pure stochasticstates yields a conventional geometric phase together with an amplitude factor.We show that the decoherence process described by the decaying amplitude can bea geometric quantity independent of the system's dynamics. It is a remarkablefact that the geometric phase of a quantum system can serve as an idealrealisation of quantum gates due to its robustness against dynamical errors,however, in this paper we show that, for some open quantum systems, a desirablegeometric phase may be accompanied by an unwanted robust geometric decoherencefactor. Two exactly solvable models are studied to demonstrate that, while thedecoherence is a purely dynamical effect for a dephasing two-level model, thedecoherence in a dissipative two-level model can be a geometric process.Finally, we show that such a geometric decoherence effect may be eliminated bya non-perturbative control scheme."	Quantum Physics (quant-ph)	
q9ac	將籠林檎 / ??	278	228	カシミール効果は、ミラーに挟まれた真空というセットアップで電磁場の揺らぎを考えることで出てくるミラー間の引力相互作用だが、この真空の部分を電解質(液体)に置き換えてみたらどうなる？という試行。非局所応答があったりイオンがあるおかげで縦モードの寄与がでてくる。 https://t.co/IWHVJCuNVt	2019/6/30 7:17	https://arxiv.org/abs/1906.06395	Scattering theory of the screened Casimir interaction in electrolytes	"We apply the scattering approach to the Casimir interaction between twodielectric half-spaces separated by an electrolyte solution. We take thenonlocal electromagnetic response of the intervening medium into account, whichresults from the presence of movable ions in solution. In addition to the usualtransverse modes, we consider longitudinal channels and their coupling byreflection at the surface of the local dielectric. The Casimir interactionenergy is calculated from the matrix describing a round-trip of coupledtransverse and longitudinal waves between the interacting surfaces. Thenonzero-frequency contributions are approximately unaffected by the presence ofions. We find, at zero frequency, a contribution from longitudinal channels,which is screened over a distance of the order of the Debye length, alongsidean unscreened term arising from transverse-magnetic modes. The latter definesthe long-distance asymptotic limit for the interaction."	Mesoscale and Nanoscale Physics (cond-mat.mes-hall)	Quantum Physics (quant-ph)
q9ac	將籠林檎 / ??	278	228	量子論における時間の矢の問題。コヒーレント状態のエントロピーが時間とともに増大していくことを示している⇔時間には向きがある https://t.co/pVBTRfK5ha	2019/6/30 7:24	https://arxiv.org/abs/1906.11712	A Theory for Time Arrow	"Physical laws for elementary particles can be described by the quantumdynamics equation given a Hamiltonian. The solution are probability amplitudesin Hilbert space that evolve over time. A probability density function overposition and time is given as the magnitude square of such probabilityamplitude. An entropy can be associated with these probability densitiescharacterizing the position information of a particle. Coherent states arelocalized wave packets and may describe the spatial distribution for someparticle states. We show that due to a dispersion property of Hamiltonians inquantum physics, the entropy of coherent states increases over time. Weinvestigate a partition of the Hilbert space into four sets based on whetherthe entropy is (i) increasing but not constant, (ii) decreasing but notconstant, (iii) constant, (iv) oscillating.We then postulate that quantum theory of elementary particles is equippedwith a law that entropy (weakly) increases in time and thus states in set (ii)are disallowed, and the states in set (iii) can not complete an oscillationperiod. There is a key role of the conjugate process transforming states thatare allowed into states that are not, and vice-versa.Then, according to this law, quantum theory is not time reversible unless thestate is in the partition (iii), e.g., stationary states (eigentstates of theHamiltonian). This law in quantum theory limits physical scenarios beyondconservation laws, providing causality reasoning by defining an arrow of time."	Quantum Physics (quant-ph)	
q9ac	將籠林檎 / ??	278	228	時空上に螺旋転位がある系のディラック場とそれを回転させた時の振る舞いの解析。  時空上の螺旋転位(・ω・ )!そんなのあるんだなあ https://t.co/ZvfAQrH4X4	2019/6/30 7:32	https://arxiv.org/abs/1906.10995	Topological and rotating effects on the Dirac field in the spiral dislocation spacetime	"By considering a spacetime with a spiral dislocation, we analyse thebehaviour of the Dirac field subject to a hard-wall confining potential. Insearch of relativistic bound states solutions, we discuss the influence of thetopology of the spiral dislocation spacetime on the energy levels. Further, weanalyse the effects of rotation on the Dirac field in the spiral dislocationspacetime. We show that both rotation and the topology of the spacetime imposea restriction on the values of the radial coordinate. Thus, we analyse theeffects of rotation and the topology of the spiral dislocation spacetime on theDirac field subject to a hard-wall confining potential by searching forrelativistic bound states solutions."	Quantum Physics (quant-ph)	General Relativity and Quantum Cosmology (gr-qc)
q9ac	將籠林檎 / ??	278	228	半無限のバルクに詰まったディラック場と電磁場の相互作用。トポロジカル物質と電磁場の相互作用の解析にお役立ちらしい。 https://t.co/T1SiAKct18	2019/6/30 7:37	https://arxiv.org/abs/1906.06704	Quantum Dirac fermions in half space and their interaction with electromagnetic field	"We study the polarization tensor of a Dirac field in $(3+1)$ dimensionsconfined to a half space -- a problem motivated by applications to thecondensed matter physics, and to Topological Insulators in particular. Althoughthe Pauli-Villars regularization scheme has a number of advantages, likeexplicit gauge invariance and decoupling of heavy modes, it is not applicableon manifolds with boundaries. Here, we modify this scheme by giving an axialmass to the regulators and to the physical field. We compute the renormalizedpolarization tensor in coordinate representation. We discuss then the inducedChern-Simons type action on the boundary and compare it to the effective actionof a $(2+1)$ dimensional Dirac fermion."	High Energy Physics - Theory (hep-th)	Mesoscale and Nanoscale Physics (cond-mat.mes-hall);Mathematical Physics (math-ph)
q9ac	將籠林檎 / ??	278	228	二枚のグラフェンがカーボンナノチューブで繋がってる「ワームホール」みたいな不思議な物質を考えている。ワームホールがあるとランダウ量子化みたいなことが起こるらしい。 https://t.co/Yzfj0MDNgb	2019/6/30 7:58	https://arxiv.org/abs/1906.09195	Graphene wormhole trapped by external magnetic field	In this work we study the behavior of massless fermions in a graphenewormhole and in the presence of an external magnetic field. The graphenewormhole is made from two sheets of graphene that play the roles ofasymptotically flat spaces connected through a carbon nanotube with a zig-zagboundary. We solve the massless Dirac equation in this geometry and analyze itswave function. We show that the energy spectra of these solutions exhibitsimilar behavior to Landau levels.	High Energy Physics - Theory (hep-th)	Mesoscale and Nanoscale Physics (cond-mat.mes-hall)
TsuguoMogami	mogami290	12	10	置換対称性のある集合を出力とするNNをどう作るかは前々から問題だった。 https://t.co/y4OeDu7jpM を私の言葉でぶっちゃければ、多対1で自然に表現できる集合→内部表現の逆関数として、1対多の関数を定義すれば集合を出力できるということ。境界に現れる不連続と置換対称性はソルバに押し付ける。	2019/6/30 11:31	https://arxiv.org/abs/1906.06565	Deep Set Prediction Networks	"We study the problem of predicting a set from a feature vector with a deepneural network. Existing approaches ignore the set structure of the problem andsuffer from discontinuity issues as a result. We propose a general model forpredicting sets that properly respects the structure of sets and avoids thisproblem. With a single feature vector as input, we show that our model is ableto auto-encode point sets, predict bounding boxes of the set of objects in animage, and predict the attributes of these objects in an image."	Machine Learning (cs.LG)	Machine Learning (stat.ML)
toshiki_recruit	たかはしとしき@リクルート	200	390	お https://t.co/I88upzMK6f	2019/6/30 12:19	https://arxiv.org/abs/1903.12478	Item Listing Optimization for E-commerce Websites based on Diversity	"For e-commerce websites, deciding the manner in which items are listed onwebpages is an important issue because it can dramatically affect item sales.One of the simplest strategies of listing items to improve the overall sales isto do so in a descending order of sales or sales numbers. However, in listsgenerated using this strategy, items with high similarity are often placedconsecutively. In other words, the generated item list might be biased toward aspecific preference. Therefore, this study employs penalties for items withhigh similarity being placed next to each other in the list and transforms theitem listing problem to a quadratic assignment problem (QAP). The QAP iswell-known as an NP-hard problem that cannot be solved in polynomial time. Tosolve the QAP, we employ quantum annealing (QA), which exploits the quantumtunneling effect to efficiently solve an optimization problem. In addition, wepropose a problem decomposition method based on the structure of the itemlisting problem because the quantum annealer we use (i.e., D-Wave 2000Q) has alimited number of quantum bits. Our experimental results indicate that we cancreate an item list that considers both sales and diversity. In addition, weobserve that using the problem decomposition method based on a problemstructure can lead to a better solution with the quantum annealer in comparisonwith the existing problem decomposition method."	Quantum Physics (quant-ph)	Optimization and Control (math.OC)
u_vi58	まむ	609	349	一方で、もしブラックボックス関数の入力空間が1次元ならば、ICML2018にhttps://t.co/WwyfgI6tWsが出ていて、タイトなcumulative regret boundを達成するアルゴリズムが得られていることが分かって面白い。	2019/6/30 12:22	https://arxiv.org/abs/1805.11792	Tight Regret Bounds for Bayesian Optimization in One Dimension	"We consider the problem of Bayesian optimization (BO) in one dimension, undera Gaussian process prior and Gaussian sampling noise. We provide a theoreticalanalysis showing that, under fairly mild technical assumptions on the kernel,the best possible cumulative regret up to time $T$ behaves as$\Omega(\sqrt{T})$ and $O(\sqrt{T\log T})$. This gives a tight characterizationup to a $\sqrt{\log T}$ factor, and includes the first non-trivial lower boundfor noisy BO. Our assumptions are satisfied, for example, by the squaredexponential and Mat?rn-$\nu$ kernels, with the latter requiring $\nu > 2$.Our results certify the near-optimality of existing bounds (Srinivas {\em etal.}, 2009) for the SE kernel, while proving them to be strictly suboptimal forthe Mat?rn kernel with $\nu > 2$."	Machine Learning (stat.ML)	Information Theory (cs.IT);Machine Learning (cs.LG);Optimization and Control (math.OC)
subarusatosi	中嶋慧	"3,333"	23	量子開放系のBerry位相に興味がある人は、私のD論 https://t.co/OYjL51WnSg や https://t.co/SYFiIZQKwl が面白いと感じるかも知れません。	2019/6/30 12:45	https://arxiv.org/abs/1609.06167	Gauge freedom in observables and Landsbergs nonadiabatic geometric phase: pumping spectroscopy of interacting open quantum systems	"We set up a general density-operator approach to geometric steady-statepumping through slowly driven open quantum systems. This approach applies tostrongly interacting systems that are weakly coupled to multiple reservoirs athigh temperature, illustrated by an Anderson quantum dot, but shows potentialfor generalization. Pumping gives rise to a nonadiabatic geometric phase thatcan be described by a framework originally developed for classical dissipativesystems by Landsberg. This geometric phase is accumulated by the transportedobservable (charge, spin, energy) and not by the quantum state. It thus differsradically from the adiabatic Berry-Simon phase, even when generalizing it tomixed states, following Sarandy and Lidar. Importantly, our geometricformulation of pumping stays close to a direct physical intuition (i) by tyinggauge transformations to calibration of the meter registering the transportedobservable and (ii) by deriving a geometric connection from a driving-frequencyexpansion of the current. Our approach provides a systematic and efficient wayto compute the geometric pumping of various observables, including charge,spin, energy and heat. Our geometric curvature formula reveals a generalexperimental scheme for performing geometric transport spectroscopy thatenhances standard nonlinear spectroscopies based on measurements for staticparameters. We indicate measurement strategies for separating the usefulgeometric pumping contribution to transport from nongeometric effects. Finally,we highlight several advantages of our approach in an exhaustive comparisonwith the Sinitsyn-Nemenmann full-counting statistics (FCS) approach togeometric pumping of an observable`s first moment. We explain how in the FCSapproach an ""adiabatic"" approximation leads to a manifestly nonadiabatic resultinvolving a finite retardation time of the response to parameter driving."	Mesoscale and Nanoscale Physics (cond-mat.mes-hall)	Quantum Physics (quant-ph)
yu4u	Yusuke Uchida	"4,447"	950	同じようにNASを4 hoursでできると言っているこの論文、4 hoursとは言ったがGPU hoursとは言っていない（TPUv2）のが利根川っぽくて良い / Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4 Hours https://t.co/vBBADsvHB0 #cvsaisentan	2019/6/30 14:50	https://arxiv.org/abs/1904.02877	Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4 Hours	"Can we automatically design a Convolutional Network (ConvNet) with thehighest image classification accuracy under the runtime constraint of a mobiledevice? Neural architecture search (NAS) has revolutionized the design ofhardware-efficient ConvNets by automating this process. However, the NASproblem remains challenging due to the combinatorially large design space,causing a significant searching time (at least 200 GPU-hours). To alleviatethis complexity, we propose Single-Path NAS, a novel differentiable NAS methodfor designing hardware-efficient ConvNets in less than 4 hours. Ourcontributions are as follows: 1. Single-path search space: Compared to previousdifferentiable NAS methods, Single-Path NAS uses one single-pathover-parameterized ConvNet to encode all architectural decisions with sharedconvolutional kernel parameters, hence drastically decreasing the number oftrainable parameters and the search cost down to few epochs. 2.Hardware-efficient ImageNet classification: Single-Path NAS achieves 74.96%top-1 accuracy on ImageNet with 79ms latency on a Pixel 1 phone, which isstate-of-the-art accuracy compared to NAS methods with similar constraints(<80ms). 3. NAS efficiency: Single-Path NAS search cost is only 8 epochs (30TPU-hours), which is up to 5,000x faster compared to prior work. 4.Reproducibility: Unlike all recent mobile-efficient NAS methods which onlyrelease pretrained models, we open-source our entire codebase at:this https URL."	Machine Learning (cs.LG)	Computer Vision and Pattern Recognition (cs.CV);Machine Learning (stat.ML)
syao_ming	しゃをみん	281	108	少し前のGANSynthみたいに、位相推定を正しくできれば、時間周波数域上で高音質の音声合成ができますよという話。STFTについての論考が助かる・・・しかし、時間域信号の直接生成もそこそこ成功しているのに(WaveNet)、未だに位相推定はうまくいかないんだなぁ・・・ https://t.co/JqYuaRoKhR	2019/6/30 14:55	https://arxiv.org/abs/1902.04072	Adversarial Generation of Time-Frequency Features with application in audio synthesis	"Time-frequency (TF) representations provide powerful and intuitive featuresfor the analysis of time series such as audio. But still, generative modelingof audio in the TF domain is a subtle matter. Consequently, neural audiosynthesis widely relies on directly modeling the waveform and previous attemptsat unconditionally synthesizing audio from neurally generated invertible TFfeatures still struggle to produce audio at satisfying quality. In thisarticle, focusing on the short-time Fourier transform, we discuss thechallenges that arise in audio synthesis based on generated invertible TFfeatures and how to overcome them. We demonstrate the potential of deliberategenerative TF modeling by training a generative adversarial network (GAN) onshort-time Fourier features. We show that by applying our guidelines, ourTF-based network was able to outperform a state-of-the-art GAN generatingwaveforms directly, despite the similar architecture in the two networks."	Sound (cs.SD)	Machine Learning (cs.LG);Audio and Speech Processing (eess.AS);Machine Learning (stat.ML)
esXFdfOJxiGBFLx	人工知能 Deep Learning AI image medical machine learni	858	"1,901"	学習しやすい画像を生成する方法に関するGAN論文です。 これは今後、どのようなポイントが画像の認識に重要かがわかるかもしれません。 医療では癌などの診断根拠になるような画像特徴を導ける可能性があります。 https://t.co/PCUJuhlPBA	2019/6/30 16:58	https://arxiv.org/abs/1906.10112	GANalyze: Toward Visual Definitions of Cognitive Image Properties	"We introduce a framework that uses Generative Adversarial Networks (GANs) tostudy cognitive properties like memorability, aesthetics, and emotionalvalence. These attributes are of interest because we do not have a concretevisual definition of what they entail. What does it look like for a dog to bemore or less memorable? GANs allow us to generate a manifold of natural-lookingimages with fine-grained differences in their visual attributes. By navigatingthis manifold in directions that increase memorability, we can visualize whatit looks like for a particular generated image to become more or lessmemorable. The resulting ``visual definitions"" surface image properties (like``object size"") that may underlie memorability. Through behavioral experiments,we verify that our method indeed discovers image manipulations that causallyaffect human memory performance. We further demonstrate that the same frameworkcan be used to analyze image aesthetics and emotional valence. Visit theGANalyze website at this http URL."	Computer Vision and Pattern Recognition (cs.CV)	
akihiro_akichan	akihiro_f	122	118	https://t.co/dUqP0WZqSi CVPR2019.複数の物体を教師なしで追跡できるRATを提案。検出結果から画像を再構成してロスをとる機構、追跡の被りを防ぐためにFCNで抽出した特徴量ベクトルから１つ物体を検出するたびにメモリの更新(消去)をする機構がポイントか。教師なしでこれは凄いのではなかろうか。	2019/6/30 17:11	https://arxiv.org/abs/1809.03137	Tracking by Animation: Unsupervised Learning of Multi-Object Attentive Trackers	"Online Multi-Object Tracking (MOT) from videos is a challenging computervision task which has been extensively studied for decades. Most of theexisting MOT algorithms are based on the Tracking-by-Detection (TBD) paradigmcombined with popular machine learning approaches which largely reduce thehuman effort to tune algorithm parameters. However, the commonly usedsupervised learning approaches require the labeled data (e.g., bounding boxes),which is expensive for videos. Also, the TBD framework is usually suboptimalsince it is not end-to-end, i.e., it considers the task as detection andtracking, but not jointly. To achieve both label-free and end-to-end learningof MOT, we propose a Tracking-by-Animation framework, where a differentiableneural model first tracks objects from input frames and then animates theseobjects into reconstructed frames. Learning is then driven by thereconstruction error through backpropagation. We further propose aReprioritized Attentive Tracking to improve the robustness of data association.Experiments conducted on both synthetic and real video datasets show thepotential of the proposed model. Our project page is publicly available at:this https URL"	Computer Vision and Pattern Recognition (cs.CV)	Machine Learning (cs.LG);Machine Learning (stat.ML)
mesh1bot	ぼっと@27	110	115	https://t.co/sBTPR2SSbH  これ一回はちゃんと読むべきだと思うんだよなー英語に強くなりたい・・	2019/6/30 17:25	https://arxiv.org/abs/1611.08050	Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields	"We present an approach to efficiently detect the 2D pose of multiple peoplein an image. The approach uses a nonparametric representation, which we referto as Part Affinity Fields (PAFs), to learn to associate body parts withindividuals in the image. The architecture encodes global context, allowing agreedy bottom-up parsing step that maintains high accuracy while achievingrealtime performance, irrespective of the number of people in the image. Thearchitecture is designed to jointly learn part locations and their associationvia two branches of the same sequential prediction process. Our method placedfirst in the inaugural COCO 2016 keypoints challenge, and significantly exceedsthe previous state-of-the-art result on the MPII Multi-Person benchmark, bothin performance and efficiency."	Computer Vision and Pattern Recognition (cs.CV)	
KSKSKSKS2	katsugeneration	177	444	2D画像を既存の3DモデルにマッチングさせるVisual Localizationのタスクで、階層的なニューラルネットモデルを使用することにより、頑健性と計算速度を両立させた手法を提案。GPU使用で20FPS出すことができる https://t.co/TnHl0WGHeg	2019/6/30 17:36	https://arxiv.org/abs/1812.03506	From Coarse to Fine: Robust Hierarchical Localization at Large Scale	"Robust and accurate visual localization is a fundamental capability fornumerous applications, such as autonomous driving, mobile robotics, oraugmented reality. It remains, however, a challenging task, particularly forlarge-scale environments and in presence of significant appearance changes.State-of-the-art methods not only struggle with such scenarios, but are oftentoo resource intensive for certain real-time applications. In this paper wepropose HF-Net, a hierarchical localization approach based on a monolithic CNNthat simultaneously predicts local features and global descriptors for accurate6-DoF localization. We exploit the coarse-to-fine localization paradigm: wefirst perform a global retrieval to obtain location hypotheses and only latermatch local features within those candidate places. This hierarchical approachincurs significant runtime savings and makes our system suitable for real-timeoperation. By leveraging learned descriptors, our method achieves remarkablelocalization robustness across large variations of appearance and sets a newstate-of-the-art on two challenging benchmarks for large-scale localization."	Computer Vision and Pattern Recognition (cs.CV)	
Ab_ten	Ab.	60	36	https://t.co/Ql87Nnxj4u mixup: Beyond Empirical Risk Minimization に GAN の学習を stabilize するって書かれとったー。ちゃんと読まねば。	2019/6/30 17:57	https://arxiv.org/abs/1710.09412	mixup: Beyond Empirical Risk Minimization	"Large deep neural networks are powerful, but exhibit undesirable behaviorssuch as memorization and sensitivity to adversarial examples. In this work, wepropose mixup, a simple learning principle to alleviate these issues. Inessence, mixup trains a neural network on convex combinations of pairs ofexamples and their labels. By doing so, mixup regularizes the neural network tofavor simple linear behavior in-between training examples. Our experiments onthe ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets showthat mixup improves the generalization of state-of-the-art neural networkarchitectures. We also find that mixup reduces the memorization of corruptlabels, increases the robustness to adversarial examples, and stabilizes thetraining of generative adversarial networks."	Machine Learning (cs.LG)	Machine Learning (stat.ML)
KSKSKSKS2	katsugeneration	177	444	音声および映像を元にした質問応答のタスクで、マルチモーダルなアテンションを利用したシンプルなモデルで、既存手法をCIDErで20ポイント上回る手法を提案 https://t.co/5mtnOrlCGO	2019/6/30 18:45	https://arxiv.org/abs/1904.05876	A Simple Baseline for Audio-Visual Scene-Aware Dialog	"The recently proposed audio-visual scene-aware dialog task paves the way to amore data-driven way of learning virtual assistants, smart speakers and carnavigation systems. However, very little is known to date about how toeffectively extract meaningful information from a plethora of sensors thatpound the computational engine of those devices. Therefore, in this paper, weprovide and carefully analyze a simple baseline for audio-visual scene-awaredialog which is trained end-to-end. Our method differentiates in a data-drivenmanner useful signals from distracting ones using an attention mechanism. Weevaluate the proposed approach on the recently introduced and challengingaudio-visual scene-aware dataset, and demonstrate the key features that permitto outperform the current state-of-the-art by more than 20\% on CIDEr."	Computer Vision and Pattern Recognition (cs.CV)	Artificial Intelligence (cs.AI);Computation and Language (cs.CL);Machine Learning (cs.LG);Sound (cs.SD);Audio and Speech Processing (eess.AS)
KSKSKSKS2	katsugeneration	177	444	ビデオについてのキャプションを生成するタスクにおいて、映像情報を時間方向の変化や物体検出やアクション認識の結果を利用してエンコードするEnriched VisualEncodingという新しい手法を提案。MSVDなどのベンチマークで既存手法を上回る結果を示した。 https://t.co/dmsfNFClJR	2019/6/30 19:55	https://arxiv.org/abs/1902.10322	Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning	"Automatic generation of video captions is a fundamental challenge in computervision. Recent techniques typically employ a combination of ConvolutionalNeural Networks (CNNs) and Recursive Neural Networks (RNNs) for videocaptioning. These methods mainly focus on tailoring sequence learning throughRNNs for better caption generation, whereas off-the-shelf visual features areborrowed from CNNs. We argue that careful designing of visual features for thistask is equally important, and present a visual feature encoding technique togenerate semantically rich captions using Gated Recurrent Units (GRUs). Ourmethod embeds rich temporal dynamics in visual features by hierarchicallyapplying Short Fourier Transform to CNN features of the whole video. Itadditionally derives high level semantics from an object detector to enrich therepresentation with spatial dynamics of the detected objects. The finalrepresentation is projected to a compact space and fed to a language model. Bylearning a relatively simple language model comprising two GRU layers, weestablish new state-of-the-art on MSVD and MSR-VTT datasets for METEOR andROUGE_L metrics."	Computer Vision and Pattern Recognition (cs.CV)	
candidusflumen	Toshihico　Shiracawa	"1,501"	"2,013"	「A theory of quantum gravity based on quantum computation」 量子計算に基づき重力と量子力学を統一しようという話だ。今流行りの研究のように見えるが、元々2005年に初稿が上げられ、このバージョンは2018年のものだ。結構古い時期に量子情報と重力の関連に注目している https://t.co/WzNtoaNt83	2019/6/30 21:40	https://arxiv.org/abs/quant-ph/0501135	[quant-ph/0501135] A theory of quantum gravity based on quantum computation	"This paper proposes a method of unifying quantum mechanics and gravity basedon quantum computation. In this theory, fundamental processes are described interms of pairwise interactions between quantum degrees of freedom. The geometryof space-time is a construct, derived from the underlying quantum informationprocessing. The computation gives rise to a superposition of four-dimensionalspacetimes, each of which obeys the Einstein-Regge equations. The theory makesexplicit predictions for the back-reaction of the metric to computational`matter,' black-hole evaporation, holography, and quantum cosmology."	Quantum Physics (quant-ph)	General Relativity and Quantum Cosmology (gr-qc)
candidusflumen	Toshihico　Shiracawa	"1,501"	"2,013"	「Quantum Computation as Gravity」 情報理論も重力の理論も幾何学で扱えるので、幾何学的観点から統一しようという試みのようだ → https://t.co/c2RKlieNOH	2019/6/30 21:55	https://arxiv.org/abs/1807.04422	Quantum Computation as Gravity	"We formulate Nielsen's geometric approach to complexity in the context of twodimensional conformal field theories, where series of conformal transformationsare interpreted as unitary circuits. We show that the complexity functional canbe written as the Polyakov action of two dimensional gravity or, equivalently,as the geometric action on the coadjoint orbits of the Virasoro group. Thisway, we argue that gravity sets the rules for optimal quantum computation inconformal field theories."	High Energy Physics - Theory (hep-th)	Quantum Physics (quant-ph)
KSKSKSKS2	katsugeneration	177	444	画像とその説明文が与えられ、説明文内の単語と画像の対応関係を求めるPhrase Groundingのタスクにおいて、学習時に説明文と画像のペアしか与えられない弱教師あり学習の設定で、既存手法を大幅に上回る性能を示した https://t.co/KPlmlbf2Gt	2019/6/30 22:03	https://arxiv.org/abs/1811.11683	Multi-level Multimodal Common Semantic Space for Image-Phrase Grounding	"We address the problem of phrase grounding by lear ing a multi-level commonsemantic space shared by the textual and visual modalities. We exploit multiplelevels of feature maps of a Deep Convolutional Neural Network, as well ascontextualized word and sentence embeddings extracted from a character-basedlanguage model. Following dedicated non-linear mappings for visual features ateach level, word, and sentence embeddings, we obtain multiple instantiations ofour common semantic space in which comparisons between any target text and thevisual content is performed with cosine similarity. We guide the model by amulti-level multimodal attention mechanism which outputs attended visualfeatures at each level. The best level is chosen to be compared with textcontent for maximizing the pertinence scores of image-sentence pairs of theground truth. Experiments conducted on three publicly available datasets showsignificant performance gains (20%-60% relative) over the state-of-the-art inphrase localization and set a new performance record on those datasets. Weprovide a detailed ablation study to show the contribution of each element ofour approach and release our code on GitHub."	Computer Vision and Pattern Recognition (cs.CV)	Computation and Language (cs.CL);Machine Learning (cs.LG);Image and Video Processing (eess.IV)
hsntdo	Hoshino Tadao	286	100	タイトルからしてすごそうな論文みつけた（アブストだけ読んだ） https://t.co/E9UcztBbNA	2019/6/30 22:24	https://arxiv.org/abs/1904.04276	On assumption-free tests and confidence intervals for causal effects estimated by machine learning	"For many causal effect parameters $\psi$ of interest doubly robust machinelearning estimators $\widehat\psi_1$ are the state-of-the-art, incorporatingthe benefits of the low prediction error of machine learning algorithms; thedecreased bias of doubly robust estimators; and.the analytic tractability andbias reduction of cross fitting. When the potential confounders is highdimensional, the associated $(1 - \alpha)$ Wald intervals may still undercovereven in large samples, because the bias may be of the same or even larger orderthan its standard error. In this paper, we introduce tests that can have thepower to detect whether the bias of $\widehat\psi_1$ is of the same or evenlarger order than its standard error of order $n^{-1/2}$, can provide a lowerconfidence limit on the degree of under coverage of the interval andstrikingly, are valid under essentially no assumptions. We also introduce anestimator with bias generally less than that of $\widehat\psi_1$, yet whosestandard error is not much greater than $\widehat\psi_1$'s. The tests, as wellas the estimator $\widehat\psi_2$, are based on a U-statistic that is thesecond-order influence function for the parameter that encodes the estimablepart of the bias of $\widehat\psi_1$. Our impressive claims need to be temperedin several important ways. First no test, including ours, of the nullhypothesis that the ratio of the bias to its standard error can be consistent[without making additional assumptions that may be incorrect]. Furthermore theabove claims only apply to parameters in a particular class. For the others,our results are less sharp and require more careful interpretation."	Machine Learning (stat.ML)	Machine Learning (cs.LG);Statistics Theory (math.ST);Methodology (stat.ME)
asam9891	Masa.I	470	128	"Adversarial Examples Are Not Bugs, They Are Features さっきの投稿の参考文献。robust な特徴は人の感覚と一致してる普遍的な特徴、non robust な特徴は人の感覚と必ずしも一致しないが特定のクラスの識別に重要な特徴。non robust な特徴が敵対事例の原因となっている https://t.co/78rcMx5FXZ"	2019/6/30 22:34	https://arxiv.org/abs/1905.02175	"Adversarial Examples Are Not Bugs, They Are Features"	"Adversarial examples have attracted significant attention in machinelearning, but the reasons for their existence and pervasiveness remain unclear.We demonstrate that adversarial examples can be directly attributed to thepresence of non-robust features: features derived from patterns in the datadistribution that are highly predictive, yet brittle and incomprehensible tohumans. After capturing these features within a theoretical framework, weestablish their widespread existence in standard datasets. Finally, we presenta simple setting where we can rigorously tie the phenomena we observe inpractice to a misalignment between the (human-specified) notion of robustnessand the inherent geometry of the data."	Machine Learning (stat.ML)	Cryptography and Security (cs.CR);Computer Vision and Pattern Recognition (cs.CV);Machine Learning (cs.LG)
kosukemizz0310	kosuke.M	529	499	分位点回帰を用いたDistributional RLの改良。分位点ごとにモデルを近似することをやめ、分位点のembeddingをモデルに加えている。また、リスクを考慮したモデル化も行った。 https://t.co/WDhNDtGC60	2019/7/1 1:36	https://arxiv.org/abs/1806.06923	Implicit Quantile Networks for Distributional Reinforcement Learning	"In this work, we build on recent advances in distributional reinforcementlearning to give a generally applicable, flexible, and state-of-the-artdistributional variant of DQN. We achieve this by using quantile regression toapproximate the full quantile function for the state-action returndistribution. By reparameterizing a distribution over the sample space, thisyields an implicitly defined return distribution and gives rise to a largeclass of risk-sensitive policies. We demonstrate improved performance on the 57Atari 2600 games in the ALE, and use our algorithm's implicitly defineddistributions to study the effects of risk-sensitive policies in Atari games."	Machine Learning (cs.LG)	Artificial Intelligence (cs.AI);Machine Learning (stat.ML)
KSKSKSKS2	katsugeneration	177	444	クエリ画像と同じものが写っている画像を検索するタスクで、ローカル特徴量によるリランキングを後付けできる手法を提案。グローバルな特徴量を出力する既存のCNNを再学習せずに、ベースモデルによる類似度検索と比較し、最大で5ポイントほどmAPやmP@10が向上することを示した https://t.co/2NDZg51F2w	2019/7/1 9:02	https://arxiv.org/abs/1905.06358	Local Features and Visual Words Emerge in Activations	"We propose a novel method of deep spatial matching (DSM) for image retrieval.Initial ranking is based on image descriptors extracted from convolutionalneural network activations by global pooling, as in recent state-of-the-artwork. However, the same sparse 3D activation tensor is also approximated by acollection of local features. These local features are then robustly matched toapproximate the optimal alignment of the tensors. This happens without anynetwork modification, additional layers or training. No local feature detectionhappens on the original image. No local feature descriptors and no visualvocabulary are needed throughout the whole process.We experimentally show that the proposed method achieves the state-of-the-artperformance on standard benchmarks across different network architectures anddifferent global pooling methods. The highest gain in performance is achievedwhen diffusion on the nearest-neighbor graph of global descriptors is initiatedfrom spatially verified images."	Computer Vision and Pattern Recognition (cs.CV)	
icoxfog417	piqcy	"8,884"	127	"BERTを超えたと話題になったXLNetのコストについての話。論文中では""512 TPU v3 chips""で2.5 daysと言及されている。1TPUは4chipsで構成されるので128TPUを2.5days=$61,440ほどになるとの試算(660万ほど)。一発で上手くいったはずはないと思うので実態はさらに上と思われる  https://t.co/ZpnHUq3GwV https://t.co/GS0FirpDNV"	2019/7/1 9:37	https://arxiv.org/abs/1906.08237	XLNet: Generalized Autoregressive Pretraining for Language Understanding	"With the capability of modeling bidirectional contexts, denoisingautoencoding based pretraining like BERT achieves better performance thanpretraining approaches based on autoregressive language modeling. However,relying on corrupting the input with masks, BERT neglects dependency betweenthe masked positions and suffers from a pretrain-finetune discrepancy. In lightof these pros and cons, we propose XLNet, a generalized autoregressivepretraining method that (1) enables learning bidirectional contexts bymaximizing the expected likelihood over all permutations of the factorizationorder and (2) overcomes the limitations of BERT thanks to its autoregressiveformulation. Furthermore, XLNet integrates ideas from Transformer-XL, thestate-of-the-art autoregressive model, into pretraining. Empirically, XLNetoutperforms BERT on 20 tasks, often by a large margin, and achievesstate-of-the-art results on 18 tasks including question answering, naturallanguage inference, sentiment analysis, and document ranking."	Computation and Language (cs.CL)	Machine Learning (cs.LG)
yu4u	Yusuke Uchida	"4,447"	950	"FPGAﾖｲｼｮｰｯ / “[1906.11879] Comparing Energy Efficiency of CPU, GPU and FPGA Implementations for Vision Kernels” https://t.co/b6KjqFIYTL"	2019/7/1 10:06	https://arxiv.org/abs/1906.11879	"Comparing Energy Efficiency of CPU, GPU and FPGA Implementations for Vision Kernels"	"Developing high performance embedded vision applications requires balancingrun-time performance with energy constraints. Given the mix of hardwareaccelerators that exist for embedded computer vision (e.g. multi-core CPUs,GPUs, and FPGAs), and their associated vendor optimized vision libraries, itbecomes a challenge for developers to navigate this fragmented solution space.To aid with determining which embedded platform is most suitable for theirapplication, we conduct a comprehensive benchmark of the run-time performanceand energy efficiency of a wide range of vision kernels. We discuss rationalesfor why a given underlying hardware architecture innately performs well orpoorly based on the characteristics of a range of vision kernel categories.Specifically, our study is performed for three commonly used HW acceleratorsfor embedded vision applications: ARM57 CPU, Jetson TX2 GPU and ZCU102 FPGA,using their vendor optimized vision libraries: OpenCV, VisionWorks andxfOpenCV. Our results show that the GPU achieves an energy/frame reductionratio of 1.1-3.2x compared to the others for simple kernels. While for morecomplicated kernels and complete vision pipelines, the FPGA outperforms theothers with energy/frame reduction ratios of 1.2-22.3x. It is also observedthat the FPGA performs increasingly better as a vision application's pipelinecomplexity grows."	Computer Vision and Pattern Recognition (cs.CV)	Image and Video Processing (eess.IV)
L_H_Sullivan	ふー??じん??	368	319	Lattice and magnetic dynamics in polar chiral incommensurate antiferromagnet Ni2InSbO6 https://t.co/W1I7pQTN2A arkパイセンがファーストちゃうの？	2019/7/1 11:10	https://arxiv.org/abs/1906.12327	Lattice and magnetic dynamics in polar chiral incommensurate antiferromagnet Ni$_2$InSbO$_6$	"Complex systems with coexisting polarity, chirality and incommensuratemagnetism are of great interest because they open new degrees of freedom ininteraction between different subsystems and therefore they host a plethora ofintriguing physical properties. Here we report on optical properties andlattice and spin dynamics of Ni$_2$InSbO$_6$ single crystals studied with theuse of polarized optical microscopy and micro-Raman spectroscopy in thetemperature range 10-300 K. Ni$_2$InSbO$_6$ crystallizes in a polar structuredescribed by the noncentrosymmetric space group R3 and two types of structuraldomains were visualized due to natural optical activity of opposite chirality.Raman tensor elements of most A and E phonons along with their symmetry weredetermined. The manifestation of LO-TO splitting was observed for the A modes.By tracking the temperature dependencies of phonon frequencies the wellpronounced spin-phonon interaction was observed for several modes below andabove the N?el transition temperature TN = 76 K. In antiferromagnetic phase awide excitation centred at 247 cm-1 was detected and assigned to the two-magnonmode and this value was used for estimating exchange parameters through linearspin-wave theory calculations."	Materials Science (cond-mat.mtrl-sci)	Optics (physics.optics)
L_H_Sullivan	ふー??じん??	368	319	Complex magnetic phase diagram of metamagnetic MnPtSi https://t.co/CXM6KGIjel 興味深い	2019/7/1 11:12	https://arxiv.org/abs/1906.11864	Complex magnetic phase diagram of metamagnetic MnPtSi	"The magnetic, thermal and transport properties as well as electronic bandstructure of MnPtSi are reported. MnPtSi is a metal that undergoes aferromagnetic transition at $T_{\mathrm{C}}=340$(1) K and a spin-reorientationtransition at $T_{\mathrm{N}}=326$(1) K to an antiferromagnetic phase.First-principles electronic structure calculations indicate a not-fullypolarized spin state of Mn in a $d^5$ electron configuration with $J=S=3$/2, inagreement with the saturation magnetization of 3~$\mu_{\mathrm{B}}$ in theordered state and the observed paramagnetic effective moment. A sizeableanomalous Hall effect in the antiferromagnetic phase alongside thecomputational study suggests that the antiferromagnetic structure isnon-collinear. Based on thermodynamic and resistivity data we construct amagnetic phase diagram. Magnetization curves $M$($H$) at low temperaturesreveal a metamagnetic transition of spin-flop type. The spin-flopped phaseterminates at a critical point with $T_{\mathrm{cr}}\approx 300$ K and$H_{\mathrm{cr}}\approx 10$ kOe, near which a peak of the magnetocaloricentropy change is observed. Using Arrott plot analysis and magnetoresistivitydata we argue that the metamagnetic transition is of a first-order type,whereas the strong field dependence of $T_{\mathrm{N}}$ and the linearrelationship of the $T_{\mathrm{N}}$ with $M^2$ hint at its magnetoelasticnature."	Strongly Correlated Electrons (cond-mat.str-el)	
hmkz_	はま	"1,082"	"2,520"	GA（正確に言うと進化計算）意外と強いですよ。最近流行りのOne-shot NAS（ニューラルネットの学習と同時に構造探索もする技術）も先の論文の発展形ですし。 https://t.co/Te7VPRkGK7	2019/7/1 13:01	https://arxiv.org/abs/1905.08537	Adaptive Stochastic Natural Gradient Method for One-Shot Neural Architecture Search	"High sensitivity of neural architecture search (NAS) methods against theirinput such as step-size (i.e., learning rate) and search space preventspractitioners from applying them out-of-the-box to their own problems, albeitits purpose is to automate a part of tuning process. Aiming at a fast, robust,and widely-applicable NAS, we develop a generic optimization framework for NAS.We turn a coupled optimization of connection weights and neural architectureinto a differentiable optimization by means of stochastic relaxation. Itaccepts arbitrary search space (widely-applicable) and enables to employ agradient-based simultaneous optimization of weights and architecture (fast). Wepropose a stochastic natural gradient method with an adaptive step-sizemechanism built upon our theoretical investigation (robust). Despite itssimplicity and no problem-dependent parameter tuning, our method exhibited nearstate-of-the-art performances with low computational budgets both on imageclassification and inpainting tasks."	Machine Learning (cs.LG)	Neural and Evolutionary Computing (cs.NE);Machine Learning (stat.ML)
kawashima2201_	Q学習をかじった?Kawashima??	62	320	"参加してる機械学習勉強会で「A free energy principle for a particular physics」って論文の解読会が2,3ヶ月以内に開かれると聞いて泣いて震えてる https://t.co/LDQHmvF3H0"	2019/7/1 13:09	https://arxiv.org/abs/1906.10184	A free energy principle for a particular physics	"This monograph attempts a theory of every 'thing' that can be distinguishedfrom other things in a statistical sense. The ensuing statisticalindependencies, mediated by Markov blankets, speak to a recursive compositionof ensembles (of things) at increasingly higher spatiotemporal scales. Thisdecomposition provides a description of small things; e.g., quantum mechanics -via the Schrodinger equation, ensembles of small things - via statisticalmechanics and related fluctuation theorems, through to big things - viaclassical mechanics. These descriptions are complemented with a Bayesianmechanics for autonomous or active things. Although this work provides aformulation of every thing, its main contribution is to examine theimplications of Markov blankets for self-organisation to nonequilibriumsteady-state. In brief, we recover an information geometry and accompanyingfree energy principle that allows one to interpret the internal states ofsomething as representing or making inferences about its external states. Theensuing Bayesian mechanics is compatible with quantum, statistical andclassical mechanics and may offer a formal description of lifelike particles."	Neurons and Cognition (q-bio.NC)	
Kenji_Sugisaki	杉﨑 研司 (Kenji Sugisaki)	360	127	Hole-Spin-Echo Envelope Modulations https://t.co/KM7LBvH6eR ESR関係でESEEMはなじみがあるけどそれのhole版。気になる。	2019/7/1 13:56	https://arxiv.org/abs/1906.11953	Hole-Spin-Echo Envelope Modulations	"Hole spins in semiconductor quantum dots or bound to acceptor impurities showpromise as potential qubits, partly because of their weak and anisotropichyperfine couplings to proximal nuclear spins. Since the hyperfine coupling isweak, it can be difficult to measure. However, an anisotropic hyperfinecoupling can give rise to a substantial spin-echo envelope modulation that canbe Fourier-analyzed to accurately reveal the hyperfine tensor. Here, we give ageneral theoretical analysis for hole-spin-echo envelope modulation (HSEEM),and apply this analysis to the specific case of a boron-acceptor hole spin insilicon. For boron acceptor spins in unstrained silicon, both the hyperfine andZeeman Hamiltonians are approximately isotropic leading to negligible envelopemodulations. In contrast, in strained silicon, where light-hole spin qubits canbe energetically isolated, we find the hyperfine Hamiltonian and $g$-tensor aresufficiently anisotropic to give spin-echo-envelope modulations. We show thatthere is an optimal magnetic-field orientation that maximizes the visibility ofenvelope modulations in this case. Based on microscopic estimates of thehyperfine coupling, we find that the maximum modulation depth can besubstantial, reaching $\sim 10\%$, at a moderate laboratory magnetic field,$B\lesssim 200\,\mathrm{mT}$."	Mesoscale and Nanoscale Physics (cond-mat.mes-hall)	Quantum Physics (quant-ph)
ikkoham	濵村 一航 Ikko Hamamura??	633	501	最近出た良いレビューらしい https://t.co/IdZmLSFZ1l #qikansai26	2019/7/1 15:02	https://arxiv.org/abs/1904.06560	A Quantum Engineer's Guide to Superconducting Qubits	"The aim of this review is to provide quantum engineers with an introductoryguide to the central concepts and challenges in the rapidly accelerating fieldof superconducting quantum circuits. Over the past twenty years, the field hasmatured from a predominantly basic research endeavor to one that increasinglyexplores the engineering of larger-scale superconducting quantum systems. Here,we review several foundational elements -- qubit design, noise properties,qubit control, and readout techniques -- developed during this period, bridgingfundamental concepts in circuit quantum electrodynamics (cQED) andcontemporary, state-of-the-art applications in gate-model quantum computation."	Quantum Physics (quant-ph)	Mesoscale and Nanoscale Physics (cond-mat.mes-hall);Applied Physics (physics.app-ph)
st_red_strat	's.to;t@??はご飯の上に魚が乗ってるから神	287	990	@enthal_p ミクロな因果律を指導原理として仮定する、というのならまだ良いけど  そもそもラグランジアンがnon-localな相互作用しか含んでなくてもマクロにconsistentかどうかは全く自明ではない https://t.co/1dvYhnmaIq ミクロな因果律からマクロな因果律は一般には言えないし、逆を無批判に仮定するのもヤバい	2019/7/1 15:42	https://arxiv.org/abs/hep-th/0602178	"[hep-th/0602178] Causality, Analyticity and an IR Obstruction to UV Completion"	"We argue that certain apparently consistent low-energy effective fieldtheories described by local, Lorentz-invariant Lagrangians, secretly exhibitmacroscopic non-locality and cannot be embedded in any UV theory whose S-matrixsatisfies canonical analyticity constraints. The obstruction involves the signsof a set of leading irrelevant operators, which must be strictly positive toensure UV analyticity. An IR manifestation of this restriction is that the""wrong"" signs lead to superluminal fluctuations around non-trivial backgrounds,making it impossible to define local, causal evolution, and implying asurprising IR breakdown of the effective theory. Such effective theories cannot arise in quantum field theories or weakly coupled string theories, whoseS-matrices satisfy the usual analyticity properties. This conclusion applies tothe DGP brane-world model modifying gravity in the IR, giving a simpleexplanation for the difficulty of embedding this model into controlled stringybackgrounds, and to models of electroweak symmetry breaking that predictnegative anomalous quartic couplings for the W and Z. Conversely, anyexperimental support for the DGP model, or measured negative signs foranomalous quartic gauge boson couplings at future accelerators, wouldconstitute direct evidence for the existence of superluminality and macroscopicnon-locality unlike anything previously seen in physics, and almostincidentally falsify both local quantum field theory and perturbative stringtheory."	High Energy Physics - Theory (hep-th)	High Energy Physics - Phenomenology (hep-ph)
levelfour_	Han Bao	"1,135"	531	@tmiya_ なるほど…UCBで考えるとそうなりそうですね。最近だとおそらくそういう問題意識があってgood arm identification（ある程度良い腕をすべて選ぶ）みたいな問題も模索されているんだろうなと思いました。 https://t.co/7Q4Grxv0mC	2019/7/1 16:08	https://arxiv.org/abs/1710.06360	Good Arm Identification via Bandit Feedback	"We consider a novel stochastic multi-armed bandit problem called {\em goodarm identification} (GAI), where a good arm is defined as an arm with expectedreward greater than or equal to a given threshold. GAI is a pure-explorationproblem that a single agent repeats a process of outputting an arm as soon asit is identified as a good one before confirming the other arms are actuallynot good. The objective of GAI is to minimize the number of samples for eachprocess. We find that GAI faces a new kind of dilemma, the {\emexploration-exploitation dilemma of confidence}, which is different difficultyfrom the best arm identification. As a result, an efficient design ofalgorithms for GAI is quite different from that for the best armidentification. We derive a lower bound on the sample complexity of GAI that istight up to the logarithmic factor $\mathrm{O}(\log \frac{1}{\delta})$ foracceptance error rate $\delta$. We also develop an algorithm whose samplecomplexity almost matches the lower bound. We also confirm experimentally thatour proposed algorithm outperforms naive algorithms in synthetic settings basedon a conventional bandit problem and clinical trial researches for rheumatoidarthritis."	Machine Learning (stat.ML)	
tmaehara	? ??	"6,881"	717	A History of Metaheuristics https://t.co/IDQ2wrHyFJ 面白かった．	2019/7/1 17:34	https://arxiv.org/abs/1704.00853	A History of Metaheuristics	"This chapter describes the history of metaheuristics in five distinctperiods, starting long before the first use of the term and ending a long timein the future."	Artificial Intelligence (cs.AI)	
Lepidoptera2015	あおすじあげはちょう	290	347	https://t.co/zojYyqGSQs 推薦におけるfairnessってどう定義すればいいの？って話	2019/7/1 17:37	https://arxiv.org/abs/1903.00780v1	[1903.00780v1] Fairness in Recommendation Ranking through Pairwise Comparisons	"Recommender systems are one of the most pervasive applications of machinelearning in industry, with many services using them to match users to productsor information. As such it is important to ask: what are the possible fairnessrisks, how can we quantify them, and how should we address them? In this paperwe offer a set of novel metrics for evaluating algorithmic fairness concerns inrecommender systems. In particular we show how measuring fairness based onpairwise comparisons from randomized experiments provides a tractable means toreason about fairness in rankings from recommender systems. Building on thismetric, we offer a new regularizer to encourage improving this metric duringmodel training and thus improve fairness in the resulting rankings. We applythis pairwise regularization to a large-scale, production recommender systemand show that we are able to significantly improve the system's pairwisefairness."	Computers and Society (cs.CY)	Artificial Intelligence (cs.AI);Information Retrieval (cs.IR);Machine Learning (cs.LG);Machine Learning (stat.ML)
dojin_tw	安藤道人	"3,896"	901	"先週、サイバーエージェントの安井翔太氏@housecat442によるゲスト講義を行った。  学部生向け講義だが、広告業界における機械学習や因果推論の活用がテーマで、私が一番質問してしまった。  安井氏とイェール大の成田氏らとの共著論文（Narita, Yasui, Yata 2019)はこちら https://t.co/IUYAFx27tN https://t.co/9YjPKS3JKb"	2019/7/1 17:42	https://arxiv.org/abs/1809.03084	Efficient Counterfactual Learning from Bandit Feedback	"What is the most statistically efficient way to do off-policy evaluation andoptimization with batch data from bandit feedback? For log data generated bycontextual bandit algorithms, we consider offline estimators for the expectedreward from a counterfactual policy. Our estimators are shown to have lowestvariance in a wide class of estimators, achieving variance reduction relativeto standard estimators. We then apply our estimators to improve advertisementdesign by a major advertisement company. Consistent with the theoreticalresult, our estimators allow us to improve on the existing bandit algorithmwith more statistical confidence compared to a state-of-the-art benchmark."	Machine Learning (cs.LG)	Artificial Intelligence (cs.AI);Information Retrieval (cs.IR);Methodology (stat.ME);Machine Learning (stat.ML)
hhayakawa	早川尚男	"1,992"	426	https://t.co/tJ3tI6tzMI　或いは@Qhapaq_49 のseminarで https://t.co/FUQNoPzUFz の紹介がありました。	2019/7/1 17:59	https://arxiv.org/abs/1905.11481	AI Feynman: a Physics-Inspired Method for Symbolic Regression	"A core challenge for both physics and artificial intellicence (AI) issymbolic regression: finding a symbolic expression that matches data from anunknown function. Although this problem is likely to be NP-hard in principle,functions of practical interest often exhibit symmetries, separability,compositionality and other simplifying properties. In this spirit, we develop arecursive multidimensional symbolic regression algorithm that combines neuralnetwork fitting with a suite of physics-inspired techniques. We apply it to 100equations from the Feynman Lectures on Physics, and it discovers all of them,while previous publicly available software cracks only 71; for a more difficulttest set, we improve the state of the art success rate from 15% to 90%."	Computational Physics (physics.comp-ph)	Artificial Intelligence (cs.AI);Machine Learning (cs.LG);High Energy Physics - Theory (hep-th)
atomicchildren	あとむ	258	491	arxivの結果。https://t.co/66RwIHIXp2	2019/7/1 18:06					
esXFdfOJxiGBFLx	人工知能 Deep Learning AI image medical machine learni	858	"1,901"	MaskR-CNNによる乳がんの検出&amp;Segmentationに関するarxivです。 マンモグラフィーをグレーから擬似カラーに変化し、カラーコントラストとして塊状パターンを認識しやすくした点にあります。シーケンスをもつMRIやモダリティ間の差を特徴にすることができる可能性があります。 https://t.co/zZKWdFqiG9	2019/7/1 19:25	https://arxiv.org/abs/1906.12118	Fully automatic computer-aided mass detection and segmentation via pseudo-color mammograms and Mask R-CNN	"Purpose: To propose pseudo-color mammograms that enhance mammographic massesas part of a fast computer-aided detection (CAD) system that simultaneouslydetects and segments masses without any user intervention. Methods: Theproposed pseudo-color mammograms, whose three channels contain the originalgrayscale mammogram and two morphologically enhanced images, are used toprovide pseudo-color contrast to the lesions. The morphological enhancement'sifts' out the mass-like mammographic patterns to improve detection andsegmentation. We construct a fast, fully automated simultaneous mass detectionand segmentation CAD system using the colored mammograms as inputs of transferlearning with the Mask R-CNN which is a state-of-the-art deep learningframework. The source code for this work has been made available online.Results: Evaluated on the publicly available mammographic dataset INbreast, themethod outperforms the state-of-the-art methods by achieving an average truepositive rate of 0.90 at 0.9 false positive per image and an average Dicesimilarity index for mass segmentation of 0.88, while taking 20.4 seconds toprocess each image on average. Conclusions: The proposed method provides anaccurate, fully-automatic breast mass detection and segmentation result in lessthan half a minute without any user intervention while outperformingstate-of-the-art methods."	Computer Vision and Pattern Recognition (cs.CV)	
en_sof	?zero	159	134	さっそく https://t.co/tDgzgYiqyu	2019/7/1 20:38	https://arxiv.org/abs/1906.11213	Gluon Field Digitization for Quantum Computers	"Simulations of gauge theories on quantum computers require the digitizationof continuous field variables. Digitization schemes that uses the minimumamount of qubits are desirable. We present a practical scheme for digitizing$SU(3)$ gauge theories via its discrete subgroup $S(1080)$. The $S(1080)$standard Wilson action cannot be used since a phase transition occurs as thecoupling is decreased, well before the scaling regime. We proposed a modifiedaction that allows simulations in the scaling window and carry out classicalMonte Carlo calculations down to lattice spacings of order $a\approx 0.08$ fm.We compute a set of observables with sub-percent precision at multiple latticespacings and show that the continuum extrapolated value agrees with the full$SU(3)$ results. This suggests that this digitization scheme providessufficient precision for NISQ-era QCD simulations."	High Energy Physics - Lattice (hep-lat)	Nuclear Theory (nucl-th);Computational Physics (physics.comp-ph);Quantum Physics (quant-ph)
osciiart	OsciiArt◆SPNEXTcRxQ	"1,905"	"1,166"	ラベルありデータとラベルなしデータでクラスの分布が違うと半教師あり学習はやらない方がましになる。というデータはあったわ。 https://t.co/Q7e9PLHbH8 https://t.co/4suteBSRB0	2019/7/1 20:54	https://arxiv.org/abs/1804.09170	Realistic Evaluation of Deep Semi-Supervised Learning Algorithms	"Semi-supervised learning (SSL) provides a powerful framework for leveragingunlabeled data when labels are limited or expensive to obtain. SSL algorithmsbased on deep neural networks have recently proven successful on standardbenchmark tasks. However, we argue that these benchmarks fail to address manyissues that these algorithms would face in real-world applications. Aftercreating a unified reimplementation of various widely-used SSL techniques, wetest them in a suite of experiments designed to address these issues. We findthat the performance of simple baselines which do not use unlabeled data isoften underreported, that SSL methods differ in sensitivity to the amount oflabeled and unlabeled data, and that performance can degrade substantially whenthe unlabeled dataset contains out-of-class examples. To help guide SSLresearch towards real-world applicability, we make our unified reimplementionand evaluation platform publicly available."	Machine Learning (cs.LG)	Machine Learning (stat.ML)
diskshima	Daisuke Shimamoto	369	952	時々考え過ぎちゃって、不必要に複雑にしちゃうのかもしれませんね。 ・Forget ゲート ・Chronic initialization で MNIST で良い結果が出たそうです。  The unreasonable effectiveness of the forget gate https://t.co/s73rTYydhx	2019/7/1 21:23	https://arxiv.org/abs/1804.04849	The unreasonable effectiveness of the forget gate	"Given the success of the gated recurrent unit, a natural question is whetherall the gates of the long short-term memory (LSTM) network are necessary.Previous research has shown that the forget gate is one of the most importantgates in the LSTM. Here we show that a forget-gate-only version of the LSTMwith chrono-initialized biases, not only provides computational savings butoutperforms the standard LSTM on multiple benchmark datasets and competes withsome of the best contemporary models. Our proposed network, the JANET, achievesaccuracies of 99% and 92.5% on the MNIST and pMNIST datasets, outperforming thestandard LSTM which yields accuracies of 98.5% and 91%."	Neural and Evolutionary Computing (cs.NE)	Machine Learning (cs.LG);Machine Learning (stat.ML)
necrophilism	きゃりーねくねく	605	449	全然知らなかったけど，AI Feynman https://t.co/UKvC1C6uU8 なるものが話題になってたのか．	2019/7/1 21:41	https://arxiv.org/abs/1905.11481	AI Feynman: a Physics-Inspired Method for Symbolic Regression	"A core challenge for both physics and artificial intellicence (AI) issymbolic regression: finding a symbolic expression that matches data from anunknown function. Although this problem is likely to be NP-hard in principle,functions of practical interest often exhibit symmetries, separability,compositionality and other simplifying properties. In this spirit, we develop arecursive multidimensional symbolic regression algorithm that combines neuralnetwork fitting with a suite of physics-inspired techniques. We apply it to 100equations from the Feynman Lectures on Physics, and it discovers all of them,while previous publicly available software cracks only 71; for a more difficulttest set, we improve the state of the art success rate from 15% to 90%."	Computational Physics (physics.comp-ph)	Artificial Intelligence (cs.AI);Machine Learning (cs.LG);High Energy Physics - Theory (hep-th)
re_hako_moon	はこつき＠VR	43	49	https://t.co/BACDU24k4Q 単眼カメラ画像から人間のメッシュを再構成する。一度画像からメッシュを構築後、Joint、Anchor、Vertexの順に徐々にメッシュの変形を推定していくことで密に細かい形状（衣服など）を含めた再構成を実現。	2019/7/1 21:53	https://arxiv.org/abs/1904.10506	Detailed Human Shape Estimation from a Single Image by Hierarchical Mesh Deformation	"This paper presents a novel framework to recover detailed human body shapesfrom a single image. It is a challenging task due to factors such as variationsin human shapes, body poses, and viewpoints. Prior methods typically attempt torecover the human body shape using a parametric based template that lacks thesurface details. As such the resulting body shape appears to be withoutclothing. In this paper, we propose a novel learning-based framework thatcombines the robustness of parametric model with the flexibility of free-form3D deformation. We use the deep neural networks to refine the 3D shape in aHierarchical Mesh Deformation (HMD) framework, utilizing the constraints frombody joints, silhouettes, and per-pixel shading information. We are able torestore detailed human body shapes beyond skinned models. Experimentsdemonstrate that our method has outperformed previous state-of-the-artapproaches, achieving better accuracy in terms of both 2D IoU number and 3Dmetric distance. The code is available in this https URL"	Computer Vision and Pattern Recognition (cs.CV)	Image and Video Processing (eess.IV)
mlmasasing	Masa	72	213	XLNetの論文をメモしておく https://t.co/nHgneekTeM	2019/7/1 22:15	https://arxiv.org/abs/1906.08237	XLNet: Generalized Autoregressive Pretraining for Language Understanding	"With the capability of modeling bidirectional contexts, denoisingautoencoding based pretraining like BERT achieves better performance thanpretraining approaches based on autoregressive language modeling. However,relying on corrupting the input with masks, BERT neglects dependency betweenthe masked positions and suffers from a pretrain-finetune discrepancy. In lightof these pros and cons, we propose XLNet, a generalized autoregressivepretraining method that (1) enables learning bidirectional contexts bymaximizing the expected likelihood over all permutations of the factorizationorder and (2) overcomes the limitations of BERT thanks to its autoregressiveformulation. Furthermore, XLNet integrates ideas from Transformer-XL, thestate-of-the-art autoregressive model, into pretraining. Empirically, XLNetoutperforms BERT on 20 tasks, often by a large margin, and achievesstate-of-the-art results on 18 tasks including question answering, naturallanguage inference, sentiment analysis, and document ranking."	Computation and Language (cs.CL)	Machine Learning (cs.LG)
KSuzukiii	すずきぃ@求職	348	306	やってることはわかったんだけど、一から作るのめんどいなぁ... / Data-Free Quantization through Weight Equalization and Bias Correction https://t.co/MApWU1ioSs	2019/7/1 22:56	https://arxiv.org/abs/1906.04721	Data-Free Quantization through Weight Equalization and Bias Correction	"We introduce a data-free quantization method for deep neural networks thatdoes not require fine-tuning or hyperparameter selection. It achievesnear-original model performance on common computer vision architectures andtasks. 8-bit fixed-point quantization is essential for efficient inference inmodern deep learning hardware architectures. However, quantizing models to runin 8-bit is a non-trivial task, frequently leading to either significantperformance reduction or engineering time spent on training a network to beamenable to quantization. Our approach relies on equalizing the weight rangesin the network by making use of a scale-equivariance property of activationfunctions. In addition the method corrects biases in the error that areintroduced during quantization. This improves quantization accuracyperformance, and can be applied ubiquitously to almost any model with astraight-forward API call. For common architectures, such as the MobileNetfamily, we achieve state-of-the-art quantized model performance. We furthershow that the method also extends to other computer vision architectures andtasks such as semantic segmentation and object detection."	Machine Learning (cs.LG)	Computer Vision and Pattern Recognition (cs.CV);Machine Learning (stat.ML)
hayashiyus	Yusuke HAYASHI 林 祐輔	"3,520"	565	統計モデルに逆温度を導入する一般的な手順．  1. https://t.co/3i7VpTqtOP 2. https://t.co/1yt6OIqScb https://t.co/rcz8YxUPoN	2019/7/1 23:51	"https://arxiv.org/abs/1004.2316, https://arxiv.org/abs/1208.6338"	"Asymptotic Equivalence of Bayes Cross Validation and Widely Applicable Information Criterion in Singular Learning Theory, A Widely Applicable Bayesian Information Criterion"	"In regular statistical models, the leave-one-out cross-validation isasymptotically equivalent to the Akaike information criterion. However, sincemany learning machines are singular statistical models, the asymptotic behaviorof the cross-validation remains unknown. In previous studies, we establishedthe singular learning theory and proposed a widely applicable informationcriterion, the expectation value of which is asymptotically equal to theaverage Bayes generalization loss. In the present paper, we theoreticallycompare the Bayes cross-validation loss and the widely applicable informationcriterion and prove two theorems. First, the Bayes cross-validation loss isasymptotically equivalent to the widely applicable information criterion as arandom variable. Therefore, model selection and hyperparameter optimizationusing these two values are asymptotically equivalent. Second, the sum of theBayes generalization error and the Bayes cross-validation error isasymptotically equal to $2\lambda/n$, where $\lambda$ is the real log canonicalthreshold and $n$ is the number of training samples. Therefore the relationbetween the cross-validation error and the generalization error is determinedby the algebraic geometrical structure of a learning machine. We also clarifythat the deviance information criteria are different from the Bayescross-validation and the widely applicable information criterion., A statistical model or a learning machine is called regular if the map takinga parameter to a probability distribution is one-to-one and if its Fisherinformation matrix is always positive definite. If otherwise, it is calledsingular. In regular statistical models, the Bayes free energy, which isdefined by the minus logarithm of Bayes marginal likelihood, can beasymptotically approximated by the Schwarz Bayes information criterion (BIC),whereas in singular models such approximation does not hold.Recently, it was proved that the Bayes free energy of a singular model isasymptotically given by a generalized formula using a birational invariant, thereal log canonical threshold (RLCT), instead of half the number of parametersin BIC. Theoretical values of RLCTs in several statistical models are now beingdiscovered based on algebraic geometrical methodology. However, it has beendifficult to estimate the Bayes free energy using only training samples,because an RLCT depends on an unknown true distribution.In the present paper, we define a widely applicable Bayesian informationcriterion (WBIC) by the average log likelihood function over the posteriordistribution with the inverse temperature $1/\log n$, where $n$ is the numberof training samples. We mathematically prove that WBIC has the same asymptoticexpansion as the Bayes free energy, even if a statistical model is singular forand unrealizable by a statistical model. Since WBIC can be numericallycalculated without any information about a true distribution, it is ageneralized version of BIC onto singular statistical models."	"Machine Learning (cs.LG), Machine Learning (cs.LG)"	", Machine Learning (stat.ML)"
fullflu	fullflu	85	137	多重代入法と機械学習のアンサンブル学習をどう結びつけるのか、ってのを研究している事例があれば知りたい。arxivとかにちらほらあるけど、あんまり調べてないのでこれが王道なのかはわからない https://t.co/Rut3mNrOPe	2019/7/2 5:23	https://arxiv.org/abs/1802.00154	Bootstrapping and Multiple Imputation Ensemble Approaches for Missing Data	"Presence of missing values in a dataset can adversely affect the performanceof a classifier. Single and Multiple Imputation are normally performed to fillin the missing values. In this paper, we present several variants of combiningsingle and multiple imputation with bootstrapping to create ensembles that canmodel uncertainty and diversity in the data, and that are robust to highmissingness in the data. We present three ensemble strategies: bootstrapping onincomplete data followed by (i) single imputation and (ii) multiple imputation,and (iii) multiple imputation ensemble without bootstrapping. We perform anextensive evaluation of the performance of the these ensemble strategies on 8datasets by varying the missingness ratio. Our results show that bootstrappingfollowed by multiple imputation using expectation maximization is the mostrobust method even at high missingness ratio (up to 30%). For small missingnessratio (up to 10%) most of the ensemble methods perform quivalently but betterthan single imputation. Kappa-error plots suggest that accurate classifierswith reasonable diversity is the reason for this behaviour. A consistentobservation in all the datasets suggests that for small missingness (up to10%), bootstrapping on incomplete data without any imputation producesequivalent results to other ensemble methods."	Machine Learning (cs.LG)	
tmaehara	? ??	"6,881"	717	わたしはアルゴリズム系に出すときは conclusion カットします．たとえば https://t.co/Trc6I0St7y https://t.co/9na2Pv9CeT https://t.co/XvAQaLYL6w あたりは conclusion なし． https://t.co/EOenzmBYNB	2019/7/2 7:41	"https://arxiv.org/abs/1707.04020, https://arxiv.org/abs/1902.08742"	"Stochastic Packing Integer Programs with Few Queries, Optimal Algorithm to Reconstruct a Tree from a Subtree Distance"	"We consider a stochastic variant of the packing-type integer linearprogramming problem, which contains random variables in the objective vector.We are allowed to reveal each entry of the objective vector by conducting aquery, and the task is to find a good solution by conducting a small number ofqueries. We propose a general framework of adaptive and non-adaptive algorithmsfor this problem, and provide a unified methodology for analyzing theperformance of those algorithms. We also demonstrate our framework by applyingit to a variety of stochastic combinatorial optimization problems such asmatching, matroid, and stable set problems., This paper addresses the problem of finding a representation of a subtreedistance, which is an extension of the tree metric. We show that a minimalrepresentation is uniquely determined by a given subtree distance, and give alinear time algorithm that finds such a representation. This algorithm achievesthe optimal time complexity."	"Data Structures and Algorithms (cs.DS), Data Structures and Algorithms (cs.DS)"	
akihiro_akichan	akihiro_f	122	118	https://t.co/cYf0mKYOMC 印象の残りやすさを調整できる機構GANalyzeを提案。生成器Gと印象度検査器Aを固定し、調整したいパラメータaと潜在変数zの埋め込み器Tを学習させ、zが固定なのでaを調整すれば同じ構図で印象に残りやすい画像を生成できる。 https://t.co/KbyiCTk1RS	2019/7/2 8:23	https://arxiv.org/abs/1906.10112	GANalyze: Toward Visual Definitions of Cognitive Image Properties	"We introduce a framework that uses Generative Adversarial Networks (GANs) tostudy cognitive properties like memorability, aesthetics, and emotionalvalence. These attributes are of interest because we do not have a concretevisual definition of what they entail. What does it look like for a dog to bemore or less memorable? GANs allow us to generate a manifold of natural-lookingimages with fine-grained differences in their visual attributes. By navigatingthis manifold in directions that increase memorability, we can visualize whatit looks like for a particular generated image to become more or lessmemorable. The resulting ``visual definitions"" surface image properties (like``object size"") that may underlie memorability. Through behavioral experiments,we verify that our method indeed discovers image manipulations that causallyaffect human memory performance. We further demonstrate that the same frameworkcan be used to analyze image aesthetics and emotional valence. Visit theGANalyze website at this http URL."	Computer Vision and Pattern Recognition (cs.CV)	
TalesOfOdajun	TalesOfOdajun	165	221	読む https://t.co/7MOrnhSH4o	2019/7/2 9:23	https://arxiv.org/abs/1903.10970	Apache Hive: From MapReduce to Enterprise-grade Big Data Warehousing	"Apache Hive is an open-source relational database system for analyticbig-data workloads. In this paper we describe the key innovations on thejourney from batch tool to fully fledged enterprise data warehousing system. Wepresent a hybrid architecture that combines traditional MPP techniques withmore recent big data and cloud concepts to achieve the scale and performancerequired by today's analytic applications. We explore the system by detailingenhancements along four main axis: Transactions, optimizer, runtime, andfederation. We then provide experimental results to demonstrate the performanceof the system for typical workloads and conclude with a look at the communityroadmap."	Databases (cs.DB)	
icoxfog417	piqcy	"8,884"	127	失われた言語の解読(翻訳)を行う研究。失われている故に大規模なコーパスは使えないので、同族言語とのアライメントを手がかりに翻訳を行なっている。具体的には、既知の同族言語における文字の並び/単語の出現確率で制約をかけて生成を行なっている。  https://t.co/wyBQd6rOkR	2019/7/2 9:34	https://arxiv.org/abs/1906.06718	Neural Decipherment via Minimum-Cost Flow: from Ugaritic to Linear B	"In this paper we propose a novel neural approach for automatic deciphermentof lost languages. To compensate for the lack of strong supervision signal, ourmodel design is informed by patterns in language change documented inhistorical linguistics. The model utilizes an expressive sequence-to-sequencemodel to capture character-level correspondences between cognates. Toeffectively train the model in an unsupervised manner, we innovate the trainingprocedure by formalizing it as a minimum-cost flow problem. When applied to thedecipherment of Ugaritic, we achieve a 5.5% absolute improvement overstate-of-the-art results. We also report the first automatic results indeciphering Linear B, a syllabic language related to ancient Greek, where ourmodel correctly translates 67.3% of cognates."	Computation and Language (cs.CL)	
saeeeeru	さえない / Saeru Yamamuro	"1,646"	482	"『ザ・フォーミュラ』の著者であるバラバシの研究グループが""サッカー選手を評価する専門家の能力""について分析した論文。 https://t.co/RX99b4iXKv"	2019/7/2 9:36	https://arxiv.org/abs/1712.02224	Human Perception of Performance	"Humans are routinely asked to evaluate the performance of other individuals,separating success from failure and affecting outcomes from science toeducation and sports. Yet, in many contexts, the metrics driving the humanevaluation process remain unclear. Here we analyse a massive dataset capturingplayers' evaluations by human judges to explore human perception of performancein soccer, the world's most popular sport. We use machine learning to design anartificial judge which accurately reproduces human evaluation, allowing us todemonstrate how human observers are biased towards diverse contextual features.By investigating the structure of the artificial judge, we uncover the aspectsof the players' behavior which attract the attention of human judges,demonstrating that human evaluation is based on a noticeability heuristic whereonly feature values far from the norm are considered to rate an individual'sperformance."	Physics and Society (physics.soc-ph)	"Artificial Intelligence (cs.AI);Data Analysis, Statistics and Probability (physics.data-an);Applications (stat.AP)"
Ryuhei_Mori	Mori	100	50	グラフの彩色数が O(1.9140^n)時間の量子アルゴリズムで計算できるというお話。 https://t.co/flRkOBKJyY 古典アルゴリズムでは branching が包除原理に負けることが多いけど、量子アルゴリズムでは逆転できる。 量子アルゴリズムなんも知らなくても、古典アルゴリズムが好きなら参戦できるので是非。	2019/7/2 10:00	https://arxiv.org/abs/1907.00529	Exponential-time quantum algorithms for graph coloring problems	"The fastest known classical algorithm deciding the $k$-colorability of$n$-vertex graph requires running time $\Omega(2^n)$ for $k\ge 5$. In thiswork, we present an exponential-space quantum algorithm computing the chromaticnumber with running time $O(1.9140^n)$ using quantum random access memory(QRAM). Our approach is based on Ambainis et al's quantum dynamic programmingwith applications of Grover's search to branching algorithms. We also present apolynomial-space quantum algorithm not using QRAM for the graph $20$-coloringproblem with running time $O(1.9575^n)$. In the polynomial-space quantumalgorithm, we essentially show $(4-\epsilon)^n$-time classical algorithms thatcan be improved quadratically by Grover's search."	Data Structures and Algorithms (cs.DS)	Quantum Physics (quant-ph)
qard_t	T-QARD channel	516	0	論文はこちら https://t.co/MButwL5k8L https://t.co/mT86T0CzSC	2019/7/2 10:38	https://arxiv.org/abs/1907.00707	Quantum-Assisted Genetic Algorithm	"Genetic algorithms, which mimic evolutionary processes to solve optimizationproblems, can be enhanced by using powerful semi-local search algorithms asmutation operators. Here, we introduce reverse quantum annealing, a class ofquantum evolutions that can be used for performing families of quasi-local orquasi-nonlocal search starting from a classical state, as novel sources ofmutations. Reverse annealing enables the development of genetic algorithms thatuse quantum fluctuation for mutations and classical mechanisms for thecrossovers -- we refer to these as Quantum-Assisted Genetic Algorithms (QAGAs).We describe a QAGA and present experimental results using a D-Wave 2000Qquantum annealing processor. On a set of spin-glass inputs, standard (forward)quantum annealing finds good solutions very quickly but struggles to findglobal optima. In contrast, our QAGA proves effective at finding global optimafor these inputs. This successful interplay of non-local classical and quantumfluctuations could provide a promising step toward practical applications ofNoisy Intermediate-Scale Quantum (NISQ) devices for heuristic discreteoptimization."	Quantum Physics (quant-ph)	Neural and Evolutionary Computing (cs.NE)
whisponchan	NoriakiOshita	"1,671"	719	@AskOkra ソースドメインとターゲットドメインの分布のposterior ratioというのを定義して、その値を訓練することによって転移学習するのは、定式化も綺麗なのでいいと思います。 https://t.co/Su7L8sD3to こちらはチョットテクニカルですが最近の傾向を知るのに良いと思います。 https://t.co/KsQfgagGLs	2019/7/2 10:52	https://arxiv.org/abs/1506.02784	Estimating Posterior Ratio for Classification: Transfer Learning from Probabilistic Perspective	"Transfer learning assumes classifiers of similar tasks share certainparameter structures. Unfortunately, modern classifiers uses sophisticatedfeature representations with huge parameter spaces which lead to costlytransfer. Under the impression that changes from one classifier to anothershould be ``simple'', an efficient transfer learning criteria that only learnsthe ``differences'' is proposed in this paper. We train a \emph{posteriorratio} which turns out to minimizes the upper-bound of the target learningrisk. The model of posterior ratio does not have to share the same parameterspace with the source classifier at all so it can be easily modelled andefficiently trained. The resulting classifier therefore is obtained by simplymultiplying the existing probabilistic-classifier with the learned posteriorratio."	Machine Learning (stat.ML)	Machine Learning (cs.LG)
norita113	nrt@ブルベ冬	710	827	え？まじ？ / [1907.00015] Dark matter heating of gas accreting onto Sgr A$^*$ - https://t.co/NMEv55YkZh	2019/7/2 10:56	https://arxiv.org/abs/1907.00015	Dark matter heating of gas accreting onto Sgr A$^*$	"We study effects of heating by dark matter (DM) annihilation on black holegas accretion. We observe that, for reasonable assumptions about DM densitiesin spikes around supermassive black holes, as well as DM masses andannihilation cross-sections within the standard WIMP model, heating by DMannihilation may have an appreciable effect on the accretion onto Sgr A$^*$ inthe Galactic center. Motivated by this observation we study the effects of suchheating on Bondi accretion, i.e. spherically symmetric, steady-state Newtonianaccretion onto a black hole. We consider different adiabatic indices for thegas, and different power-law exponents for the DM density profile. We find thattypical transonic solutions with heating have a significantly reduced accretionrate. However, for many plausible parameters, transonic solutions do not exist,suggesting a breakdown of the underlying assumptions of steady-state Bondiaccretion. Our findings indicate that heating by DM annihilation may play animportant role in the accretion onto supermassive black holes at the center ofgalaxies, and may help explain the low accretion rate observed for Sgr A$^*$."	High Energy Astrophysical Phenomena (astro-ph.HE)	General Relativity and Quantum Cosmology (gr-qc)
esXFdfOJxiGBFLx	人工知能 Deep Learning AI image medical machine learni	858	"1,901"	皮膚領域のsegmentationに関するarXivです。 少し珍しいのは皮膚を撮影する装置に組み込めるようにパラメータを削減したGANを提案している点である。ボトルネックをなくし、位置とchannel attentionを追加することでパラメータを削減しつつ、既存より性能を出している。 https://t.co/E8NMLSODVk	2019/7/2 10:58	https://arxiv.org/abs/1907.00856	MobileGAN: Skin Lesion Segmentation Using a Lightweight Generative Adversarial Network	"Skin lesion segmentation in dermoscopic images is a challenge due to theirblurry and irregular boundaries. Most of the segmentation approaches based ondeep learning are time and memory consuming due to the hundreds of millions ofparameters. Consequently, it is difficult to apply them to real dermatoscopedevices with limited GPU and memory resources. In this paper, we propose alightweight and efficient Generative Adversarial Networks (GAN) model, calledMobileGAN for skin lesion segmentation. More precisely, the MobileGAN combines1D non-bottleneck factorization networks with position and channel attentionmodules in a GAN model. The proposed model is evaluated on the test dataset ofthe ISBI 2017 challenges and the validation dataset of ISIC 2018 challenges.Although the proposed network has only 2.35 millions of parameters, it is stillcomparable with the state-of-the-art. The experimental results show that ourMobileGAN obtains comparable performance with an accuracy of 97.61%."	Image and Video Processing (eess.IV)	Computer Vision and Pattern Recognition (cs.CV)
Ryuhei_Mori	Mori	100	50	短い。https://t.co/D6RMM3HDeX	2019/7/2 11:07	https://arxiv.org/abs/1907.00847	Induced subgraphs of hypercubes and a proof of the Sensitivity Conjecture	"In this paper, we show that every $(2^{n-1}+1)$-vertex induced subgraph ofthe $n$-dimensional cube graph has maximum degree at least $\sqrt{n}$. Thisresult is best possible, and improves a logarithmic lower bound shown by Chung,F?redi, Graham and Seymour in 1988. As a direct consequence, we prove thatthe sensitivity and degree of a boolean function are polynomially related,solving an outstanding foundational problem in theoretical computer science,the Sensitivity Conjecture of Nisan and Szegedy."	Combinatorics (math.CO)	Computational Complexity (cs.CC)
ueda_physics	Shu	"1,116"	"1,148"	"Higgs inflation の一種でアクシオンの質量などを計算してみた, scalar-to-tensor ratio が 1e-12 くらいになるのが特徴 https://t.co/wmdeGiDvrt"	2019/7/2 11:22	https://arxiv.org/abs/1906.11837	Axion dark matter from Higgs inflation with an intermediate $H_*$	"In order to accommodate the QCD axion as the dark matter (DM) in a model inwhich the Peccei-Quinn (PQ) symmetry is broken before the end of inflation, arelatively low scale of inflation has to be invoked in order to avoid boundsfrom DM isocurvature fluctuations. We construct a simple model in which theStandard Model Higgs field is non-minimally coupled to gravity and acts as theinflaton, leading to a scale of inflation $H_* \sim 10^8\,$GeV. When the PQsymmetry is incorporated in the model and the energy scale at which thesymmetry breaks is much larger than the scale of inflation, we find that inthis scenario the required axion mass for which the axion constitutes all DM is$m_0 \lesssim 0.05{\rm \,\mu eV}$ for a quartic Higgs self-coupling$\lambda_\phi = 0.1$, which correspond to the PQ breaking scale $v_\sigma\gtrsim 10^{14}\,$GeV and tensor-to-scalar ratio $r \sim 10^{-12}$. Futureexperiments sensitive to the relevant QCD axion mass scale can therefore shedlight on the physics of the Universe before the end of inflation."	Cosmology and Nongalactic Astrophysics (astro-ph.CO)	General Relativity and Quantum Cosmology (gr-qc);High Energy Physics - Phenomenology (hep-ph)
ueda_physics	Shu	"1,116"	"1,148"	"Configuration entropy の最小値とダークエネルギーの状態方程式・パラメータの関係から, 後者に制約を付けられるかもしれない https://t.co/gKwPLE5ToQ"	2019/7/2 11:22	https://arxiv.org/abs/1907.00331	Can we constrain the dark energy equation of state parameters using configuration entropy?	We propose a new scheme for constraining the dark energy equation of stateparameter/parameters based on the study of the evolution of the configurationentropy. We analyze a set of one parameter and two parameter dynamical darkenergy models and find that the derivative of the configuration entropy in allthe dynamical dark energy models exhibit a minimum. The magnitude of theminimum of the entropy rate is decided by both the form of the equation ofstate as well as the parameters associated with it. The location of the minimumof the entropy rate is less sensitive to the equation of state and dependsmainly on its parameters. We determine the best fit equations for the locationand magnitude of the minimum of the entropy rate in terms of theparameter/parameters of the dark energy equation of state. These relationswould allow us to constrain the dark energy equation of stateparameter/parameters for any given parametrization provided the evolution ofthe configuration entropy in the Universe is known from observations.	Cosmology and Nongalactic Astrophysics (astro-ph.CO)	
osciiart	OsciiArt◆SPNEXTcRxQ	"1,905"	"1,166"	元々軽量なモデルを作るためにdistillationは提案されているが同じサイズで高性能のモデルを使うために利用することはBorn Again Network (BAN) で提案されている。ただしpseudo labeling がhard targetを使うに対しBANは原則soft targetを使う等ところどころ異なる。 https://t.co/KU9IjCAANN	2019/7/2 12:15	https://arxiv.org/abs/1805.04770	Born Again Neural Networks	"Knowledge distillation (KD) consists of transferring knowledge from onemachine learning model (the teacher}) to another (the student). Commonly, theteacher is a high-capacity model with formidable performance, while the studentis more compact. By transferring knowledge, one hopes to benefit from thestudent's compactness. %we desire a compact model with performance close to theteacher's. We study KD from a new perspective: rather than compressing models,we train students parameterized identically to their teachers. Surprisingly,these {Born-Again Networks (BANs), outperform their teachers significantly,both on computer vision and language modeling tasks. Our experiments with BANsbased on DenseNets demonstrate state-of-the-art performance on the CIFAR-10(3.5%) and CIFAR-100 (15.5%) datasets, by validation error. Additionalexperiments explore two distillation objectives: (i) Confidence-Weighted byTeacher Max (CWTM) and (ii) Dark Knowledge with Permuted Predictions (DKPP).Both methods elucidate the essential components of KD, demonstrating a role ofthe teacher outputs on both predicted and non-predicted classes. We presentexperiments with students of various capacities, focusing on the under-exploredcase where students overpower teachers. Our experiments show significantadvantages from transferring knowledge between DenseNets and ResNets in eitherdirection."	Machine Learning (stat.ML)	Artificial Intelligence (cs.AI);Machine Learning (cs.LG)
Kenji_Sugisaki	杉﨑 研司 (Kenji Sugisaki)	360	127	Computational Chemistry on Quantum Computers: Ground state estimation https://t.co/Zd6oEaMG5I あとで読む	2019/7/2 13:16	https://arxiv.org/abs/1907.00362	Computational Chemistry on Quantum Computers: Ground state estimation	"We present computational chemistry data for small molecules ($CO$, $HCl$,$F_2$, $NH_4^+$, $CH_4$, $NH_{3}$, $H_3O^+$, $H{_2}O$, $BeH_{2}$, $LiH$,$OH^-$, $HF$, $HeH^+$, $H_2$), obtained by implementing the Unitary CoupledCluster method with Single and Double excitations (UCCSD) on a quantum computersimulator. We have used the Variational Quantum Eigensolver (VQE) algorithm toextract the ground state energies of these molecules. This energy datarepresents the expected ground state energy that a quantum computer willproduce for the given molecules, on the STO-3G basis. Since there is a lot ofinterest in the implementation of UCCSD on quantum computers, we hope that ourwork will serve as a benchmark for future experimental implementations."	Quantum Physics (quant-ph)	Materials Science (cond-mat.mtrl-sci)
hillbig	Daisuke Okanohara	"15,910"	254	画像に対する敵対的摂動で人間に差がわからない変化で予測ラベルが変わるのは、ノイズや過学習のせいではなく、人間には認識できない汎化可能な特徴を捉えているためであり、実際得られた特徴を使った分類は他のデータセットにも汎化する。https://t.co/1YdGJ02BSe	2019/7/2 13:19	https://arxiv.org/abs/1905.02175	"Adversarial Examples Are Not Bugs, They Are Features"	"Adversarial examples have attracted significant attention in machinelearning, but the reasons for their existence and pervasiveness remain unclear.We demonstrate that adversarial examples can be directly attributed to thepresence of non-robust features: features derived from patterns in the datadistribution that are highly predictive, yet brittle and incomprehensible tohumans. After capturing these features within a theoretical framework, weestablish their widespread existence in standard datasets. Finally, we presenta simple setting where we can rigorously tie the phenomena we observe inpractice to a misalignment between the (human-specified) notion of robustnessand the inherent geometry of the data."	Machine Learning (stat.ML)	Cryptography and Security (cs.CR);Computer Vision and Pattern Recognition (cs.CV);Machine Learning (cs.LG)
esXFdfOJxiGBFLx	人工知能 Deep Learning AI image medical machine learni	858	"1,901"	Adversarial Exampleに対してモデルではなく、データセットで対策を行うという考えのarXivです。Adversarial Exampleは専門ではなかったけどこれは面白いと思った。ロバストと非ロバストは面白いな。 https://t.co/iHBDbYzxTo	2019/7/2 15:22	https://arxiv.org/abs/1905.02175	"Adversarial Examples Are Not Bugs, They Are Features"	"Adversarial examples have attracted significant attention in machinelearning, but the reasons for their existence and pervasiveness remain unclear.We demonstrate that adversarial examples can be directly attributed to thepresence of non-robust features: features derived from patterns in the datadistribution that are highly predictive, yet brittle and incomprehensible tohumans. After capturing these features within a theoretical framework, weestablish their widespread existence in standard datasets. Finally, we presenta simple setting where we can rigorously tie the phenomena we observe inpractice to a misalignment between the (human-specified) notion of robustnessand the inherent geometry of the data."	Machine Learning (stat.ML)	Cryptography and Security (cs.CR);Computer Vision and Pattern Recognition (cs.CV);Machine Learning (cs.LG)
akashi_akatsuki	明石暁	426	593	Recent Trends in Deep Learning Based Natural Language Processing https://t.co/U9lvS8LhWg  2017年のだけど読むか…	2019/7/2 15:56	https://arxiv.org/abs/1708.02709	Recent Trends in Deep Learning Based Natural Language Processing	"Deep learning methods employ multiple processing layers to learn hierarchicalrepresentations of data and have produced state-of-the-art results in manydomains. Recently, a variety of model designs and methods have blossomed in thecontext of natural language processing (NLP). In this paper, we reviewsignificant deep learning related models and methods that have been employedfor numerous NLP tasks and provide a walk-through of their evolution. We alsosummarize, compare and contrast the various models and put forward a detailedunderstanding of the past, present and future of deep learning in NLP."	Computation and Language (cs.CL)	
hobbymath2020	hobbymath	81	55	新しいプレプリントをアップしました。 https://t.co/fZ4WciPrEI  カルバックライブラーダイバージェンスの下限が、分布の平均値と分散で決まることを示したものです。 ベルヌーイ分布に対しては、等号が成立します。	2019/7/2 16:27	https://arxiv.org/abs/1907.00288	A New Lower Bound for Kullback-Leibler Divergence Based on Hammersley-Chapman-Robbins Bound	"In this paper, we derive a useful lower bound for the Kullback-Leiblerdivergence (KL-divergence) based on the Hammersley-Chapman-Robbins bound(HCRB). The HCRB states that the variance of an estimator is bounded from belowby the Chi-square divergence and the expectation value of the estimator. Byusing the relation between the KL-divergence and the Chi-square divergence, weshow that the lower bound for the KL-divergence which only depends on theexpectation value and the variance of a function we choose. We show that theequality holds for the Bernoulli distributions and show that the inequalityconverges to the Cram?r-Rao bound when two distributions are very close.Furthermore, we describe application examples and examples of numericalcalculation."	Statistics Theory (math.ST)	Information Theory (cs.IT);Machine Learning (stat.ML)
atushiTAKEDA	武田敦志	77	36	@chokudai 競プロ界隈での著作権は把握していないのですが、情報処理学会だと、著作者の権利（第５条）として規定してます。 https://t.co/Ud1tD1Hx2K  arxivだと、arxvi側の権利を規定しています。 https://t.co/eSiS1ctkWO  こんな感じで、著作権を持たない側の権利を明記した方がいいかなと思います。	2019/7/2 18:32					
Q7Xf5U4TpGCMDjG	ほ(研究)	0	0	https://t.co/6dgO3MVqOE  https://t.co/QT5Zqs9neq アイスホッケーでの行動認識を行う研究 Keypoint+Optical Flowを用いることで従来手法よりも精度が向上している。 keypointとして関節点の他にアイスホッケーのスティックの始点、終点を加えている。 https://t.co/siSjNhTKB0	2019/7/2 18:51	https://arxiv.org/abs/1812.09533	Temporal Hockey Action Recognition via Pose and Optical Flows	"Recognizing actions in ice hockey using computer vision poses challenges dueto bulky equipment and inadequate image quality. A novel two-stream frameworkhas been designed to improve action recognition accuracy for hockey using threemain components. First, pose is estimated via the Part Affinity Fields model toextract meaningful cues from the player. Second, optical flow (usingLiteFlowNet) is used to extract temporal features. Third, pose and optical flowstreams are fused and passed to fully-connected layers to estimate the hockeyplayer's action. A novel publicly available dataset named HARPET (Hockey ActionRecognition Pose Estimation, Temporal) was created, composed of sequences ofannotated actions and pose of hockey players including their hockey sticks asan extension of human body pose. Three contributions are recognized. (1) Thenovel two-stream architecture achieves 85% action recognition accuracy, withthe inclusion of optical flows increasing accuracy by about 10%. (2) The uniquelocalization of hand-held objects (e.g., hockey sticks) as part of poseincreases accuracy by about 13%. (3) For pose estimation, a bigger and moregeneral dataset, MSCOCO, is successfully used for transfer learning to asmaller and more specific dataset, HARPET, achieving a PCKh of 87%."	Computer Vision and Pattern Recognition (cs.CV)	
Pechod_dynol	sepia	618	644	https://t.co/dYymFxo5rh Scheme representation for first-order logic   これのこと？	2019/7/2 19:11	https://arxiv.org/abs/1402.2600	Scheme representation for first-order logic	"Although contemporary model theory has been called ""algebraic geometry minusfields"", the formal methods of the two fields are radically different. Thisdissertation aims to shrink that gap by presenting a theory of logical schemes,geometric entities which relate to first-order logical theories in much thesame way that algebraic schemes relate to commutative rings.The construction relies on a Grothendieck-style representation theorem whichassociates every coherent or classical first-order theory with an affinescheme: a topological groupoid (the spectrum of the theory) together with asheaf of (local) syntactic categories. The groupoid is constructed from thesemantics of the theory (models and isomorphisms) and topologized using aStone-type construction. The sheaf of categories can be regarded as a logicaltheory varying over the spectrum, and its global sections recover the theory upto semantic equivalence. These affine pieces can be glued together to give moregeneral logical schemes and these are studied using methods from algebraicgeometry. The final chapter also presents some connections between schemes andother areas of logic such as model theory, type theory and topos theory."	Logic (math.LO)	Algebraic Geometry (math.AG);Category Theory (math.CT)
shiku0304	しく	85	57	平坦な空間じゃないとカーネルが正定値にならないことに気付かなかった僕が馬鹿でした。一週間分の仕事が無駄になりましたが、妙にスッキリしました。 https://t.co/BlDa1OmHbI	2019/7/2 20:37	https://arxiv.org/abs/1411.0296	Geodesic Exponential Kernels: When Curvature and Linearity Conflict	"We consider kernel methods on general geodesic metric spaces and provide bothnegative and positive results. First we show that the common Gaussian kernelcan only be generalized to a positive definite kernel on a geodesic metricspace if the space is flat. As a result, for data on a Riemannian manifold, thegeodesic Gaussian kernel is only positive definite if the Riemannian manifoldis Euclidean. This implies that any attempt to design geodesic Gaussian kernelson curved Riemannian manifolds is futile. However, we show that for spaces withconditionally negative definite distances the geodesic Laplacian kernel can begeneralized while retaining positive definiteness. This implies that geodesicLaplacian kernels can be generalized to some curved spaces, including spheresand hyperbolic spaces. Our theoretical results are verified empirically."	Machine Learning (cs.LG)	Computer Vision and Pattern Recognition (cs.CV)
daigo_hirooka	Daigo	97	560	いい表現を得るためにはinductive biasが重要ってICML2019のbest paperでも言ってましたね。 https://t.co/mF8iF9JPdK https://t.co/IE3a1UACOt	2019/7/2 20:42	https://arxiv.org/abs/1811.12359	Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations	"The key idea behind the unsupervised learning of disentangled representationsis that real-world data is generated by a few explanatory factors of variationwhich can be recovered by unsupervised learning algorithms. In this paper, weprovide a sober look at recent progress in the field and challenge some commonassumptions. We first theoretically show that the unsupervised learning ofdisentangled representations is fundamentally impossible without inductivebiases on both the models and the data. Then, we train more than 12000 modelscovering most prominent methods and evaluation metrics in a reproduciblelarge-scale experimental study on seven different data sets. We observe thatwhile the different methods successfully enforce properties ``encouraged'' bythe corresponding losses, well-disentangled models seemingly cannot beidentified without supervision. Furthermore, increased disentanglement does notseem to lead to a decreased sample complexity of learning for downstream tasks.Our results suggest that future work on disentanglement learning should beexplicit about the role of inductive biases and (implicit) supervision,investigate concrete benefits of enforcing disentanglement of the learnedrepresentations, and consider a reproducible experimental setup coveringseveral data sets."	Machine Learning (cs.LG)	Artificial Intelligence (cs.AI);Machine Learning (stat.ML)
allowfirm	allowfirm	12	37	@shion_honda はじめまして。式10.41のハッチング箇所は「LSTM: A Search Space Odyssey」( https://t.co/p0y5PsKuxV )ですと、p.2の「g」に対応すると思いますが、たしかに図1でもgは「usually tanh」と記載されていました。式10.42の方がシグモイドですから、その相方はtanhが一般的なように思われます。	2019/7/2 21:52	https://arxiv.org/abs/1503.04069	LSTM: A Search Space Odyssey	"Several variants of the Long Short-Term Memory (LSTM) architecture forrecurrent neural networks have been proposed since its inception in 1995. Inrecent years, these networks have become the state-of-the-art models for avariety of machine learning problems. This has led to a renewed interest inunderstanding the role and utility of various computational components oftypical LSTM variants. In this paper, we present the first large-scale analysisof eight LSTM variants on three representative tasks: speech recognition,handwriting recognition, and polyphonic music modeling. The hyperparameters ofall LSTM variants for each task were optimized separately using random search,and their importance was assessed using the powerful fANOVA framework. Intotal, we summarize the results of 5400 experimental runs ($\approx 15$ yearsof CPU time), which makes our study the largest of its kind on LSTM networks.Our results show that none of the variants can improve upon the standard LSTMarchitecture significantly, and demonstrate the forget gate and the outputactivation function to be its most critical components. We further observe thatthe studied hyperparameters are virtually independent and derive guidelines fortheir efficient adjustment."	Neural and Evolutionary Computing (cs.NE)	Machine Learning (cs.LG)
MomonariKudo	工藤 桃成 Momonari Kudo	237	186	"論文""Algorithmic study of superspecial hyperelliptic curves over finite fields"" (with Shushi Harashita)をarXivに公開しました。 https://t.co/9cDdmqX05F 一般種数の超楕円曲線のうちsuperspecialなものを数え上げるアルゴリズムと、超楕円曲線の自己同型群を計算するアルゴリズムを提案。"	2019/7/2 22:08	https://arxiv.org/abs/1907.00894	Algorithmic study of superspecial hyperelliptic curves over finite fields	"This paper presents algorithmic approaches to study superspecialhyperelliptic curves. The algorithms proposed in this paper are: an algorithmto enumerate superspecial hyperelliptic curves of genus $g$ over finite fields$\mathbb{F}_q$, and an algorithm to compute the automorphism group of a (notnecessarily superspecial) hyperelliptic curve over finite fields. The firstalgorithm works for any $(g,q)$ such that $q$ and $2g+2$ are coprime and$q>2g+1$. As an application, we enumerate superspecial hyperelliptic curves ofgenus $g=4$ over $\mathbb{F}_{p}$ for $11 \leq p \leq 23$ and over$\mathbb{F}_{p^2}$ for $11 \leq p \leq 19$ with our implementation on acomputer algebra system Magma. Moreover, we found maximal hyperelliptic curvesand minimal hyperelliptic curves over $\mathbb{F}_{p^2}$ from among enumeratedsuperspecial ones. The second algorithm computes an automorphism as a concreteelement in (a quotient of) a linear group in the general linear group of degree$2$."	Algebraic Geometry (math.AG)	Number Theory (math.NT)
re_hako_moon	はこつき＠VR	43	49	https://t.co/NKkjbUZ5e1 教師なし学習で三次元特徴点の検出器を学習。点群データセット中のモデルをランダムに剛体変換し、その剛体変換前後で変わらず検出できるような特徴点を検出する。一度局所点群から特徴点を計算し、改めて特徴点同士の相対位置を考慮して最終的な特徴点と信頼度を出力する。	2019/7/2 22:12	https://arxiv.org/abs/1904.00229	USIP: Unsupervised Stable Interest Point Detection from 3D Point Clouds	"In this paper, we propose the USIP detector: an Unsupervised Stable InterestPoint detector that can detect highly repeatable and accurately localizedkeypoints from 3D point clouds under arbitrary transformations without the needfor any ground truth training data. Our USIP detector consists of a featureproposal network that learns stable keypoints from input 3D point clouds andtheir respective transformed pairs from randomly generated transformations. Weprovide degeneracy analysis of our USIP detector and suggest solutions toprevent it. We encourage high repeatability and accurate localization of thekeypoints with a probabilistic chamfer loss that minimizes the distancesbetween the detected keypoints from the training point cloud pairs. Extensiveexperimental results of repeatability tests on several simulated and real-world3D point cloud datasets from Lidar, RGB-D and CAD models show that our USIPdetector significantly outperforms existing hand-crafted and deeplearning-based 3D keypoint detectors. Our code is available at the projectwebsite. this https URL"	Computer Vision and Pattern Recognition (cs.CV)	
akihiro_akichan	akihiro_f	122	118	https://t.co/hWzbQImOKV 画像中の重要人物を抽出するPOINTを提案。画像中の人物を全て抜き出した後にそれぞれの顔、周囲、位置の３つをまとめてCNNで特徴量化し、関係性を計算するRelation Moduleがコアか。Self-AttentionのようにQKVで関係性を取得するが３項の積でなくQV＋KVの定式化になっている。 https://t.co/5aezltGCqX	2019/7/2 22:22	https://arxiv.org/abs/1904.03632	Learning to Learn Relation for Important People Detection in Still Images	"Humans can easily recognize the importance of people in social event images,and they always focus on the most important individuals. However, learning tolearn the relation between people in an image, and inferring the most importantperson based on this relation, remains undeveloped. In this work, we propose adeep imPOrtance relatIon NeTwork (POINT) that combines both relation modelingand feature learning. In particular, we infer two types of interaction modules:the person-person interaction module that learns the interaction between peopleand the event-person interaction module that learns to describe how a person isinvolved in the event occurring in an image. We then estimate the importancerelations among people from both interactions and encode the relation featurefrom the importance relations. In this way, POINT automatically learns severaltypes of relation features in parallel, and we aggregate these relationfeatures and the person's feature to form the importance feature for importantpeople classification. Extensive experimental results show that our method iseffective for important people detection and verify the efficacy of learning tolearn relations for important people detection."	Computer Vision and Pattern Recognition (cs.CV)	
atsushieeeee	Atsushi Tabata	74	71	#ImageNet 単体だと、テクスチャの要因が強くなるが、style transferしたデータセットを合わせて学習することで、物体の特徴として形状も重視させることが可能に。よりロバストなモデルが作れる。https://t.co/SZKw1oea6P	2019/7/2 22:30	https://arxiv.org/abs/1811.12231	ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness	"Convolutional Neural Networks (CNNs) are commonly thought to recogniseobjects by learning increasingly complex representations of object shapes. Somerecent studies suggest a more important role of image textures. We here putthese conflicting hypotheses to a quantitative test by evaluating CNNs andhuman observers on images with a texture-shape cue conflict. We show thatImageNet-trained CNNs are strongly biased towards recognising textures ratherthan shapes, which is in stark contrast to human behavioural evidence andreveals fundamentally different classification strategies. We then demonstratethat the same standard architecture (ResNet-50) that learns a texture-basedrepresentation on ImageNet is able to learn a shape-based representationinstead when trained on ""Stylized-ImageNet"", a stylized version of ImageNet.This provides a much better fit for human behavioural performance in ourwell-controlled psychophysical lab setting (nine experiments totalling 48,560psychophysical trials across 97 observers) and comes with a number ofunexpected emergent benefits such as improved object detection performance andpreviously unseen robustness towards a wide range of image distortions,highlighting advantages of a shape-based representation."	Computer Vision and Pattern Recognition (cs.CV)	Artificial Intelligence (cs.AI);Machine Learning (cs.LG);Neurons and Cognition (q-bio.NC);Machine Learning (stat.ML)
shunk031	しゅんけー	"1,701"	667	DropConnect、お前もベイジアンニューラルネットだったんだな… https://t.co/cEEyDfcE1u	2019/7/2 23:10	https://arxiv.org/abs/1906.04569	DropConnect Is Effective in Modeling Uncertainty of Bayesian Deep Networks	"Deep neural networks (DNNs) have achieved state-of-the-art performances inmany important domains, including medical diagnosis, security, and autonomousdriving. In these domains where safety is highly critical, an erroneousdecision can result in serious consequences. While a perfect predictionaccuracy is not always achievable, recent work on Bayesian deep networks showsthat it is possible to know when DNNs are more likely to make mistakes. Knowingwhat DNNs do not know is desirable to increase the safety of deep learningtechnology in sensitive applications. Bayesian neural networks attempt toaddress this challenge. However, traditional approaches are computationallyintractable and do not scale well to large, complex neural networkarchitectures. In this paper, we develop a theoretical framework to approximateBayesian inference for DNNs by imposing a Bernoulli distribution on the modelweights. This method, called MC-DropConnect, gives us a tool to represent themodel uncertainty with little change in the overall model structure orcomputational cost. We extensively validate the proposed algorithm on multiplenetwork architectures and datasets for classification and semantic segmentationtasks. We also propose new metrics to quantify the uncertainty estimates. Thisenables an objective comparison between MC-DropConnect and prior approaches.Our empirical results demonstrate that the proposed framework yieldssignificant improvement in both prediction accuracy and uncertainty estimationquality compared to the state of the art."	Machine Learning (cs.LG)	Artificial Intelligence (cs.AI);Computer Vision and Pattern Recognition (cs.CV);Machine Learning (stat.ML)
KSKSKSKS2	katsugeneration	177	444	画像からキャプションを生成するタスクで、画像から複数のPOSタグのシーケンスを予測し、その情報をもとにキャプションを生成することにより、多様で精度の高いキャプションを既存手法より高速に生成する手法を提案した。 https://t.co/8wyBRnB3wt	2019/7/2 23:36	https://arxiv.org/abs/1805.12589	"Fast, Diverse and Accurate Image Captioning Guided By Part-of-Speech"	"Image captioning is an ambiguous problem, with many suitable captions for animage. To address ambiguity, beam search is the de facto method for samplingmultiple captions. However, beam search is computationally expensive and knownto produce generic captions. To address this concern, some variationalauto-encoder (VAE) and generative adversarial net (GAN) based methods have beenproposed. Though diverse, GAN and VAE are less accurate. In this paper, wefirst predict a meaningful summary of the image, then generate the captionbased on that summary. We use part-of-speech as summaries, since our summaryshould drive caption generation. We achieve the trifecta: (1) High accuracy forthe diverse captions as evaluated by standard captioning metrics and userstudies; (2) Faster computation of diverse captions compared to beam search anddiverse beam search; and (3) High diversity as evaluated by counting novelsentences, distinct n-grams and mutual overlap (i.e., mBleu-4) scores."	Computer Vision and Pattern Recognition (cs.CV)	
shion_honda	Shion Honda	"1,234"	242	"Triangulation Learning Network [Qin+, 2019, CVPR] 2Dステレオ画像を活用して3Dで物体検出を行うという研究。深さ情報を使わず、2枚の画像の差分から三角測量のように物体のアンカーの位置を推定するTLNetを提案。channel reweightingも提案。KITTIでSOTA。 https://t.co/75UuE3wqrb #NowReading https://t.co/aUe2WwgAuj"	2019/7/3 0:44	https://arxiv.org/abs/1906.01193	Triangulation Learning Network: from Monocular to Stereo 3D Object Detection	"In this paper, we study the problem of 3D object detection from stereoimages, in which the key challenge is how to effectively utilize stereoinformation. Different from previous methods using pixel-level depth maps, wepropose employing 3D anchors to explicitly construct object-levelcorrespondences between the regions of interest in stereo images, from whichthe deep neural network learns to detect and triangulate the targeted object in3D space. We also introduce a cost-efficient channel reweighting strategy thatenhances representational features and weakens noisy signals to facilitate thelearning process. All of these are flexibly integrated into a solid baselinedetector that uses monocular images. We demonstrate that both the monocularbaseline and the stereo triangulation learning network outperform the priorstate-of-the-arts in 3D object detection and localization on the challengingKITTI dataset."	Computer Vision and Pattern Recognition (cs.CV)	
daikinish	Daiki Nishiguchi	"1,562"	833	自分の論文が2つも、各々から図を引用されつつレビュー論文に出て来ると嬉しい…！ https://t.co/dy0GMmaJvV	2019/7/3 1:41	https://arxiv.org/abs/1907.00360	Self-Propelled Rods: Insights and Perspectives for Active Matter	"A wide range of experimental systems including gliding, swarming and swimmingbacteria, in-vitro motility assays as well as shaken granular media arecommonly described as self-propelled rods. Large ensembles of those entitiesdisplay a large variety of self-organized, collective phenomena, includingformation of moving polar clusters, polar and nematic dynamic bands,mobility-induced phase separation, topological defects and mesoscaleturbulence, among others. Here, we give a brief survey of experimentalobservations and review the theoretical description of self-propelled rods. Ourfocus is on the emergent pattern formation of ensembles of dry self-propelledrods governed by short-ranged, contact mediated interactions and their wetcounterparts that are also subject to long-ranged hydrodynamic flows.Altogether, self-propelled rods provide an overarching theme covering manyaspects of active matter containing well-explored limiting cases. Theircollective behavior not only bridges the well-studied regimes of polarself-propelled particles and active nematics, and includes active phaseseparation, but also reveals a rich variety of new patterns."	Statistical Mechanics (cond-mat.stat-mech)	Soft Condensed Matter (cond-mat.soft);Biological Physics (physics.bio-ph)
MikasorFlow	A$AP MIKA$A	42	117	Deterministic generation of a two-dimensional cluster state for universal quantum computing  これです  https://t.co/6PNE0gEafM	2019/7/3 2:29	https://arxiv.org/abs/1906.08709	Deterministic generation of a two-dimensional cluster state for universal quantum computing	"Measurement-based quantum computation offers exponential computationalspeed-up via simple measurements on a large entangled cluster state. We proposeand demonstrate a scalable scheme for the generation of photonic cluster statessuitable for universal measurement-based quantum computation. We exploittemporal multiplexing of squeezed light modes, delay loops, and beam-splittertransformations to deterministically generate a cylindrical cluster state witha two-dimensional (2D) topological structure as required for universal quantuminformation processing. The generated state consists of more than 30000entangled modes arranged in a cylindrical lattice with 24 modes on thecircumference, defining the input register, and a length of 1250 modes,defining the computation depth. Our demonstrated source of 2D cluster statescan be combined with quantum error correction based on theGottesman-Kitaev-Preskill qubit encoding to enable fault-tolerant quantumcomputation."	Quantum Physics (quant-ph)	Optics (physics.optics)
norarenmei1	おやー	36	428	数学の話でたので、久しぶりにポアンカレ予想証明論文にてをつけてる https://t.co/oaK9TElJ6m	2019/7/3 2:39					
kimar_iidx	未来に虹を架けよう	293	282	https://t.co/7LQ58MbWBB よくわからないまま読んでるんだけど引用が最近のばっかりでホットなんだなあと思っている	2019/7/3 4:19	https://arxiv.org/abs/1810.07258	Late-Time Observations of Type Ia Supernova SN 2014J with the Hubble Space Telescope Wide Field Camera 3	"Recent works have studied the late-time light curves of Type Ia supernovae(SNe Ia) when these were older than 500 days past B-band maximum light. Ofthese, SN 2014J, which exploded in the nearby galaxy M82, was studied with theAdvanced Camera for Surveys onboard the Hubble Space Telescope (HST) by Yang etal. Here, I report complementary photometry of SN 2014J taken with the HST WideField Camera 3 when it was ~360-1300 days old. My F555W measurements areconsistent with the F606W measurements of Yang et al., but the F438Wmeasurements are ~1 mag fainter than their F475W measurements. I corroboratetheir finding that even though SN 2014J has spatially resolved light echoes,its photometry is not contaminated by an unresolved echo. Finally, I comparethe F438W and F555W light curves of SN 2014J to those of the other late-timeSNe Ia observed to date and show that more intrinsically luminous SNe haveslower light-curve decline rates. This is consistent with the correlationclaimed by Graur et al., which was based on a comparison of pseudo-bolometriclight curves. By conducting a direct comparison of the late-time light curvesin the same filters, I remove any systematic uncertainties introduced by theassumptions that go into constructing the pseudo-bolometric light curves, thusstrengthening the Graur et al. claim."	High Energy Astrophysical Phenomena (astro-ph.HE)	Cosmology and Nongalactic Astrophysics (astro-ph.CO)
iBotamon	iBotamon???5 CVPR???	606	"1,861"	この論文は既製のEmbeddingを使わずにゼロベースでコーパスから構築している。OOV問題に対処しようとした？ https://t.co/0jvldDZtF8	2019/7/3 6:28	https://arxiv.org/abs/1708.09254	Interpretation of Mammogram and Chest X-Ray Reports Using Deep Neural Networks - Preliminary Results	"Radiology reports are an important means of communication betweenradiologists and other physicians. These reports express a radiologist'sinterpretation of a medical imaging examination and are critical inestablishing a diagnosis and formulating a treatment plan. In this paper, wepropose a Bi-directional convolutional neural network (Bi-CNN) model for theinterpretation and classification of mammograms based on breast density andchest radiographic radiology reports based on the basis of chest pathology. Theproposed approach helps to organize databases of radiology reports, retrievethem expeditiously, and evaluate the radiology report that could be used in anauditing system to decrease incorrect diagnoses. Our study revealed that theproposed Bi-CNN outperforms the random forest and the support vector machinemethods."	Computer Vision and Pattern Recognition (cs.CV)	
iBotamon	iBotamon???5 CVPR???	606	"1,861"	これも8万件のレポートからword2vecをゼロベースで構築している。このNeural-Attention Modelは上手く理解できていないけれどself-attentionっぽい？ https://t.co/Ij4vrTJ4PL	2019/7/3 7:38	https://arxiv.org/abs/1708.06828	Classification of Radiology Reports Using Neural Attention Models	"The electronic health record (EHR) contains a large amount ofmulti-dimensional and unstructured clinical data of significant operational andresearch value. Distinguished from previous studies, our approach embraces adouble-annotated dataset and strays away from obscure ""black-box"" models tocomprehensive deep learning models. In this paper, we present a novel neuralattention mechanism that not only classifies clinically important findings.Specifically, convolutional neural networks (CNN) with attention analysis areused to classify radiology head computed tomography reports based on fivecategories that radiologists would account for in assessing acute andcommunicable findings in daily practice. The experiments show that our CNNattention models outperform non-neural models, especially when trained on alarger dataset. Our attention analysis demonstrates the intuition behind theclassifier's decision by generating a heatmap that highlights attended termsused by the CNN model; this is valuable when potential downstream medicaldecisions are to be performed by human experts or the classifier information isto be used in cohort construction such as for epidemiological studies."	Computation and Language (cs.CL)	Artificial Intelligence (cs.AI);Information Retrieval (cs.IR)
barinoriron	てんにょ	"2,095"	301	またも FRB の母銀河特定。星形成率がとても低い銀河とのことで、発生源は old stellar population ではないかとのこと。  A fast radio burst localised to a massive galaxy　https://t.co/S7ikI0gg7O	2019/7/3 10:10	https://arxiv.org/abs/1907.01542	A fast radio burst localised to a massive galaxy	"Intense, millisecond-duration bursts of radio waves have been detected frombeyond the Milky Way [1]. Their extragalactic origins are evidenced by theirlarge dispersion measures, which are greater than expected for propagationthrough the Milky Way interstellar medium alone, and imply contributions fromthe intergalactic medium and potentially host galaxies [2]. Although severaltheories exist for the sources of these fast radio bursts, their intensities,durations and temporal structures suggest coherent emission from highlymagnetised plasma [3,4]. Two sources have been observed to repeat [5,6], andone repeater (FRB 121102) has been localised to the largest star-forming regionof a dwarf galaxy at a cosmological redshift of 0.19 [7, 8]. However, the hostgalaxies and distances of the so far non-repeating fast radio bursts are yet tobe identified. Unlike repeating sources, these events must be observed with aninterferometer with sufficient spatial resolution for arcsecond localisation atthe time of discovery. Here we report the localisation of a fast radio burst(FRB 190523) to a few-arcsecond region containing a single massive galaxy at aredshift of 0.66. This galaxy is in stark contrast to the host of FRB 121102,being a thousand times more massive, with a greater than hundred times lowerspecific star-formation rate. The properties of this galaxy highlight thepossibility of a channel for FRB production associated with older stellarpopulations."	High Energy Astrophysical Phenomena (astro-ph.HE)	Instrumentation and Methods for Astrophysics (astro-ph.IM)
monizuka	GPO: makoto onizuka	642	533	Graph U-Nets: graph pooling においてグラフそのものを縮退させるという大技を導入． https://t.co/JAwyqlGK6P	2019/7/3 11:17	https://arxiv.org/abs/1905.05178	Graph U-Nets	"We consider the problem of representation learning for graph data.Convolutional neural networks can naturally operate on images, but havesignificant challenges in dealing with graph data. Given images are specialcases of graphs with nodes lie on 2D lattices, graph embedding tasks have anatural correspondence with image pixel-wise prediction tasks such assegmentation. While encoder-decoder architectures like U-Nets have beensuccessfully applied on many image pixel-wise prediction tasks, similar methodsare lacking for graph data. This is due to the fact that pooling andup-sampling operations are not natural on graph data. To address thesechallenges, we propose novel graph pooling (gPool) and unpooling (gUnpool)operations in this work. The gPool layer adaptively selects some nodes to forma smaller graph based on their scalar projection values on a trainableprojection vector. We further propose the gUnpool layer as the inverseoperation of the gPool layer. The gUnpool layer restores the graph into itsoriginal structure using the position information of nodes selected in thecorresponding gPool layer. Based on our proposed gPool and gUnpool layers, wedevelop an encoder-decoder model on graph, known as the graph U-Nets. Ourexperimental results on node classification and graph classification tasksdemonstrate that our methods achieve consistently better performance thanprevious models."	Machine Learning (cs.LG)	Machine Learning (stat.ML)
masahiro_sakai	Masahiro Sakai	"1,787"	"1,333"	Principled Deep Neural Network Training through Linear Programming https://t.co/MciqNOXhEi NNの学習(経験損失の最小化)を、2進近似の上で木分解を使って指数的サイズのLPに帰着。直接実用的には使えなさそうで、理論的な洞察に繋がると良いと思うのだけど、自分はあまり理解できてない………	2019/7/3 11:49	https://arxiv.org/abs/1810.03218	Principled Deep Neural Network Training through Linear Programming	"Deep Learning has received significant attention due to its impressiveperformance in many state-of-the-art learning tasks. Unfortunately, while verypowerful, Deep Learning is not well understood theoretically and in particularonly recently results for the complexity of training deep neural networks havebeen obtained. In this work we show that large classes of deep neural networkswith various architectures (e.g., DNNs, CNNs, Binary Neural Networks, andResNets), activation functions (e.g., ReLUs and leaky ReLUs), and lossfunctions (e.g., Hinge loss, Euclidean loss, etc) can be trained to nearoptimality with desired target accuracy using linear programming in time thatis exponential in the input data and parameter space dimension and polynomialin the size of the data set; improvements of the dependence in the inputdimension are known to be unlikely assuming $P\neq NP$, and improving thedependence on the parameter space dimension remains open. In particular, weobtain polynomial time algorithms for training for a given fixed networkarchitecture. Our work applies more broadly to empirical risk minimizationproblems which allows us to generalize various previous results and obtain newcomplexity results for previously unstudied architectures in the properlearning setting."	Machine Learning (cs.LG)	Optimization and Control (math.OC);Machine Learning (stat.ML)
Soliton111	Soliton	78	96	half-BPS op.の4点関数において、特別なR-charge polarizationかつ各BPS状態が非常に重い極限をとれば、4点関数の計算は八角形ダイアグラムの二乗に比例した形でかけるらしい。 で、可積分系テクニックをつかえば、all loopの計算が可能とのこと。  https://t.co/TsADi5yrat https://t.co/WKRsKv4Deu	2019/7/3 12:01	"https://arxiv.org/abs/1903.05038, https://arxiv.org/abs/1905.11467"	"Determinant formula for the octagon form factor in $\mathcal{N}$=4 SYM, The Octagon as a Determinant"	"We compute to all loop orders correlation function of four heavy BPSoperators in $\mathcal{N}$= 4 SYM with special polarisations consideredrecently by Frank Coronado. Our main result is an expression for the octagonform factor as determinant of a semi-infinite matrix. We find that at weakcoupling the entries of this matrix are linear combinations of ladder functionswith simple rational coefficients and give the full perturbative expansion ofthe octagon., The computation of a certain class of four-point functions of heavily chargedBPS operators boils down to the computation of a special form factor - theoctagon. In this paper, which is an extended version of the short note [1], wederive a non-perturbative formula for the square of the octagon as thedeterminant of a semi-infinite skew-symmetric matrix. We show thatperturbatively in the weak coupling limit the octagon is given by a determinantconstructed from the polylogarithms evaluating ladder Feynman graphs. We alsogive a simple operator representation of the octagon in terms of a vacuumexpectation value of massless free bosons or fermions living in the rapidityplane."	"High Energy Physics - Theory (hep-th), High Energy Physics - Theory (hep-th)"	
yu4u	Yusuke Uchida	"4,447"	950	なんかすごいでかい（語彙）カメラ画像からのOCRのためのデータセット (ICDAR 2019) https://t.co/ouadk3eKGj / Brno Mobile OCR Dataset https://t.co/QpvuoNRLKB https://t.co/XYQJkfZgSn	2019/7/3 12:07	https://arxiv.org/abs/1907.01307	Brno Mobile OCR Dataset	"We introduce the Brno Mobile OCR Dataset (B-MOD) for document OpticalCharacter Recognition from low-quality images captured by handheld mobiledevices. While OCR of high-quality scanned documents is a mature field wheremany commercial tools are available, and large datasets of text in the wildexist, no existing datasets can be used to develop and test document OCRmethods robust to non-uniform lighting, image blur, strong noise, built-indenoising, sharpening, compression and other artifacts present in manyphotographs from mobile devices.This dataset contains 2 113 unique pages from random scientific papers, whichwere photographed by multiple people using 23 different mobile devices. Theresulting 19 728 photographs of various visual quality are accompanied byprecise positions and text annotations of 500k text lines. We further providean evaluation methodology, including an evaluation server and a testset withnon-public annotations.We provide a state-of-the-art text recognition baseline build onconvolutional and recurrent neural networks trained with Connectionist TemporalClassification loss. This baseline achieves 2 %, 22 % and 73 % word error rateson easy, medium and hard parts of the dataset, respectively, confirming thatthe dataset is challenging.The presented dataset will enable future development and evaluation ofdocument analysis for low-quality images. It is primarily intended forline-level text recognition, and can be further used for line localization,layout analysis, image restoration and text binarization."	Computer Vision and Pattern Recognition (cs.CV)	
esXFdfOJxiGBFLx	人工知能 Deep Learning AI image medical machine learni	858	"1,901"	マルチGANによるパッチベースでの高解像度医用画像の生成に関するarXivです。 生成に関してはパッチにして計算コストの大きい3DCTや胸部X戦に対応させて、マルチにすることで性能を向上させつつってことだと思うけど、その画像をどう扱うべきかは医師は困りそうではある。 https://t.co/cGgBUpB9gr	2019/7/3 12:33	https://arxiv.org/abs/1907.01376	Multi-scale GANs for Memory-efficient Generation of High Resolution Medical Images	"Currently generative adversarial networks (GANs) are rarely applied tomedical images of large sizes, especially 3D volumes, due to their largecomputational demand. We propose a novel multi-scale patch-based GAN approachto generate large high resolution 2D and 3D images. Our key idea is to firstlearn a low-resolution version of the image and then generate patches ofsuccessively growing resolutions conditioned on previous scales. In a domaintranslation use-case scenario, 3D thorax CTs of size 512x512x512 and thoraxX-rays of size 2048x2048 are generated and we show that, due to the constantGPU memory demand of our method, arbitrarily large images of high resolutioncan be generated. Moreover, compared to common patch-based approaches, ourmulti-resolution scheme enables better image quality and prevents patchartifacts."	Image and Video Processing (eess.IV)	Computer Vision and Pattern Recognition (cs.CV)
hiropon_matsu	HIROPON	88	412	"Bengio Prigogineなんかも引かれている。 ""Learning the Arrow of Time."" https://t.co/YaJ8KQ9jOG"	2019/7/3 13:05	https://arxiv.org/abs/1907.01285	Learning the Arrow of Time	"We humans seem to have an innate understanding of the asymmetric progressionof time, which we use to efficiently and safely perceive and manipulate ourenvironment. Drawing inspiration from that, we address the problem of learningan arrow of time in a Markov (Decision) Process. We illustrate how a learnedarrow of time can capture meaningful information about the environment, whichin turn can be used to measure reachability, detect side-effects and to obtainan intrinsic reward signal. We show empirical results on a selection ofdiscrete and continuous environments, and demonstrate for a class of stochasticprocesses that the learned arrow of time agrees reasonably well with a knownnotion of an arrow of time given by the celebrated Jordan-Kinderlehrer-Ottoresult."	Machine Learning (cs.LG)	Artificial Intelligence (cs.AI)
Kenji_Sugisaki	杉﨑 研司 (Kenji Sugisaki)	360	127	Symmetry Configuration Mapping for Compact Representation of Quantum Chemistry on Quantum Computers https://t.co/KDRvoIXPCC あとで読む。	2019/7/3 14:19	https://arxiv.org/abs/1907.01493	Symmetry Configuration Mapping for Compact Representation of Quantum Chemistry on Quantum Computers	"Near-term quantum computers may be able to significantly speed up complexcomputational tasks, but algorithms that make efficient use of quantumresources are needed. Quantum chemistry is widely regarded as a candidate forthe first demonstration of quantum advantage with near-term quantum computers.In the present work, we demonstrate how taking advantage of the symmetries of amolecule leads to a reduction in the number of qubits required. This reductionin qubits also leads to a reduction in the number of variational parametersneeded to reach chemical accuracy. Furthermore, we show how a simplemodification of the hardware-efficient ansatz for the variational quantumeigensolver yields a factor of 3 reduction in the number of parameters with noloss in accuracy for most problems in quantum chemistry."	Quantum Physics (quant-ph)	
norihitoishida	Norihito Ishida	256	509	https://t.co/IsfZTzv1VF L2正則化はバッチ正規化と一緒にやっても意味なし　覚えました	2019/7/3 14:26	https://arxiv.org/abs/1706.05350	L2 Regularization versus Batch and Weight Normalization	"Batch Normalization is a commonly used trick to improve the training of deepneural networks. These neural networks use L2 regularization, also calledweight decay, ostensibly to prevent overfitting. However, we show that L2regularization has no regularizing effect when combined with normalization.Instead, regularization has an influence on the scale of weights, and therebyon the effective learning rate. We investigate this dependence, both in theory,and experimentally. We show that popular optimization methods such as ADAM onlypartially eliminate the influence of normalization on the learning rate. Thisleads to a discussion on other ways to mitigate this issue."	Machine Learning (cs.LG)	Machine Learning (stat.ML)
takasan_san_san	Kazuaki Takasan / 高三 和晃	"1,622"	"2,005"	arXivはこちら High-frequency Expansion for Floquet Prethermal Phases with Emergent Symmetries: Application to Time Crystals and Floquet Engineering https://t.co/IUURrEbvM5	2019/7/3 15:39	https://arxiv.org/abs/1902.01126	High-frequency Expansion for Floquet Prethermal Phases with Emergent Symmetries: Application to Time Crystals and Floquet Engineering	"Prethermalization, where quasi-steady states are realized in the intermediatelong time regime (prethermal regime), in periodically driven (Floquet) systemsis an important phenomenon since it provides a platform of nontrivial Floquetmany-body physics. In this Letter, we consider Floquet systems with dual energyscales: the Hamiltonian consists of two different terms whose amplitude iseither comparable or much smaller than the frequency. As a result, when thelarger-amplitude drive induces a \mathbb{Z}_N symmetry operation, we obtain theeffective static Hamiltonian respecting a new emergent \mathbb{Z}_N symmetry inhigh frequency expansions, which describes the dynamics of such Floquet systemsin the prethermal regime. As an application of our formulation, we considerprethermal discrete time crystals, in which our formalism gives a general wayto analyze them in the prethermal regime in terms of the static effectiveHamiltonian. We also provide an application to Floquet engineering, with whichwe can perform simultaneous control of phases and symmetries of the systems.This enables us to control symmetry protected topological phases even when theoriginal system does not respect the symmetry."	Mesoscale and Nanoscale Physics (cond-mat.mes-hall)	Other Condensed Matter (cond-mat.other);Statistical Mechanics (cond-mat.stat-mech)
emerson_et_al	えまーそん	224	199	久々に単著出してみました https://t.co/m6sltV5S0m	2019/7/3 17:26	https://arxiv.org/abs/1907.00993	Dynamical Emergence of Scalaron in Higgs Inflation	"We point out that a light scalaron dynamically emerges if scalar fields havea sizable non-minimal coupling to the Ricci scalar as in the Higgs inflationmodel. We support this claim in two ways. One is based on the renormalizationgroup equation; the non-minimal coupling inevitably induces a Ricci scalarquadratic term due to the renormalization group running. The other is based onscattering amplitudes; a scalar four-point amplitude develops a pole aftersumming over a certain class of diagrams, which we identify as the scalaron.Our result implies that the Higgs inflation is actually a two-fieldinflationary model. Another implication is that the Higgs inflation does notsuffer from the unitarity issue since the scalaron pushes up the cut-off scaleto the Planck scale."	High Energy Physics - Phenomenology (hep-ph)	Cosmology and Nongalactic Astrophysics (astro-ph.CO);General Relativity and Quantum Cosmology (gr-qc);High Energy Physics - Theory (hep-th)
NH_M_	Nm?m	"1,131"	427	"Lohitsiri, Tong. Hypercharge Quantisation and Fermat's Last Theorem https://t.co/FWLFdrxm6y 素粒子標準模型とフェルマーの最終定理の関係性が見つかったようです。ハイパーチャージ量子化、ゲージアノマリー相殺、そしてフェルマーの最終定理によって、標準模型の電荷を導出できることがわかった"	2019/7/3 18:06	https://arxiv.org/abs/1907.00514	Hypercharge Quantisation and Fermat's Last Theorem	"What values of the Standard Model hypercharges result in a mathematicallyconsistent quantum field theory? We show that the constraints imposed by thelack of gauge anomalies can be recast as the equation x^3 + y^3 = z^3. Ifhypercharge is quantised, then x, y and z must be integers. The trivial (andonly) solutions, with x=0 or y=0, reproduce the hypercharge assignments seen inNature. This argument does not rely on the mixed gauge-gravitational anomaly,which is automatically vanishing if hypercharge is quantised and the gaugeanomalies vanish."	High Energy Physics - Theory (hep-th)	High Energy Physics - Phenomenology (hep-ph)
hiromichinomata	H. NOMATA	627	979	予測外したときの責任重大感 https://t.co/SoJBAw3bCg	2019/7/3 18:29	https://arxiv.org/abs/1906.11893	HalalNet: A Deep Neural Network that Classifies the Halalness Slaughtered Chicken from their Images	"Halal requirement in food is important for millions of Muslims worldwideespecially for meat and chicken products, insuring that slaughter houses adhereto this requirement is a challenging task to do manually. In this paper amethod is proposed that uses a camera that takes images of slaughtered chickenon the conveyor in a slaughter house, the images are then analyzed by a deepneural network to classify if the image is of a halal slaughtered chicken ornot. However, traditional deep learning models require large amounts of data totrain on, which in this case these amounts of data were challenging to collectespecially the images of non-halal slaughtered chicken, hence this paper showshow the use of one shot learning [1] and transfer learning [2] can reach highaccuracy on the few amounts of data that were available. The architecture usedis based on the Siamese neural networks architecture which ranks the similaritybetween two inputs [3] while using the Xception network [4] as the twinnetworks. We call it HalalNet. This work was done as part of SYCUT (syriahcompliant slaughtering system) which is a monitoring system that monitors thehalalness of the slaughtered chicken in a slaughter house. The data used totrain and validate HalalNet was collected from the Azain slaughtering site(Semenyih, Selangor, Malaysia) containing images of both halal and non-halalslaughtered chicken."	Computer Vision and Pattern Recognition (cs.CV)	Image and Video Processing (eess.IV)
phasetr	相転移P	"3,355"	"1,313"	@yaschan__ https://t.co/EjqSvfadpv もあります。	2019/7/3 19:26					
Dave50425992	Dave@AQUA	128	516	@TaneoKoyama タンパク質の相性？ 生物的なことはわかんないけど、求まる解はハミルトニアンが1番小さい状態(要はエネルギー的に1番安定な状態)だよね。  他のNP問題の解法どうぞ。 https://t.co/eN4Cf7KuBq	2019/7/3 19:33	https://arxiv.org/abs/1302.5843	Ising formulations of many NP problems	"We provide Ising formulations for many NP-complete and NP-hard problems,including all of Karp's 21 NP-complete problems. This collects and extendsmappings to the Ising model from partitioning, covering and satisfiability. Ineach case, the required number of spins is at most cubic in the size of theproblem. This work may be useful in designing adiabatic quantum optimizationalgorithms."	Statistical Mechanics (cond-mat.stat-mech)	Computational Complexity (cs.CC);Data Structures and Algorithms (cs.DS);Quantum Physics (quant-ph)
tenityu	Takayuki Tanabe?	69	119	メモリアロケーターごとの比較ベンチみたいなものってどこで手に入りますかね．．．_mm_malloc の性能が知りたい．今年の SIGMOD ポスターでこれ (https://t.co/PPfECiiQBB ) の発展版は見たんですけど，_mm_malloc が入ってなくて．	2019/7/3 19:38	https://arxiv.org/abs/1905.01135	On the Impact of Memory Allocation on High-Performance Query Processing	"Somewhat surprisingly, the behavior of analytical query engines is cruciallyaffected by the dynamic memory allocator used. Memory allocators highlyinfluence performance, scalability, memory efficiency and memory fairness toother processes. In this work, we provide the first comprehensive experimentalanalysis on the impact of memory allocation for high-performance query engines.We test five state-of-the-art dynamic memory allocators and discuss theirstrengths and weaknesses within our DBMS. The right allocator can increase theperformance of TPC-DS (SF 100) by 2.7x on a 4-socket Intel Xeon server."	Databases (cs.DB)	Performance (cs.PF)
shion_honda	Shion Honda	"1,234"	242	"Deep Drug-Target Binding Affinity Prediction [Ozturk+, 2018, Bioinfo.] タンパク質と化合物の文字列表現をそれぞれCNNでencodeし、それらをDNNに入力して両者の結合を予測するDeepDTAを提案。DavisとKIBAで評価し、CNNの表現学習による精度を確認した。 https://t.co/qTi58Aj5fv #NowReading https://t.co/kVxWkurbrq"	2019/7/3 21:21	https://arxiv.org/abs/1801.10193	DeepDTA: Deep Drug-Target Binding Affinity Prediction	"The identification of novel drug-target (DT) interactions is a substantialpart of the drug discovery process. Most of the computational methods that havebeen proposed to predict DT interactions have focused on binary classification,where the goal is to determine whether a DT pair interacts or not. However,protein-ligand interactions assume a continuum of binding strength values, alsocalled binding affinity and predicting this value still remains a challenge.The increase in the affinity data available in DT knowledge-bases allows theuse of advanced learning techniques such as deep learning architectures in theprediction of binding affinities. In this study, we propose a deep-learningbased model that uses only sequence information of both targets and drugs topredict DT interaction binding affinities. The few studies that focus on DTbinding affinity prediction use either 3D structures of protein-ligandcomplexes or 2D features of compounds. One novel approach used in this work isthe modeling of protein sequences and compound 1D representations withconvolutional neural networks (CNNs). The results show that the proposed deeplearning based model that uses the 1D representations of targets and drugs isan effective approach for drug target binding affinity prediction. The model inwhich high-level representations of a drug and a target are constructed viaCNNs achieved the best Concordance Index (CI) performance in one of our largerbenchmark data sets, outperforming the KronRLS algorithm and SimBoost, astate-of-the-art method for DT binding affinity prediction."	Machine Learning (stat.ML)	Machine Learning (cs.LG)
mocobt	mocobt??	225	454	分子構造の学習でGCNは使われていたり。 https://t.co/l78WSOUKkN #xpaperchallenge	2019/7/3 21:22	https://arxiv.org/abs/1805.11973	MolGAN: An implicit generative model for small molecular graphs	"Deep generative models for graph-structured data offer a new angle on theproblem of chemical synthesis: by optimizing differentiable models thatdirectly generate molecular graphs, it is possible to side-step expensivesearch procedures in the discrete and vast space of chemical structures. Weintroduce MolGAN, an implicit, likelihood-free generative model for smallmolecular graphs that circumvents the need for expensive graph matchingprocedures or node ordering heuristics of previous likelihood-based methods.Our method adapts generative adversarial networks (GANs) to operate directly ongraph-structured data. We combine our approach with a reinforcement learningobjective to encourage the generation of molecules with specific desiredchemical properties. In experiments on the QM9 chemical database, wedemonstrate that our model is capable of generating close to 100% validcompounds. MolGAN compares favorably both to recent proposals that usestring-based (SMILES) representations of molecules and to a likelihood-basedmethod that directly generates graphs, albeit being susceptible to modecollapse."	Machine Learning (stat.ML)	Machine Learning (cs.LG)
akihiro_akichan	akihiro_f	122	118	https://t.co/SwjxcFA9jQ 料理画像から材料と作り方を生成する研究。ResNetで特徴量を抽出して材料を推定、Transformer Decoderで再帰的に作り方を構成、という作りになっている。ドメイン絞れば、材料のレコメンドくらいには使えそう。料理写真から材料推定→カロリー計算とかできないかな https://t.co/TorBPMRQCS	2019/7/3 21:25	https://arxiv.org/abs/1812.06164	Inverse Cooking: Recipe Generation from Food Images	"People enjoy food photography because they appreciate food. Behind each mealthere is a story described in a complex recipe and, unfortunately, by simplylooking at a food image we do not have access to its preparation process.Therefore, in this paper we introduce an inverse cooking system that recreatescooking recipes given food images. Our system predicts ingredients as sets bymeans of a novel architecture, modeling their dependencies without imposing anyorder, and then generates cooking instructions by attending to both image andits inferred ingredients simultaneously. We extensively evaluate the wholesystem on the large-scale Recipe1M dataset and show that (1) we improveperformance w.r.t. previous baselines for ingredient prediction; (2) we areable to obtain high quality recipes by leveraging both image and ingredients;(3) our system is able to produce more compelling recipes than retrieval-basedapproaches according to human judgment. We make code and models publiclyavailable."	Computer Vision and Pattern Recognition (cs.CV)	
s_aiueo32	さしすせ	325	430	GraphSAGEと同じ著者なのか - https://t.co/m6InY1gbBT #xpaperchallenge	2019/7/3 21:32	https://arxiv.org/abs/1806.01445	Embedding Logical Queries on Knowledge Graphs	"Learning low-dimensional embeddings of knowledge graphs is a powerfulapproach used to predict unobserved or missing edges between entities. However,an open challenge in this area is developing techniques that can go beyondsimple edge prediction and handle more complex logical queries, which mightinvolve multiple unobserved edges, entities, and variables. For instance, givenan incomplete biological knowledge graph, we might want to predict ""em whatdrugs are likely to target proteins involved with both diseases X and Y?"" -- aquery that requires reasoning about all possible proteins that {\em might}interact with diseases X and Y. Here we introduce a framework to efficientlymake predictions about conjunctive logical queries -- a flexible but tractablesubset of first-order logic -- on incomplete knowledge graphs. In our approach,we embed graph nodes in a low-dimensional space and represent logical operatorsas learned geometric operations (e.g., translation, rotation) in this embeddingspace. By performing logical operations within a low-dimensional embeddingspace, our approach achieves a time complexity that is linear in the number ofquery variables, compared to the exponential complexity required by a naiveenumeration-based approach. We demonstrate the utility of this framework in twoapplication studies on real-world datasets with millions of relations:predicting logical relationships in a network of drug-gene-disease interactionsand in a graph-based representation of social interactions derived from apopular web forum."	Social and Information Networks (cs.SI)	Machine Learning (cs.LG);Machine Learning (stat.ML)
yoshi_and_aki	Yoshi-aki Shimada	624	831	"ISCA2019のMartonoshiグループの「Full-Stack, Real-System Quantum Computer Studies」なかなか面白い。Rigetti（超伝導）, IBM（超伝導）, UMD（イオントラップ）の量子コンピュータを複数のプログラムで性能比較。UMDマシンが良いっぽいなぁ。https://t.co/AsuLErJ0Xg"	2019/7/3 22:13	https://arxiv.org/abs/1905.11349	"Full-Stack, Real-System Quantum Computer Studies: Architectural Comparisons and Design Insights"	"In recent years, Quantum Computing (QC) has progressed to the point wheresmall working prototypes are available for use. Termed Noisy Intermediate-ScaleQuantum (NISQ) computers, these prototypes are too small for large benchmarksor even for Quantum Error Correction, but they do have sufficient resources torun small benchmarks, particularly if compiled with optimizations to make useof scarce qubits and limited operation counts and coherence times. QC has notyet, however, settled on a particular preferred device implementationtechnology, and indeed different NISQ prototypes implement qubits with verydifferent physical approaches and therefore widely-varying device and machinecharacteristics.Our work performs a full-stack, benchmark-driven hardware-software analysisof QC systems. We evaluate QC architectural possibilities, software-visiblegates, and software optimizations to tackle fundamental design questions aboutgate set choices, communication topology, the factors affecting benchmarkperformance and compiler optimizations. In order to answer key cross-technologyand cross-platform design questions, our work has built the first top-to-bottomtoolflow to target different qubit device technologies, includingsuperconducting and trapped ion qubits which are the current QC front-runners.We use our toolflow, TriQ, to conduct {\em real-system} measurements on 7running QC prototypes from 3 different groups, IBM, Rigetti, and University ofMaryland. From these real-system experiences at QC's hardware-softwareinterface, we make observations about native and software-visible gates fordifferent QC technologies, communication topologies, and the value ofnoise-aware compilation even on lower-noise platforms. This is the largestcross-platform real-system QC study performed thus far; its results have thepotential to inform both QC device and compiler design going forward."	Quantum Physics (quant-ph)	
tomonoritotani	"戸谷友則 (TOTANI, Tomonori)"	352	0	https://t.co/VTFF77PRiE 先日ツイートした、単発の高速電波バーストとして始めて FRB 180924 に母銀河が同定されたというニュースに続き、別チームが FRB 190523 の母銀河を同定。こちらも、大きめで星形成をあまりしていない銀河ということで、古い星種族からの FRB を支持。	2019/7/3 23:04	https://arxiv.org/abs/1907.01542	A fast radio burst localised to a massive galaxy	"Intense, millisecond-duration bursts of radio waves have been detected frombeyond the Milky Way [1]. Their extragalactic origins are evidenced by theirlarge dispersion measures, which are greater than expected for propagationthrough the Milky Way interstellar medium alone, and imply contributions fromthe intergalactic medium and potentially host galaxies [2]. Although severaltheories exist for the sources of these fast radio bursts, their intensities,durations and temporal structures suggest coherent emission from highlymagnetised plasma [3,4]. Two sources have been observed to repeat [5,6], andone repeater (FRB 121102) has been localised to the largest star-forming regionof a dwarf galaxy at a cosmological redshift of 0.19 [7, 8]. However, the hostgalaxies and distances of the so far non-repeating fast radio bursts are yet tobe identified. Unlike repeating sources, these events must be observed with aninterferometer with sufficient spatial resolution for arcsecond localisation atthe time of discovery. Here we report the localisation of a fast radio burst(FRB 190523) to a few-arcsecond region containing a single massive galaxy at aredshift of 0.66. This galaxy is in stark contrast to the host of FRB 121102,being a thousand times more massive, with a greater than hundred times lowerspecific star-formation rate. The properties of this galaxy highlight thepossibility of a channel for FRB production associated with older stellarpopulations."	High Energy Astrophysical Phenomena (astro-ph.HE)	Instrumentation and Methods for Astrophysics (astro-ph.IM)
Soliton111	Soliton	78	96	fishnet theoryのholographic dual(?)できてたのかw 作用は近接相互作用をもつ点粒子の集まりのものでかけて、ある意味でAdS5上のstringを離散化したものとみなせるみたいですね。 順当ではある。  https://t.co/om99PMTzke https://t.co/mfsaUU2Zmv	2019/7/3 23:15	"https://arxiv.org/abs/1903.10508, https://arxiv.org/abs/1907.01001"	"The Holographic Fishchain, Quantum Fishchain in $AdS_5$"	"We present the first-principle derivation of a weak-strong duality betweenthe fishnet theory in four dimensions and a discretized string-like modelliving in five dimensions. At strong coupling, the dual description becomesclassical and we demonstrate explicitly the classical integrability of themodel. We test our results by reproducing the strong coupling limit of the$4$-point correlator computed before non-perturbatively from the conformalpartial wave expansion. Due to the extreme simplicity of our model, it couldprovide an ideal playground for holography with no super-symmetry. Furthermore,since the fishnet model and ${\cal N}=4$ SYM theory are continuously linked ourconsideration could shed light on the derivation of AdS/CFT for the latter., In our previous paper we derived the holographic dual of the planar fishnetCFT in four dimensions. The dual model becomes classical in the stronglycoupled regime of the CFT and takes the form of an integrable chain ofparticles in five dimensions. Here we study the theory at the quantum level. Byapplying the canonical quantization procedure with constraints, we show thatthe model describes a quantum chain of particles propagating in $AdS_5$. Weprove the duality at the full quantum level in the ${\mathfrak u}(1)$ sectorand reproduce exactly the spectrum for the cases when it is known analytically."	"High Energy Physics - Theory (hep-th), High Energy Physics - Theory (hep-th)"	"Mathematical Physics (math-ph), Mathematical Physics (math-ph)"
nyker_goto	ニューヨーカーGOTO	798	735	2009年時点で https://t.co/Pbodg8v9bU にて bottoun 先生があげていた shuffle が良い理由も2015年に https://t.co/aCYn2Z3FHI で少し明らかになったりしているので SGD にはまだ改善の余地があると信じている。	2019/7/4 0:59	https://arxiv.org/abs/1510.08560	Why Random Reshuffling Beats Stochastic Gradient Descent	"We analyze the convergence rate of the random reshuffling (RR) method, whichis a randomized first-order incremental algorithm for minimizing a finite sumof convex component functions. RR proceeds in cycles, picking a uniformlyrandom order (permutation) and processing the component functions one at a timeaccording to this order, i.e., at each cycle, each component function issampled without replacement from the collection. Though RR has been numericallyobserved to outperform its with-replacement counterpart stochastic gradientdescent (SGD), characterization of its convergence rate has been a longstanding open question. In this paper, we answer this question by showing thatwhen the component functions are quadratics or smooth and the sum function isstrongly convex, RR with iterate averaging and a diminishing stepsize$\alpha_k=\Theta(1/k^s)$ for $s\in (1/2,1)$ converges at rate$\Theta(1/k^{2s})$ with probability one in the suboptimality of the objectivevalue, thus improving upon the $\Omega(1/k)$ rate of SGD. Our analysis draws onthe theory of Polyak-Ruppert averaging and relies on decoupling the dependentcycle gradient error into an independent term over cycles and another termdominated by $\alpha_k^2$. This allows us to apply law of large numbers to anappropriately weighted version of the cycle gradient errors, where the weightsdepend on the stepsize. We also provide high probability convergence rateestimates that shows decay rate of different terms and allows us to propose amodification of RR with convergence rate ${\cal O}(\frac{1}{k^2})$."	Optimization and Control (math.OC)	
cygnusgm	アルミニ	366	898	The Physics of baking good Pizza https://t.co/iS9z7wweNn 　　　↑ ギガジンで解説している元論文  ちょっと前にはオムレツを流体力学で焼こうとしてた論文があったな? https://t.co/SD4JbrT4at	2019/7/4 1:26	https://arxiv.org/abs/1806.08790	The Physics of baking good Pizza	"Physical principles are involved in almost any aspect of cooking. Here weanalyze the specific process of baking pizzas, deriving in simple terms thebaking times for two different situations: For a brick oven in a pizzeria and amodern metallic oven at home. Our study is based on basic thermodynamicprinciples relevant to the cooking process and is accessible to undergraduatestudents. We start with a historical overview of the development and art ofpizza baking, illustrate the underlying physics by some simple common examples,and then apply them in detail to the example of baking pizza."	Popular Physics (physics.pop-ph)	
udoooom	うどん	"1,871"	"1,938"	ESPNetの論文中にはTitanXで112FPSと書かれてるが，1080Tiだと116fps出るし凄まじい しかも精度も良い... https://t.co/cOSZAyefIJ	2019/7/4 1:26	https://arxiv.org/abs/1803.06815	ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation	"We introduce a fast and efficient convolutional neural network, ESPNet, forsemantic segmentation of high resolution images under resource constraints.ESPNet is based on a new convolutional module, efficient spatial pyramid (ESP),which is efficient in terms of computation, memory, and power. ESPNet is 22times faster (on a standard GPU) and 180 times smaller than thestate-of-the-art semantic segmentation network PSPNet, while its category-wiseaccuracy is only 8% less. We evaluated ESPNet on a variety of semanticsegmentation datasets including Cityscapes, PASCAL VOC, and a breast biopsywhole slide image dataset. Under the same constraints on memory andcomputation, ESPNet outperforms all the current efficient CNN networks such asMobileNet, ShuffleNet, and ENet on both standard metrics and our newlyintroduced performance metrics that measure efficiency on edge devices. Ournetwork can process high resolution images at a rate of 112 and 9 frames persecond on a standard GPU and edge device, respectively."	Computer Vision and Pattern Recognition (cs.CV)	
subarusatosi	中嶋慧	"3,333"	23	素粒子論にフェルマーの最終定理が関係してたら面白いなと思った事はあるけど、本当に関係しているのか… https://t.co/c8qMC1bbD3	2019/7/4 3:17	https://arxiv.org/abs/1907.00514	Hypercharge Quantisation and Fermat's Last Theorem	"What values of the Standard Model hypercharges result in a mathematicallyconsistent quantum field theory? We show that the constraints imposed by thelack of gauge anomalies can be recast as the equation x^3 + y^3 = z^3. Ifhypercharge is quantised, then x, y and z must be integers. The trivial (andonly) solutions, with x=0 or y=0, reproduce the hypercharge assignments seen inNature. This argument does not rely on the mixed gauge-gravitational anomaly,which is automatically vanishing if hypercharge is quantised and the gaugeanomalies vanish."	High Energy Physics - Theory (hep-th)	High Energy Physics - Phenomenology (hep-ph)
tonagai	tomo	406	88	AI ファインマン - 測定データ列から、一体どんな関数になっているかを推定する。プランクの法則とか見つけられる？ 論文：AI Feynman: a Physics-Inspired Method for Symbolic Regression https://t.co/iilSfGQvsL サイト：Feynman Symbolic Regression Database https://t.co/2iS7ZgQCDD	2019/7/4 6:52	https://arxiv.org/abs/1905.11481	AI Feynman: a Physics-Inspired Method for Symbolic Regression	"A core challenge for both physics and artificial intellicence (AI) issymbolic regression: finding a symbolic expression that matches data from anunknown function. Although this problem is likely to be NP-hard in principle,functions of practical interest often exhibit symmetries, separability,compositionality and other simplifying properties. In this spirit, we develop arecursive multidimensional symbolic regression algorithm that combines neuralnetwork fitting with a suite of physics-inspired techniques. We apply it to 100equations from the Feynman Lectures on Physics, and it discovers all of them,while previous publicly available software cracks only 71; for a more difficulttest set, we improve the state of the art success rate from 15% to 90%."	Computational Physics (physics.comp-ph)	Artificial Intelligence (cs.AI);Machine Learning (cs.LG);High Energy Physics - Theory (hep-th)
1789aorhow	まきゃ	325	241	https://t.co/a5oEYFz2HM 出社したらこれコピーする	2019/7/4 7:54	https://arxiv.org/abs/1907.00514	Hypercharge Quantisation and Fermat's Last Theorem	"What values of the Standard Model hypercharges result in a mathematicallyconsistent quantum field theory? We show that the constraints imposed by thelack of gauge anomalies can be recast as the equation x^3 + y^3 = z^3. Ifhypercharge is quantised, then x, y and z must be integers. The trivial (andonly) solutions, with x=0 or y=0, reproduce the hypercharge assignments seen inNature. This argument does not rely on the mixed gauge-gravitational anomaly,which is automatically vanishing if hypercharge is quantised and the gaugeanomalies vanish."	High Energy Physics - Theory (hep-th)	High Energy Physics - Phenomenology (hep-ph)
haruhiko_nishi	Haruhiko Nishi	69	177	https://t.co/4yktLkbaTX @sasaism 今度教えて下さい。	2019/7/4 7:58	https://arxiv.org/abs/1803.02194	Bidding Machine: Learning to Bid for Directly Optimizing Profits in Display Advertising	"Real-time bidding (RTB) based display advertising has become one of the keytechnological advances in computational advertising. RTB enables advertisers tobuy individual ad impressions via an auction in real-time and facilitates theevaluation and the bidding of individual impressions across multipleadvertisers. In RTB, the advertisers face three main challenges when optimizingtheir bidding strategies, namely (i) estimating the utility (e.g., conversions,clicks) of the ad impression, (ii) forecasting the market value (thus the cost)of the given ad impression, and (iii) deciding the optimal bid for the givenauction based on the first two. Previous solutions assume the first two aresolved before addressing the bid optimization problem. However, thesechallenges are strongly correlated and dealing with any individual problemindependently may not be globally optimal. In this paper, we propose BiddingMachine, a comprehensive learning to bid framework, which consists of threeoptimizers dealing with each challenge above, and as a whole, jointly optimizesthese three parts. We show that such a joint optimization would largelyincrease the campaign effectiveness and the profit. From the learningperspective, we show that the bidding machine can be updated smoothly with bothoffline periodical batch or online sequential training schemes. Our extensiveoffline empirical study and online A/B testing verify the high effectiveness ofthe proposed bidding machine."	Computer Science and Game Theory (cs.GT)	Computers and Society (cs.CY);Information Retrieval (cs.IR);Machine Learning (cs.LG)
syuntoku14	しゅんとく	609	673	https://t.co/wCUPhNRqMj  これ、safe rlの中でもかなりシンプルかつ強そうなのですごい(小学生)	2019/7/4 8:30	https://arxiv.org/abs/1801.08757	Safe Exploration in Continuous Action Spaces	"We address the problem of deploying a reinforcement learning (RL) agent on aphysical system such as a datacenter cooling unit or robot, where criticalconstraints must never be violated. We show how to exploit the typically smoothdynamics of these systems and enable RL algorithms to never violate constraintsduring learning. Our technique is to directly add to the policy a safety layerthat analytically solves an action correction formulation per each state. Thenovelty of obtaining an elegant closed-form solution is attained due to alinearized model, learned on past trajectories consisting of arbitrary actions.This is to mimic the real-world circumstances where data logs were generatedwith a behavior policy that is implausible to describe mathematically; suchcases render the known safety-aware off-policy methods inapplicable. Wedemonstrate the efficacy of our approach on new representative physics-basedenvironments, and prevail where reward shaping fails by maintaining zeroconstraint violations."	Artificial Intelligence (cs.AI)	
yu4u	Yusuke Uchida	"4,447"	950	tf-liteの話かな。The Minimum-Cost Flow Algorithmとかでてくるし、やはり人類は全てのCS分野に精通すべきと思ってしまう / “[1907.01989] On-Device Neural Net Inference with Mobile GPUs” https://t.co/y94j8xJrTK	2019/7/4 9:54	https://arxiv.org/abs/1907.01989	On-Device Neural Net Inference with Mobile GPUs	"On-device inference of machine learning models for mobile phones is desirabledue to its lower latency and increased privacy. Running such acompute-intensive task solely on the mobile CPU, however, can be difficult dueto limited computing power, thermal constraints, and energy consumption. Appdevelopers and researchers have begun exploiting hardware accelerators toovercome these challenges. Recently, device manufacturers are adding neuralprocessing units into high-end phones for on-device inference, but theseaccount for only a small fraction of hand-held devices. In this paper, wepresent how we leverage the mobile GPU, a ubiquitous hardware accelerator onvirtually every phone, to run inference of deep neural networks in real-timefor both Android and iOS devices. By describing our architecture, we alsodiscuss how to design networks that are mobile GPU-friendly. Ourstate-of-the-art mobile GPU inference engine is integrated into the open-sourceproject TensorFlow Lite and publicly available at this https URL."	"Distributed, Parallel, and Cluster Computing (cs.DC)"	Computer Vision and Pattern Recognition (cs.CV);Machine Learning (cs.LG);Machine Learning (stat.ML)
_tkato_	tkato	763	308	これおもしろいよ https://t.co/UXXrW86qKt	2019/7/4 10:14	https://arxiv.org/abs/1907.01989	On-Device Neural Net Inference with Mobile GPUs	"On-device inference of machine learning models for mobile phones is desirabledue to its lower latency and increased privacy. Running such acompute-intensive task solely on the mobile CPU, however, can be difficult dueto limited computing power, thermal constraints, and energy consumption. Appdevelopers and researchers have begun exploiting hardware accelerators toovercome these challenges. Recently, device manufacturers are adding neuralprocessing units into high-end phones for on-device inference, but theseaccount for only a small fraction of hand-held devices. In this paper, wepresent how we leverage the mobile GPU, a ubiquitous hardware accelerator onvirtually every phone, to run inference of deep neural networks in real-timefor both Android and iOS devices. By describing our architecture, we alsodiscuss how to design networks that are mobile GPU-friendly. Ourstate-of-the-art mobile GPU inference engine is integrated into the open-sourceproject TensorFlow Lite and publicly available at this https URL."	"Distributed, Parallel, and Cluster Computing (cs.DC)"	Computer Vision and Pattern Recognition (cs.CV);Machine Learning (cs.LG);Machine Learning (stat.ML)
fkm	fkm	891	168	MLの手法を使ってソート、やってみた人いるんだ https://t.co/L2yd7QRHJg	2019/7/4 10:22	https://arxiv.org/abs/1805.04272	An $O(N)$ Sorting Algorithm: Machine Learning Sort	"We propose an $O(N\cdot M)$ sorting algorithm by Machine Learning method,which shows a huge potential sorting big data. This sorting algorithm can beapplied to parallel sorting and is suitable for GPU or TPU acceleration.Furthermore, we discuss the application of this algorithm to sparse hash table."	Machine Learning (cs.LG)	Data Structures and Algorithms (cs.DS);Machine Learning (stat.ML)
hobbymath2020	hobbymath	81	55	プレプリント  “A New Lower Bound for Kullback-Leibler Divergence Based on Hammersley-Chapman-Robbins Bound”  https://t.co/fZ4WciPrEI  に対するサンプルコードを公開しました。 https://t.co/tQR2pB709O	2019/7/4 12:04	https://arxiv.org/abs/1907.00288	A New Lower Bound for Kullback-Leibler Divergence Based on Hammersley-Chapman-Robbins Bound	"In this paper, we derive a useful lower bound for the Kullback-Leiblerdivergence (KL-divergence) based on the Hammersley-Chapman-Robbins bound(HCRB). The HCRB states that the variance of an estimator is bounded from belowby the Chi-square divergence and the expectation value of the estimator. Byusing the relation between the KL-divergence and the Chi-square divergence, weshow that the lower bound for the KL-divergence which only depends on theexpectation value and the variance of a function we choose. We show that theequality holds for the Bernoulli distributions and show that the inequalityconverges to the Cram?r-Rao bound when two distributions are very close.Furthermore, we describe application examples and examples of numericalcalculation."	Statistics Theory (math.ST)	Information Theory (cs.IT);Machine Learning (stat.ML)
TsuguoMogami	mogami290	12	10	DL without Weight Transport: https://t.co/V13lBlig9f やっぱり眠っている間にランダム発火を使って行列から転置行列にweightを転写できるとう話だ。私の１３年前に書いたこれ https://t.co/gc3FgmrwOt と同じアイデア。やられた。	2019/7/4 13:13	https://arxiv.org/abs/1904.05391	Deep Learning without Weight Transport	"Current algorithms for deep learning probably cannot run in the brain becausethey rely on weight transport, where forward-path neurons transmit theirsynaptic weights to a feedback path, in a way that is likely impossiblebiologically. An algorithm called feedback alignment achieves deep learningwithout weight transport by using random feedback weights, but it performspoorly on hard visual-recognition tasks. Here we describe two mechanisms - aneural circuit called a weight mirror and a modification of an algorithmproposed by Kolen and Pollack in 1994 - both of which let the feedback pathlearn appropriate synaptic weights quickly and accurately even in largenetworks, without weight transport or complex wiring.Tested on the ImageNetvisual-recognition task, these mechanisms outperform both feedback alignmentand the newer sign-symmetry method, and nearly match backprop, the standardalgorithm of deep learning, which uses weight transport."	Machine Learning (cs.LG)	Machine Learning (stat.ML)
benkyouaho	Io NGS	153	178	quark hadron dualityについて https://t.co/fdzO5VC9GC  あとで読む	2019/7/4 14:01	https://arxiv.org/abs/hep-ph/0009131	[hep-ph/0009131] Quark-Hadron Duality	"I review the notion of the quark-hadron duality from the modern perspective.Both, the theoretical foundation and practical applications are discussed. Theproper theoretical framework in which the problem can be formulated and treatedis Wilson's operator product expansion (OPE). Two models developed for thedescription of duality violations are considered in some detail: one isinstanton-based, another resonance-based. The mechanisms they represent arecomplementary. Although both models are rather primitive (their largest virtueis their simplicity) they hopefully capture important features of thephenomenon. Being open for improvements, they can be used ""as is"" fororientation in the studies of duality violations in the processes of practicalinterest."	High Energy Physics - Phenomenology (hep-ph)	
KUNImt_Sun	陸〇	276	357	めっちゃ現場感あるやつみつけた 例えばSEMとかで十分条件ベースではパスモデルを作らない場合に識別条件引っかかるときの最後段階的フィルタリングみたいな形ですぐ使えるやつだなこれは https://t.co/jEBoDMj3MI	2019/7/4 17:40	https://arxiv.org/abs/1907.01654	Adjustment Criteria for Recovering Causal Effects from Missing Data	"Confounding bias, missing data, and selection bias are three common obstaclesto valid causal inference in the data sciences. Covariate adjustment is themost pervasive technique for recovering casual effects from confounding bias.In this paper, we introduce a covariate adjustment formulation for controllingconfounding bias in the presence of missing-not-at-random data and develop anecessary and sufficient condition for recovering causal effects using theadjustment. We also introduce an adjustment formulation for controlling bothconfounding and selection biases in the presence of missing data and develop anecessary and sufficient condition for valid adjustment. Furthermore, wepresent an algorithm that lists all valid adjustment sets and an algorithm thatfinds a valid adjustment set containing the minimum number of variables, whichare useful for researchers interested in selecting adjustment sets with desiredproperties."	Machine Learning (cs.LG)	Machine Learning (stat.ML)
jaguring1	小猫遊りょう（たかにゃし・りょう）	"2,601"	191	Hypercharge Quantisation and Fermat's Last Theorem https://t.co/JQG4yiJYMM フェルマーの最終定理が道具として使われた事例。一見すると、あんな役に立たなさそうな定理でさえ、他分野で使われていく。これが数学の面白さの一側面だと思っている。	2019/7/4 17:43	https://arxiv.org/abs/1907.00514	Hypercharge Quantisation and Fermat's Last Theorem	"What values of the Standard Model hypercharges result in a mathematicallyconsistent quantum field theory? We show that the constraints imposed by thelack of gauge anomalies can be recast as the equation x^3 + y^3 = z^3. Ifhypercharge is quantised, then x, y and z must be integers. The trivial (andonly) solutions, with x=0 or y=0, reproduce the hypercharge assignments seen inNature. This argument does not rely on the mixed gauge-gravitational anomaly,which is automatically vanishing if hypercharge is quantised and the gaugeanomalies vanish."	High Energy Physics - Theory (hep-th)	High Energy Physics - Phenomenology (hep-ph)
subarusatosi	中嶋慧	"3,333"	23	“Hypercharge Quantisation and Fermat's Last Theorem” https://t.co/c8qMC1bbD3  ハイパーチャージのパラメーターは5つがあるが、(1)より3つに落ちる。(2)は3パラメーターの3次式となる。 ハイパーチャージの量子化を仮定すると、フェルマーの最終定理(n = 3)より、ハイパーチャージが決まる。 https://t.co/uu5gwGvglK	2019/7/4 18:01	https://arxiv.org/abs/1907.00514	Hypercharge Quantisation and Fermat's Last Theorem	"What values of the Standard Model hypercharges result in a mathematicallyconsistent quantum field theory? We show that the constraints imposed by thelack of gauge anomalies can be recast as the equation x^3 + y^3 = z^3. Ifhypercharge is quantised, then x, y and z must be integers. The trivial (andonly) solutions, with x=0 or y=0, reproduce the hypercharge assignments seen inNature. This argument does not rely on the mixed gauge-gravitational anomaly,which is automatically vanishing if hypercharge is quantised and the gaugeanomalies vanish."	High Energy Physics - Theory (hep-th)	High Energy Physics - Phenomenology (hep-ph)
enakalle	梅谷 武	419	51	Neural Decipherment via Minimum-Cost Flow: from Ugaritic to Linear B https://t.co/hfoCTLNZLx  ＜言語学はこういうことがやりやすい分野なので、若い方はこの方向を目指すという選択肢も検討すべきかもしれない。	2019/7/4 18:31	https://arxiv.org/abs/1906.06718	Neural Decipherment via Minimum-Cost Flow: from Ugaritic to Linear B	"In this paper we propose a novel neural approach for automatic deciphermentof lost languages. To compensate for the lack of strong supervision signal, ourmodel design is informed by patterns in language change documented inhistorical linguistics. The model utilizes an expressive sequence-to-sequencemodel to capture character-level correspondences between cognates. Toeffectively train the model in an unsupervised manner, we innovate the trainingprocedure by formalizing it as a minimum-cost flow problem. When applied to thedecipherment of Ugaritic, we achieve a 5.5% absolute improvement overstate-of-the-art results. We also report the first automatic results indeciphering Linear B, a syllabic language related to ancient Greek, where ourmodel correctly translates 67.3% of cognates."	Computation and Language (cs.CL)	
mimura8322	Yukihiro MIMURA	42	121	“Hypercharge Quantisation and Fermat's Last Theorem” (https://t.co/XyQxxHlhpu)  / ハイパーチャージがU(1)の既約表現なら、表現の準同型写像が正しく定義されるためには電荷（の比）は有理数である。よって、著者はチャージの量子化の条件をもっと磨くべきである。（ほら日本語ならまだ字数余る）	2019/7/4 19:54	https://arxiv.org/abs/1907.00514	Hypercharge Quantisation and Fermat's Last Theorem	"What values of the Standard Model hypercharges result in a mathematicallyconsistent quantum field theory? We show that the constraints imposed by thelack of gauge anomalies can be recast as the equation x^3 + y^3 = z^3. Ifhypercharge is quantised, then x, y and z must be integers. The trivial (andonly) solutions, with x=0 or y=0, reproduce the hypercharge assignments seen inNature. This argument does not rely on the mixed gauge-gravitational anomaly,which is automatically vanishing if hypercharge is quantised and the gaugeanomalies vanish."	High Energy Physics - Theory (hep-th)	High Energy Physics - Phenomenology (hep-ph)
re_hako_moon	はこつき＠VR	43	49	https://t.co/iaNhd5K2Uy 弱教師あり学習による三次元点群のセグメンテーション手法．一貫したセグメンテーション結果となるよう，Consistency Scoreを導入してオンラインで整合するように最適化する．	2019/7/4 20:27	https://arxiv.org/abs/1903.10297	CoSegNet: Deep Co-Segmentation of 3D Shapes with Group Consistency Loss	"We introduce CoSegNet, a deep neural network architecture for co-segmentationof a set of 3D shapes represented as point clouds. CoSegNet takes as input aset of unsegmented shapes, proposes per-shape parts, and then jointly optimizesthe part labelings across the set subjected to a novel group consistency lossexpressed via matrix rank estimates. The proposals are refined in eachiteration by an auxiliary network that acts as a weak regularizing prior,pre-trained to denoise noisy, unlabeled parts from a large collection ofsegmented 3D shapes, where the part compositions within the same objectcategory can be highly inconsistent. The output is a consistent part labelingfor the input set, with each shape segmented into up to K (a user-specifiedhyperparameter) parts. The overall pipeline is thus weakly supervised,producing consistent segmentations tailored to the test set, without consistentground-truth segmentations. We show qualitative and quantitative results fromCoSegNet and evaluate it via ablation studies and comparisons tostate-of-the-art co-segmentation methods."	Computer Vision and Pattern Recognition (cs.CV)	Graphics (cs.GR)
Lepidoptera2015	あおすじあげはちょう	290	347	https://t.co/Kf1BB6p5IY deepの学習をfrank wolfeベースのアルゴリズムにすることで、stepsizeがclosed formで求まり、パラメータ一つ決めればlrの微調整頑張らなくてよく、SGDと同程度の性能が出るよという主張、ICLR19	2019/7/4 22:23	https://arxiv.org/abs/1811.07591	Deep Frank-Wolfe For Neural Network Optimization	"Learning a deep neural network requires solving a challenging optimizationproblem: it is a high-dimensional, non-convex and non-smooth minimizationproblem with a large number of terms. The current practice in neural networkoptimization is to rely on the stochastic gradient descent (SGD) algorithm orits adaptive variants. However, SGD requires a hand-designed schedule for thelearning rate. In addition, its adaptive variants tend to produce solutionsthat generalize less well on unseen data than SGD with a hand-designedschedule. We present an optimization method that offers empirically the best ofboth worlds: our algorithm yields good generalization performance whilerequiring only one hyper-parameter. Our approach is based on a compositeproximal framework, which exploits the compositional nature of deep neuralnetworks and can leverage powerful convex optimization algorithms by design.Specifically, we employ the Frank-Wolfe (FW) algorithm for SVM, which computesan optimal step-size in closed-form at each time-step. We further show that thedescent direction is given by a simple backward pass in the network, yieldingthe same computational cost per iteration as SGD. We present experiments on theCIFAR and SNLI data sets, where we demonstrate the significant superiority ofour method over Adam, Adagrad, as well as the recently proposed BPGrad andAMSGrad. Furthermore, we compare our algorithm to SGD with a hand-designedlearning rate schedule, and show that it provides similar generalization whileconverging faster. The code is publicly available atthis https URL."	Machine Learning (cs.LG)	Machine Learning (stat.ML)
hsntdo	Hoshino Tadao	286	100	やっぱり既にあるようだ https://t.co/kG2sBHooYj	2019/7/4 23:56	https://arxiv.org/abs/1610.01271	Generalized Random Forests	"We propose generalized random forests, a method for non-parametricstatistical estimation based on random forests (Breiman, 2001) that can be usedto fit any quantity of interest identified as the solution to a set of localmoment equations. Following the literature on local maximum likelihoodestimation, our method considers a weighted set of nearby training examples;however, instead of using classical kernel weighting functions that are proneto a strong curse of dimensionality, we use an adaptive weighting functionderived from a forest designed to express heterogeneity in the specifiedquantity of interest. We propose a flexible, computationally efficientalgorithm for growing generalized random forests, develop a large sample theoryfor our method showing that our estimates are consistent and asymptoticallyGaussian, and provide an estimator for their asymptotic variance that enablesvalid confidence intervals. We use our approach to develop new methods forthree statistical tasks: non-parametric quantile regression, conditionalaverage partial effect estimation, and heterogeneous treatment effectestimation via instrumental variables. A software implementation, grf for R andC++, is available from CRAN."	Methodology (stat.ME)	Econometrics (econ.EM);Machine Learning (stat.ML)
TomiyaAkio	3刷出ます「ディープラーニングと物理学」 A.Tomiya	"1,262"	504	@astrophys_tan えぇ、それですね https://t.co/FMIPxvKSst  色々と文献読んでて、引いてない奴も多いんですが、説明を聞いた中ではそれが分かり良かった気がします。	2019/7/5 0:21	https://arxiv.org/abs/1110.4732	Maxwell's Demon and Data Compression	"In an asymmetric Szilard engine model of Maxwell's demon, we show theequivalence between information theoretical and thermodynamic entropies whenthe demon erases information optimally. The work gain by the engine can beexactly canceled out by the work necessary to reset demon's memory afteroptimal data compression a la Shannon before the erasure."	Classical Physics (physics.class-ph)	Statistical Mechanics (cond-mat.stat-mech);History and Philosophy of Physics (physics.hist-ph)
pacifinapacific	ぱしふぃん	266	543	https://t.co/MCFPySL4fO Person Re-identificationでGeneratorによる画像生成と識別を同一ネットワークで扱う仕組みを提案。生成された画像を効果的に用いることで精度向上に寄与(CVPR 2019 oral)	2019/7/5 1:11	https://arxiv.org/abs/1904.07223	Joint Discriminative and Generative Learning for Person Re-identification	"Person re-identification (re-id) remains challenging due to significantintra-class variations across different cameras. Recently, there has been agrowing interest in using generative models to augment training data andenhance the invariance to input changes. The generative pipelines in existingmethods, however, stay relatively separate from the discriminative re-idlearning stages. Accordingly, re-id models are often trained in astraightforward manner on the generated data. In this paper, we seek to improvelearned re-id embeddings by better leveraging the generated data. To this end,we propose a joint learning framework that couples re-id learning and datageneration end-to-end. Our model involves a generative module that separatelyencodes each person into an appearance code and a structure code, and adiscriminative module that shares the appearance encoder with the generativemodule. By switching the appearance or structure codes, the generative moduleis able to generate high-quality cross-id composed images, which are online fedback to the appearance encoder and used to improve the discriminative module.The proposed joint learning framework renders significant improvement over thebaseline without using generated data, leading to the state-of-the-artperformance on several benchmark datasets."	Computer Vision and Pattern Recognition (cs.CV)	
mocobt	mocobt??	225	454	なんかHMMってぐらふっぽいしGNNと組み合わせた方法とかあるのかなと調べてみたら，先月発表された手法があった． やっぱ温故知新というか，昔の理論って大事な感じある．  [Qu et al. arXiv 2019] https://t.co/e5BX1rYl9x	2019/7/5 2:38	https://arxiv.org/abs/1905.06214	GMNN: Graph Markov Neural Networks	"This paper studies semi-supervised object classification in relational data,which is a fundamental problem in relational data modeling. The problem hasbeen extensively studied in the literature of both statistical relationallearning (e.g. relational Markov networks) and graph neural networks (e.g.graph convolutional networks). Statistical relational learning methods caneffectively model the dependency of object labels through conditional randomfields for collective classification, whereas graph neural networks learneffective object representations for classification through end-to-endtraining. In this paper, we propose the Graph Markov Neural Network (GMNN) thatcombines the advantages of both worlds. A GMNN models the joint distribution ofobject labels with a conditional random field, which can be effectively trainedwith the variational EM algorithm. In the E-step, one graph neural networklearns effective object representations for approximating the posteriordistributions of object labels. In the M-step, another graph neural network isused to model the local label dependency. Experiments on object classification,link classification, and unsupervised node representation learning show thatGMNN achieves state-of-the-art results."	Machine Learning (cs.LG)	Social and Information Networks (cs.SI);Machine Learning (stat.ML)
MasakiTaniguch4	Masaki Taniguchi	20	16	https://t.co/G3dBMgwAHD のCor Dが以前考えたことに似ている… Gromovノルムを使うとは…	2019/7/5 4:47	https://arxiv.org/abs/1804.03777	Equivariant hyperbolization of $3$-manifolds via homology cobordisms	"The main result of this paper is that any $3$-dimensional manifold with afinite group action is equivariantly, invertibly homology cobordant to ahyperbolic manifold; this result holds with suitable twisted coefficients aswell. The following two consequences motivated this work. First, there arehyperbolic equivariant corks (as defined in previous work of the authors) for awide class of finite groups. Second, any finite group that acts on a homology$3$-sphere also acts on a hyperbolic homology $3$-sphere. The theorem has otherapplications, including establishing the existence of an infinite number ofhyperbolic homology spheres with a free $Z_p$ action that does not extend toany contractible manifold. A non-equivariant version yields an infinite numberof hyperbolic integer homology spheres that bound integer homology balls but donot bound contractible manifolds. In passing, it is shown that the invertiblehomology cobordism relation on $3$-manifolds is antisymmetric."	Geometric Topology (math.GT)	Differential Geometry (math.DG)
hackernewsj	Hacker News記事題日本語翻訳	605	4	GraphQLへの移行：実用的評価 https://t.co/nrwQkSPqTz	2019/7/5 7:18	https://arxiv.org/abs/1906.07535	Migrating to GraphQL: A Practical Assessment	"GraphQL is a novel query language proposed by Facebook to implement Web-basedAPIs. In this paper, we present a practical study on migrating API clients tothis new technology. First, we conduct a grey literature review to gain anin-depth understanding on the benefits and key characteristics normallyassociated to GraphQL by practitioners. After that, we assess such benefits inpractice, by migrating seven systems to use GraphQL, instead of standardREST-based APIs. As our key result, we show that GraphQL can reduce the size ofthe JSON documents returned by REST APIs in 94% (in number of fields) and in99% (in number of bytes), both median results."	Software Engineering (cs.SE)	
hillbig	Daisuke Okanohara	"15,910"	254	様々な形状の点群の生成モデルとしてPointFlowを提案。形状を表す潜在変数を生成し、それから連続正規化フローのダイナミクスを作り、それに基づき事前分布の点群を目的の形状に変化させる。変分法を使った最尤推定で直接学習可能 https://t.co/VxHqZ7zKL7 https://t.co/KffYbQsKPf	2019/7/5 10:02	https://arxiv.org/abs/1906.12320	PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows	"As 3D point clouds become the representation of choice for multiple visionand graphics applications, the ability to synthesize or reconstructhigh-resolution, high-fidelity point clouds becomes crucial. Despite the recentsuccess of deep learning models in discriminative tasks of point clouds,generating point clouds remains challenging. This paper proposes a principledprobabilistic framework to generate 3D point clouds by modeling them as adistribution of distributions. Specifically, we learn a two-level hierarchy ofdistributions where the first level is the distribution of shapes and thesecond level is the distribution of points given a shape. This formulationallows us to both sample shapes and sample an arbitrary number of points from ashape. Our generative model, named PointFlow, learns each level of thedistribution with a continuous normalizing flow. The invertibility ofnormalizing flows enables the computation of the likelihood during training andallows us to train our model in the variational inference framework.Empirically, we demonstrate that PointFlow achieves state-of-the-artperformance in point cloud generation. We additionally show that our model canfaithfully reconstruct point clouds and learn useful representations in anunsupervised manner. The code will be available atthis https URL."	Computer Vision and Pattern Recognition (cs.CV)	Machine Learning (cs.LG)
yu4u	Yusuke Uchida	"4,447"	950	攻めてる / “[1907.02124] Non-structured DNN Weight Pruning Considered Harmful” https://t.co/llPs9QQClG	2019/7/5 10:24	https://arxiv.org/abs/1907.02124	Non-structured DNN Weight Pruning Considered Harmful	"Large deep neural network (DNN) models pose the key challenge to energyefficiency due to the significantly higher energy consumption of off-chip DRAMaccesses than arithmetic or SRAM operations. It motivates the intensiveresearch on model compression with two main approaches. Weight pruningleverages the redundancy in the number of weights and can be performed in anon-structured, which has higher flexibility and pruning rate but incurs indexaccesses due to irregular weights, or structured manner, which preserves thefull matrix structure with lower pruning rate. Weight quantization leveragesthe redundancy in the number of bits in weights. Compared to pruning,quantization is much more hardware-friendly, and has become a ""must-do"" stepfor FPGA and ASIC implementations. This paper provides a definitive answer tothe question for the first time. First, we build ADMM-NN-S by extending andenhancing ADMM-NN, a recently proposed joint weight pruning and quantizationframework. Second, we develop a methodology for fair and fundamental comparisonof non-structured and structured pruning in terms of both storage andcomputation efficiency. Our results show that ADMM-NN-S consistentlyoutperforms the prior art: (i) it achieves 348x, 36x, and 8x overall weightpruning on LeNet-5, AlexNet, and ResNet-50, respectively, with (almost) zeroaccuracy loss; (ii) we demonstrate the first fully binarized (for all layers)DNNs can be lossless in accuracy in many cases. These results provide a strongbaseline and credibility of our study. Based on the proposed comparisonframework, with the same accuracy and quantization, the results show thatnon-structrued pruning is not competitive in terms of both storage andcomputation efficiency. Thus, we conclude that non-structured pruning isconsidered harmful. We urge the community not to continue the DNN inferenceacceleration for non-structured sparsity."	Machine Learning (cs.LG)	Computer Vision and Pattern Recognition (cs.CV);Neural and Evolutionary Computing (cs.NE);Machine Learning (stat.ML)
masashiotani	マサシ	91	92	落とされたが、とりあえずarxivには出した。 https://t.co/drG5Ce7QoZ	2019/7/5 10:55	https://arxiv.org/abs/1907.02235	Compact buncher cavity for muons accelerated by a radio-frequency quadrupole	"A buncher cavity has been developed for the muons accelerated by aradio-frequency quadrupole linac (RFQ). The buncher cavity is designed for$\beta=v/c=0.04$ at an operational frequency of 324 MHz. It employs adouble-gap structure operated in the TEM mode for the required effectivevoltage with compact dimensions, in order to account for the limited space ofthe experiment. The measured resonant frequency and unloaded quality factor are323.95 MHz and $3.06\times10^3$, respectively. The buncher cavity wassuccessfully operated for longitudinal bunch size measurement of the muonsaccelerated by the RFQ."	Accelerator Physics (physics.acc-ph)	High Energy Physics - Experiment (hep-ex)
Vengineer	ソースコード解析職人	"1,664"	80	"論文は、これみたい。 「Deep Learning Inference in Facebook Data Centers: Characterization, Performance Optimizations and Hardware Implications」 https://t.co/GLpQDxD0Jo https://t.co/gPHmPPWEzW"	2019/7/5 11:32	https://arxiv.org/abs/1811.09886	"Deep Learning Inference in Facebook Data Centers: Characterization, Performance Optimizations and Hardware Implications"	"The application of deep learning techniques resulted in remarkableimprovement of machine learning models. In this paper provides detailedcharacterizations of deep learning models used in many Facebook social networkservices. We present computational characteristics of our models, describe highperformance optimizations targeting existing systems, point out theirlimitations and make suggestions for the future general-purpose/acceleratedinference hardware. Also, we highlight the need for better co-design ofalgorithms, numerics and computing platforms to address the challenges ofworkloads often run in data centers."	Machine Learning (cs.LG)	Machine Learning (stat.ML)
udoooom	うどん	"1,871"	"1,938"	Long-Term Feature Banks，今更知ったが発想シンプルで時間特徴をうまい感じに使ってるの凄いなと今更思った  https://t.co/GA7OxgDxmF	2019/7/5 12:25	https://arxiv.org/abs/1812.05038	Long-Term Feature Banks for Detailed Video Understanding	"To understand the world, we humans constantly need to relate the present tothe past, and put events in context. In this paper, we enable existing videomodels to do the same. We propose a long-term feature bank---supportiveinformation extracted over the entire span of a video---to augmentstate-of-the-art video models that otherwise would only view short clips of 2-5seconds. Our experiments demonstrate that augmenting 3D convolutional networkswith a long-term feature bank yields state-of-the-art results on threechallenging video datasets: AVA, EPIC-Kitchens, and Charades."	Computer Vision and Pattern Recognition (cs.CV)	
hhhhhhaaaaaa2	h.a.	339	524	Dirac magnons in a honeycomb lattice quantum XY magnet CoTiO3 https://t.co/DXLcOaTGZf Dirac magnonなんてのがあるんか	2019/7/5 14:02	https://arxiv.org/abs/1907.02061	Dirac magnons in a honeycomb lattice quantum XY magnet CoTiO3	"The discovery of massless Dirac electrons in graphene and topologicalDirac-Weyl materials has prompted a broad search for bosonic analogues of suchDirac particles. Recent experiments have found evidence for Dirac magnons abovean Ising-like ferromagnetic ground state in a two-dimensional (2D) kagomelattice magnet and in the van der Waals layered honeycomb crystal CrI$_3$, andin a 3D Heisenberg magnet Cu$_3$TeO$_6$. Here we report on our inelasticneutron scattering investigation on large single crystals of a stackedhoneycomb lattice magnet CoTiO$_3$, which is part of a broad family of ilmenitematerials. The magnetically ordered ground state of CoTiO$_3$ featuresferromagnetic layers of Co$^{2+}$, stacked antiferromagnetically along the$c$-axis. We discover that the magnon dispersion relation exhibits strongeasy-plane exchange anisotropy and hosts a clear gapless Dirac cone along theedge of the 3D Brillouin zone. Our results establish CoTiO$_3$ as a modelpseudospin-$1/2$ material to study interacting Dirac bosons in a 3D quantum XYmagnet."	Strongly Correlated Electrons (cond-mat.str-el)	
norihitoishida	Norihito Ishida	263	521	Dance Dance Convolution（CNN+conditional LSTMでDDRの自動譜面作成） https://t.co/vSItn8u5rM  DeepXさんの実装 https://t.co/X6WRvvTGM1	2019/7/5 14:49	https://arxiv.org/abs/1703.06891	Dance Dance Convolution	"Dance Dance Revolution (DDR) is a popular rhythm-based video game. Playersperform steps on a dance platform in synchronization with music as directed byon-screen step charts. While many step charts are available in standardizedpacks, players may grow tired of existing charts, or wish to dance to a songfor which no chart exists. We introduce the task of learning to choreograph.Given a raw audio track, the goal is to produce a new step chart. This taskdecomposes naturally into two subtasks: deciding when to place steps anddeciding which steps to select. For the step placement task, we combinerecurrent and convolutional neural networks to ingest spectrograms of low-levelaudio features to predict steps, conditioned on chart difficulty. For stepselection, we present a conditional LSTM generative model that substantiallyoutperforms n-gram and fixed-window approaches."	Machine Learning (cs.LG)	Multimedia (cs.MM);Neural and Evolutionary Computing (cs.NE);Sound (cs.SD);Machine Learning (stat.ML)
Naka_m	nakam	390	444	そういえば、弊研の機械学習論文が出ていた： https://t.co/fes6CCwBr8	2019/7/5 17:12	https://arxiv.org/abs/1907.00208	Deep Gamblers: Learning to Abstain with Portfolio Theory	"We deal with the \textit{selective classification} problem(supervised-learning problem with a rejection option), where we want to achievethe best performance at a certain level of coverage of the data. We transformthe original $m$-class classification problem to $(m+1)$-class where the$(m+1)$-th class represents the model abstaining from making a prediction dueto uncertainty. Inspired by portfolio theory, we propose a loss function forthe selective classification problem based on the doubling rate of gambling. Weshow that minimizing this loss function has a natural interpretation asmaximizing the return of a \textit{horse race}, where a player aims to balancebetween betting on an outcome (making a prediction) when confident andreserving one's winnings (abstaining) when not confident. This loss functionallows us to train neural networks and characterize the uncertainty ofprediction in an end-to-end fashion. In comparison with previous methods, ourmethod requires almost no modification to the model inference algorithm orneural architecture. Experimentally, we show that our method can identify bothuncertain and outlier data points, and achieves strong results on SVHN andCIFAR10 at various coverages of the data."	Machine Learning (cs.LG)	Machine Learning (stat.ML)
r9y9	山本りゅういち / Ryuichi Yamamoto	835	559	https://t.co/pXjrC83jDA fairseqのpaper出てるの最近まで知らなかったけど、extensibleに設計されてるのが良いよなあ。DeepVoice3の実装したときにコード参考にしたのがもう二年前で、それから大分進化してる。Pytorchベースだしapexでmix precision 学習/推論もサポートしてる。良さみがあるなあ	2019/7/5 18:58	https://arxiv.org/abs/1904.01038	"fairseq: A Fast, Extensible Toolkit for Sequence Modeling"	"fairseq is an open-source sequence modeling toolkit that allows researchersand developers to train custom models for translation, summarization, languagemodeling, and other text generation tasks. The toolkit is based on PyTorch andsupports distributed training across multiple GPUs and machines. We alsosupport fast mixed-precision training and inference on modern GPUs. A demovideo can be found at this https URL"	Computation and Language (cs.CL)	
powowowbtc	"PoW! WoW! WoW! (Mining, Bitcoin, Blockchain)"	433	84	2. 半減期を廃止し、難易度調整が閾値を超えた場合に採掘報酬を変動させる 3. 負の利子率を導入して総供給量を減少させる  論文のダウンロードはこちらから https://t.co/OG0jekguSV	2019/7/5 19:19	https://arxiv.org/abs/1801.06771	How to Make a Digital Currency on a Blockchain Stable	"Bitcoin and other similar digital currencies on blockchains are not idealmeans for payment, because their prices tend to go up in the long term (thuspeople are incentivized to hoard those currencies), and to fluctuate widely inthe short term (thus people would want to avoid risks of losing values). Thereason why those blockchain currencies based on proof of work are unstable maybe found in their designs that the supplies of currencies do not respond totheir positive and negative demand shocks, as the authors have formulated inour past work. Continuing from our past work, this paper proposes minimalchanges to the design of blockchain currencies so that their market prices areautomatically stabilized, absorbing both positive and negative demand shocks ofthe currencies by autonomously controlling their supplies. Those changes are:1) limiting re-adjustment of proof-of-work targets, 2) making mining rewardsvariable according to the observed over-threshold changes of block intervals,and 3) enforcing negative interests to remove old coins in circulation. We havemade basic design checks and evaluations of these measures through simplesimulations. In addition to stabilization of prices, the proposed measures mayhave effects of making those currencies preferred means for payment bydisincentivizing hoarding, and improving sustainability of the currency systemsby making rewards to miners perpetual."	Computers and Society (cs.CY)	
shiku0304	しく	86	60	ガウス過程みたいに、エルミート行列の逆行列作るのがボトルネックになる系の方法は、量子ビット数が増えていけば、かなり進展しそうな気がします。 https://t.co/rMDwwgfw1O	2019/7/5 19:20	https://arxiv.org/abs/1806.11463	Bayesian Deep Learning on a Quantum Computer	"Bayesian methods in machine learning, such as Gaussian processes, have greatadvantages com-pared to other techniques. In particular, they provide estimatesof the uncertainty associated with a prediction. Extending the Bayesianapproach to deep architectures has remained a major challenge. Recent resultsconnected deep feedforward neural networks with Gaussian processes, allowingtraining without backpropagation. This connection enables us to leverage aquantum algorithm designed for Gaussian processes and develop a new algorithmfor Bayesian deep learning on quantum computers. The properties of the kernelmatrix in the Gaussian process ensure the efficient execution of the corecomponent of the protocol, quantum matrix inversion, providing an at leastpolynomial speedup over classical algorithms. Furthermore, we demonstrate theexecution of the algorithm on contemporary quantum computers and analyze itsrobustness with respect to realistic noise models."	Quantum Physics (quant-ph)	Artificial Intelligence (cs.AI);Machine Learning (stat.ML)
guicho271828	(phd '(masataro . asai))	783	782	思いついたら取られてた https://t.co/ajoKTbtx2B	2019/7/5 19:59	https://arxiv.org/abs/1504.04658	Deep Karaoke: Extracting Vocals from Musical Mixtures Using a Convolutional Deep Neural Network	"Identification and extraction of singing voice from within musical mixturesis a key challenge in source separation and machine audition. Recently, deepneural networks (DNN) have been used to estimate 'ideal' binary masks forcarefully controlled cocktail party speech separation problems. However, it isnot yet known whether these methods are capable of generalizing to thediscrimination of voice and non-voice in the context of musical mixtures. Here,we trained a convolutional DNN (of around a billion parameters) to provideprobabilistic estimates of the ideal binary mask for separation of vocal soundsfrom real-world musical mixtures. We contrast our DNN results with moretraditional linear methods. Our approach may be useful for automatic removal ofvocal sounds from musical mixtures for 'karaoke' type applications."	Sound (cs.SD)	Machine Learning (cs.LG);Neural and Evolutionary Computing (cs.NE)
dmbrkp_	ダムブレークP	56	267	某氏が好きそうな話題 https://t.co/ZCQScg1Oza	2019/7/5 20:27	https://arxiv.org/abs/1907.02332	Light-Control of Localised Photo-Bio-Convection	"Microorganismal motility is often characterised by complex responses toenvironmental physico-chemical stimuli. Although the biological basis of theseresponses is often not well understood, their exploitation already promisesnovel avenues to directly control the motion of living active matter at boththe individual and collective level. Here we leverage the phototactic abilityof the model microalga {\it Chlamydomonas reinhardtii} to precisely control thetiming and position of localised cell photo-accumulation, leading to thecontrolled development of isolated bioconvective plumes. This novel form ofphoto-bio-convection allows a precise, fast and reconfigurable control of thespatio-temporal dynamics of the instability and the ensuing globalrecirculation, which can be activated and stopped in real time. A simplecontinuum model accounts for the phototactic response of the suspension anddemonstrates how the spatio-temporal dynamics of the illumination field can beused as a simple external switch to produce efficient bio-mixing."	Biological Physics (physics.bio-ph)	Fluid Dynamics (physics.flu-dyn);Cell Behavior (q-bio.CB)
q9ac	將籠林檎 / ??	277	228	非慣性系にあるアハロノフボームリング中に閉じ込められたディラック粒子。  複雑だあ(´･ω･｀)  https://t.co/w0qsdDLE2w	2019/7/5 22:00	https://arxiv.org/abs/1907.00054	Topological and noninertial effects in an Aharonov-Bohm ring	"In this paper, we study the influence of topological and noninertial effectson a Dirac particle confined in an Aharonov-Bohm (AB) ring. Next, we determinethe Dirac spinor and the energy spectrum for the relativistic bound states. Weobserve that this spectrum depends of the quantum number $n$, magnetic flux$\Phi$ of the ring, angular velocity $\omega$ of the rotating frame, and of theparameter $\eta$ associated to topology of the cosmic string spacetime. Weobserved also that this spectrum is a periodic function and grows of values infunction of $n$, $\Phi$, $\omega$ and $\eta$. In the nonrelativistic limit, weobtain the equation of motion for a particle confined in an AB ring under theinfluence of topological and noninertial effects, where this topologicaleffects are generated now by a conic space. However, unlike of the relativisticcase, the spectrum this equation depends linearly of the parameter $\omega$ anddecreases of values with the increase of such parameter. In special, weverified that in the absence of the topological and noninertial effects($\eta=1$ and $\omega=0$) we recuperate the spectrum of a particle confined inan AB ring ($\Phi\neq 0$) or in an usual 1D quantum ring ($\Phi=0$)."	High Energy Physics - Theory (hep-th)	Quantum Physics (quant-ph)
q9ac	將籠林檎 / ??	277	228	スクイーズド光があれば超強結合なしで超放射相転移が起こる。  https://t.co/1DVBgQNI36	2019/7/5 22:02	https://arxiv.org/abs/1907.00522	Squeezed light induced symmetry breaking superradiant phase transition	"We theoretically investigate the quantum phase transition in the collectivesystems of qubits in a high-quality cavity, which is driven by a squeezedlight. We show that the squeezed light induced symmetry breaking can result inquantum phase transition without the ultrastrong coupling requirement. Usingthe standard mean field theory, we derive the condition of the quantum phasetransition. Surprisingly, we show that there exists a tricritical point wherethe first- and second-order phase transitions meet. With specific atom-cavitycoupling strengths, both the first- and second-order phase transition can becontrolled by the squeezed light, leading to an optical switching from thenormal phase to the superradiant phase by just increasing the squeezed lightintensity. The signature of these phase transitions can be observed bydetecting the phase space Wigner function distribution with different profilescontrolled by the squeezed light intensity. Such superradiant phase transitioncan be implemented in various quantum systems, including atoms, quantum dotsand ions in optical cavities as well as the circuit quantum electrodynamicssystem."	Quantum Physics (quant-ph)	
q9ac	將籠林檎 / ??	277	228	デターミニスティックな光学系の上を光が伝搬する様子を説明するのにミュラー行列を使って計算する方法があるが、これでは伝搬にかかる位相を取り入れた議論ができない。そのポイントを改善したピュアなオプティクスの論文だなあ  https://t.co/WGPjbHzva3	2019/7/5 22:23	https://arxiv.org/abs/1907.00580	Two theorems on the outer product of input and output Stokes vectors for deterministic optical systems	"$2\times2$ complex Jones matrix transforms two dimensional complex Jonesvectors into complex Jones vectors and accounts for phase introduced bydeterministic optical systems. On the other hand, Mueller-Jones matrixtransforms four parameter real Stokes vectors into four parameter real Stokesvectors that contain no information about phase. Previously, a $4\times4$complex matrix ($\mathbf{Z}$ matrix) was introduced. $\mathbf{Z}$ matrix isanalogous to the Jones matrix and it is also akin to the Mueller-Jones matrixby the relation $\mathbf{M}=\mathbf{Z}\mathbf{Z^*}$. It was shown that$\mathbf{Z}$ matrix transforms Stokes vectors (Stokes matrices) into complexvectors (complex matrices) that contain relevant phases besides the otherinformation. In this note it is shown that, for deterministic optical systems,there exist two relations between outer product of experimentally measured realinput-output Stokes vectors and complex vectors (matrices) that represent thepolarization state and phase of totally polarized output light."	Optics (physics.optics)	
nebusokuririri	かまたまる	"4,775"	546	これが最新のパブリッシュしたペーパーです。よろしければ引用してください。 https://t.co/iQlpKIXqTn	2019/7/5 22:24	https://arxiv.org/abs/1707.07702	A Smooth Exit from Eternal Inflation?	"The usual theory of inflation breaks down in eternal inflation. We derive adual description of eternal inflation in terms of a deformed Euclidean CFTlocated at the threshold of eternal inflation. The partition function gives theamplitude of different geometries of the threshold surface in the no-boundarystate. Its local and global behavior in dual toy models shows that theamplitude is low for surfaces which are not nearly conformal to the roundthree-sphere and essentially zero for surfaces with negative curvature. Basedon this we conjecture that the exit from eternal inflation does not produce aninfinite fractal-like multiverse, but is finite and reasonably smooth."	High Energy Physics - Theory (hep-th)	Cosmology and Nongalactic Astrophysics (astro-ph.CO);General Relativity and Quantum Cosmology (gr-qc)
q9ac	將籠林檎 / ??	277	228	超絶縁体っていうのがジョセフソン接合素子のアレイを準備すると実現しうるらしい。超絶縁体相では抵抗が無限大になるらしいです。  https://t.co/E0EH7Y9EJ4	2019/7/5 22:36	https://arxiv.org/abs/1906.12265	Electrostatics of a superinsulator	"In 1978, to explain quark confinement in hadrons, 't Hooft coined the notionof ""superinsulator"", a hypothetical ground state endowed with infinite electricresistance and representing thus an extreme opposite to a superconductor. Incondensed matter, the superinsulating ground state was first predicted forJosephson junction arrays (JJA) and was rediscovered as a phase emerging at theinsulating side of the superconductor-insulator transition (SIT) insuperconducting films due to the duality of the phase-amplitude uncertaintyprinciple. Superinsulators, dissipationless Bose condensates of vortices retainan infinite resistance at finite temperatures and, as such, have been gainingan intense research attention. Here we investigate the response of asuperinsulator to a dc electric field and show that small fields, E<Ec1 arecompletely suppressed inside the material, a dual, electric version of theMeissner effect. Intermediate fields, Ec1<E<Ec2, penetrate the superinsulatoras electric filaments, realizing Polyakov's electric strings in compact QED, adual, electric version of the mixed state of superconductors, and, finally,large fields, E>Ec2, break down superinsulation completely. We report transportmeasurements in NbTiN films revealing both thresholds and their linear scalingwith the system size. We demonstrate that the asymptotically free behaviour ofquarks within mesons maps onto the metal-like behaviour of small films. Ourfindings open the route to measurements of Polyakov's string tension as afunction of the system's parameters, enabling the exploration of strongcoupling gauge theory concepts via desktop experiments."	Superconductivity (cond-mat.supr-con)	
q9ac	將籠林檎 / ??	277	228	量子熱力学のイントロダクション。古典熱力学とその量子論的フォーミュレーションからスタートして、最後には量子情報のプロセッシングの解析を取り扱っている。大学院生向けのテキストらしい。  https://t.co/IMBlulgPNa	2019/7/5 22:40	https://arxiv.org/abs/1907.01596	Quantum Thermodynamics: An introduction to the thermodynamics of quantum information	"This book provides an introduction to the emerging field of quantumthermodynamics, with particular focus on its relation to quantum informationand its implications for quantum computers and next generation quantumtechnologies. The text, aimed at graduate level physics students with a workingknowledge of quantum mechanics and statistical physics, provides a briefoverview of the development of classical thermodynamics and its quantumformulation in Chapter 1. Chapter 2 then explores typical thermodynamicsettings, such as cycles and work extraction protocols, when the workingmaterial is genuinely quantum. Finally, Chapter 3 explores the thermodynamicsof quantum information processing and introduces the reader to some morestate-of-the-art topics in this exciting and rapidly developing research field."	Quantum Physics (quant-ph)	Mesoscale and Nanoscale Physics (cond-mat.mes-hall);Quantum Gases (cond-mat.quant-gas);Statistical Mechanics (cond-mat.stat-mech)
q9ac	將籠林檎 / ??	277	228	電磁場中のDirac fermionと創発的ゲージ場中の中性fermionが双対な関係になっているらしい  https://t.co/P3CvjLfPcM	2019/7/5 22:46	https://arxiv.org/abs/1907.01501	Fermion-fermion duality in 3+1 dimensions	"Dualities play a central role in both quantum field theories and condensedmatter systems. Recently, a web of dualities has been discovered in 2+1dimensions. Here, we propose in particular a generalization of the Son'sfermion-fermion duality to 3+1 dimensions. We show that the action of chargedDirac fermions coupled to an external electromagnetic field is dual to anaction of neutral fermions minimally coupled to an emergent vector gauge field.This dual action contains also a further tensor (Kalb-Ramond) gauge fieldcoupled to the emergent and electromagnetic vector potentials. We firstlydemonstrate the duality in the massive case. We then show the duality in thecase of massless fermions starting from a lattice model and employing theslave-rotor approach already used in the 2+1-dimensional duality [Burkov, Phys.Rev. B 99, 035124 (2019)]. We finally apply this result to 3D Dirac semimetalsin the low-energy regime. Besides the implications in topological phases ofmatter, our results shed light on the possible existence of a novel web ofdualities in 3+1-dimensional (non-supersymmetric) quantum field theories."	Mesoscale and Nanoscale Physics (cond-mat.mes-hall)	High Energy Physics - Theory (hep-th)
math_phys	N(eutral).W(-boson).	"1,267"	340	"https://t.co/Yfm23nLVnx SSBを伴う低エネルギー有効場の理論が、機械学習と関わりあるよ、という主張。gauge理論と時系列モデルが関係していて、損失関数を""gauge不変""にする事で収束を早められる、とか述べられている。詳細は読んでみないと分からない。"	2019/7/5 22:50	https://arxiv.org/abs/1907.02163	A Quantum Field Theory of Representation Learning	"Continuous symmetries and their breaking play a prominent role incontemporary physics. Effective low-energy field theories around symmetrybreaking states explain diverse phenomena such as superconductivity, magnetism,and the mass of nucleons. We show that such field theories can also be a usefultool in machine learning, in particular for loss functions with continuoussymmetries that are spontaneously broken by random initializations. In thispaper, we illuminate our earlier published work (Bamler & Mandt, 2018) on thistopic more from the perspective of theoretical physics. We show that theanalogies between superconductivity and symmetry breaking in temporalrepresentation learning are rather deep, allowing us to formulate a gaugetheory of `charged' embedding vectors in time series models. We show thatmaking the loss function gauge invariant speeds up convergence in such models."	Machine Learning (stat.ML)	Statistical Mechanics (cond-mat.stat-mech);Machine Learning (cs.LG)
q9ac	將籠林檎 / ??	277	228	非線形媒質中の電磁場の揺らぎに関して、熱的な寄与を取り扱うのに、時空の揺らぎ→光円錐の揺らぎを考える  https://t.co/vcdkZsmFs0	2019/7/5 23:01	https://arxiv.org/abs/1907.00706	Lightcone fluctuations in a nonlinear medium due to thermal fluctuations	"We study the flight time fluctuations of a probe light propagating in a slabof nonlinear optical material with an effective fluctuating refractive indexcaused by thermal fluctuations of background photons at a temperature $T$,which are analogous to the lightcone fluctuations due to fluctuating spacetimegeometry when gravity is quantized. A smoothly varying second ordersusceptibility is introduced, which results in that background field modeswhose wavelengths are of the order of the thickness of the slab give the maincontribution. We show that, in the low-temperature limit, the contribution ofthermal fluctuations to the flight time fluctuations is proportional to $T^4$,which is a small correction compared with the contributions from vacuumfluctuations, while in the high-temperature limit, the contribution of thermalfluctuations increases linearly with $T$, which dominates over that of vacuumfluctuations. Numerical estimation shows that, in realistic situations, thecontributions from thermal fluctuations are still small compared with that fromvacuum fluctuations even at room temperature."	General Relativity and Quantum Cosmology (gr-qc)	High Energy Physics - Theory (hep-th);Quantum Physics (quant-ph)
q9ac	將籠林檎 / ??	277	228	ナノ粒子が熱輸送をエンハンスするという話。電磁場のグリーン関数を使った計算。  https://t.co/vwvUGzrIyS	2019/7/5 23:09	https://arxiv.org/abs/1907.00828	Modal Approach to the Theory of Energy Transfer Mediated by a Metallic Nanosphere	"Theoretically, the presence of a metallic nanoparticle enhances theintermolecular energy transfer. We calculate this enhancement factor with amodal approach pertaining analytical results in the case of a nanosphere. Wecalculate the Green's function of the system relaying on the spectralproperties of the electrostatic operator, fully known for spherical geometry.In contrast to other treatments, the present calculations are straightforwardfor any molecular orientation giving modal information about the response ofthe system. Numerical calculations and further discussions are also provided."	Mesoscale and Nanoscale Physics (cond-mat.mes-hall)	Classical Physics (physics.class-ph)
noan6251	ホテルバルティック（クローン）@築25年	849	846	これはAnnals of Statisticsの論文でFirst authorはE. Cand?sです（論文は別にfollowしてません）． https://t.co/h9zBSkLWsM	2019/7/5 23:16	https://arxiv.org/abs/0803.3136	Rejoinder: The Dantzig selector: Statistical estimation when $p$ is much larger than $n$	Rejoinder to ``The Dantzig selector: Statistical estimation when $p$ is muchlarger than $n$'' [math/0506081]	Statistics Theory (math.ST)	
re_hako_moon	はこつき＠VR	50	57	https://t.co/EWpedQsFtI The Perfect Match: 三次元点群ための学習ベースの特徴量を提案。局所点群をボクセル化したあとに3D CNNで学習する。対応する局所形状同士の特徴量の差が小さく、対応しない局所形状同士の特徴量の差が大きくなるようにロスを定義する。	2019/7/5 23:18	https://arxiv.org/abs/1811.06879	The Perfect Match: 3D Point Cloud Matching with Smoothed Densities	"We propose 3DSmoothNet, a full workflow to match 3D point clouds with asiamese deep learning architecture and fully convolutional layers using avoxelized smoothed density value (SDV) representation. The latter is computedper interest point and aligned to the local reference frame (LRF) to achieverotation invariance. Our compact, learned, rotation invariant 3D point clouddescriptor achieves 94.9% average recall on the 3DMatch benchmark data set,outperforming the state-of-the-art by more than 20 percent points with only 32output dimensions. This very low output dimension allows for near realtimecorrespondence search with 0.1 ms per feature point on a standard PC. Ourapproach is sensor- and sceneagnostic because of SDV, LRF and learning highlydescriptive features with fully convolutional layers. We show that 3DSmoothNettrained only on RGB-D indoor scenes of buildings achieves 79.0% average recallon laser scans of outdoor vegetation, more than double the performance of ourclosest, learning-based competitors. Code, data and pre-trained models areavailable online at this https URL."	Computer Vision and Pattern Recognition (cs.CV)	
tmasada	Tomonari MASADA	474	67	"""In a Variational Auto-Decoder framework, the approximate posterior distribution is not parameterized by a neural network, but rather using a well-known distribution directly.""…て、それ普通の変分ベイズですけど? https://t.co/K8mEss9UVN"	2019/7/5 23:28	https://arxiv.org/abs/1903.00840	Variational Auto-Decoder	"Learning a generative model from partial data (data with missingness) is achallenging area of machine learning research. We study a specificimplementation of the Auto-Encoding Variational Bayes (AEVB) algorithm, namedin this paper as a Variational Auto-Decoder (VAD). VAD is a generic frameworkwhich uses Variational Bayes and Markov Chain Monte Carlo (MCMC) methods tolearn a generative model from partial data. The main distinction between VADand Variational Auto-Encoder (VAE) is the encoder component, as VAD does nothave one. Using a proposed efficient inference method from a multivariateGaussian approximate posterior, VAD models allow inference to be performed viasimple gradient ascent rather than MCMC sampling from a probabilistic decoder.This technique reduces the inference computational cost, allows for using morecomplex optimization techniques during latent space inference (which are shownto be crucial due to a high degree of freedom in the VAD latent space), andkeeps the framework simple to implement. Through extensive experiments overseveral datasets and different missing ratios, we show that encoders cannotefficiently marginalize the input volatility caused by imputed missing values.We study multimodal datasets in this paper, which is a particular area ofimpact for VAD models."	Machine Learning (cs.LG)	Artificial Intelligence (cs.AI);Machine Learning (stat.ML)
yoshi_and_aki	Yoshi-aki Shimada	631	832	化学式から超伝導になるかどうかを機械学習で予測すると、人より当たるし、新物資(物質としては知られていたが超伝導になるかどうかは分かって無かった)も見つけられるとな。固体物理の歴史を無視してるというよりかは、「周期表すげー」と読む感じ。 https://t.co/UAW6RXTUg9	2019/7/6 0:10	https://arxiv.org/abs/1812.01995	Deep Learning Model for Finding New Superconductors	"Superconductivity has been extensively studied since its discovery in 1911.However, the feasibility of room-temperature superconductivity is unknown.There is no theory of high-temperature superconductors and there are nocomputational methods for strongly correlated systems, in whichhigh-temperature superconductivity emerges. Exploration of new superconductorsstill relies on the experience and intuition of experts, and is largely aprocess of experimental trial and error. In one study, only 3\% of thecandidate materials showed superconductivity~\cite{1468-6996-16-3-033503}. Herewe report an interdisciplinary attempt for finding new superconductors based ondeep learning. We represented the periodic table in a way that allows a deeplearning model to learn it. Although we used only the chemical composition ofmaterials as information, we obtained an $R^{2}$ value of 0.92 for predictingthe superconducting transition temperature, $T_\text{c}$, for materials in adatabase of superconductors. We obtained three remarkable results. The deeplearning method can predict superconductivity for a material with a precisionof 55\%, which shows the usefulness of the model; it found the recentlydiscovered superconductor \ce{CaBi2}, which is not in the superconductordatabase; and it found Fe-based high-temperature superconductors (discovered in2008) from the training data before 2008. These results open the way for thediscovery of new high-temperature superconductor families."	Machine Learning (cs.LG)	Computation and Language (cs.CL)
Ryuhei_Mori	Mori	101	50	今さら FOCS の accepted papers から知った。 https://t.co/sGzUBOfMEn	2019/7/6 0:38	https://arxiv.org/abs/1901.11533	Reed-Muller codes polarize	"Reed-Muller (RM) codes and polar codes are generated by the same matrix $G_m=\bigl[\begin{smallmatrix}1 & 0 \\ 1 & 1 \\ \end{smallmatrix}\bigr]^{\otimes m}$but using different subset of rows. RM codes select simply rows having largestweights. Polar codes select instead rows having the largest conditional mutualinformation proceeding top to down in $G_m$; while this is a more elaborate andchannel-dependent rule, the top-to-down ordering has the advantage of makingthe conditional mutual information polarize, giving directly acapacity-achieving code on any binary memoryless symmetric channel (BMSC). RMcodes are yet to be proved to have such property.In this paper, we reconnect RM codes to polarization theory. It is shown thatproceeding in the RM code ordering, i.e., not top-to-down but from the lightestto the heaviest rows in $G_m$, the conditional mutual information againpolarizes. We further demonstrate that it does so faster than for polar codes.This implies that $G_m$ contains another code, different than the polar codeand called here the twin code, that is provably capacity-achieving on any BMSC.This proves a necessary condition for RM codes to achieve capacity on BMSCs. Itfurther gives a sufficient condition if the rows with the largest conditionalmutual information correspond to the heaviest rows, i.e., if the twin code isthe RM code. We show here that the two codes bare similarity with each otherand give further evidence that they are likely the same."	Information Theory (cs.IT)	
shion_honda	Shion Honda	"1,243"	244	"Negative Sampling on Link Prediction [Kotnis+, 2018, KBCOM] 知識グラフのlink predictionで負例サンプリングをすると未観測linkを負例としてしまう問題に対して、6種の工夫を複数モデルに適用し比較した。スパースなKGには埋め込みを用いる手法が効く。 https://t.co/r18uU3XnDZ #NowReading https://t.co/xYL0po36gW"	2019/7/6 1:04	https://arxiv.org/abs/1708.06816	Analysis of the Impact of Negative Sampling on Link Prediction in Knowledge Graphs	"Knowledge graphs are large, useful, but incomplete knowledge repositories.They encode knowledge through entities and relations which define each otherthrough the connective structure of the graph. This has inspired methods forthe joint embedding of entities and relations in continuous low-dimensionalvector spaces, that can be used to induce new edges in the graph, i.e., linkprediction in knowledge graphs. Learning these representations relies oncontrasting positive instances with negative ones. Knowledge graphs includeonly positive relation instances, leaving the door open for a variety ofmethods for selecting negative examples. In this paper we present an empiricalstudy on the impact of negative sampling on the learned embeddings, assessedthrough the task of link prediction. We use state-of-the-art knowledge graphembeddings -- \rescal , TransE, DistMult and ComplEX -- and evaluate onbenchmark datasets -- FB15k and WN18. We compare well known methods fornegative sampling and additionally propose embedding based sampling methods. Wenote a marked difference in the impact of these sampling methods on the twodatasets, with the ""traditional"" corrupting positives method leading to bestresults on WN18, while embedding based methods benefiting the task on FB15k."	Artificial Intelligence (cs.AI)	
NieA7_3170	加藤恵と幸せな家庭を築きたい	486	208	https://t.co/2Rz76SWZrX まんまこれですが	2019/7/6 1:06	https://arxiv.org/abs/1812.04342	Learning latent representations for style control and transfer in end-to-end speech synthesis	"In this paper, we introduce the Variational Autoencoder (VAE) to anend-to-end speech synthesis model, to learn the latent representation ofspeaking styles in an unsupervised manner. The style representation learnedthrough VAE shows good properties such as disentangling, scaling, andcombination, which makes it easy for style control. Style transfer can beachieved in this framework by first inferring style representation through therecognition network of VAE, then feeding it into TTS network to guide the stylein synthesizing speech. To avoid Kullback-Leibler (KL) divergence collapse intraining, several techniques are adopted. Finally, the proposed model showsgood performance of style control and outperforms Global Style Token (GST)model in ABX preference tests on style transfer."	Computation and Language (cs.CL)	Sound (cs.SD);Audio and Speech Processing (eess.AS)
sammy_suyama	須山敦志 Suyama Atsushi	"10,049"	166	dropoutが使えないなら変分推論を使えばいいじゃない Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning https://t.co/4qWem9y5PM	2019/7/6 1:42	https://arxiv.org/abs/1506.02142	Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning	"Deep learning tools have gained tremendous attention in applied machinelearning. However such tools for regression and classification do not capturemodel uncertainty. In comparison, Bayesian models offer a mathematicallygrounded framework to reason about model uncertainty, but usually come with aprohibitive computational cost. In this paper we develop a new theoreticalframework casting dropout training in deep neural networks (NNs) as approximateBayesian inference in deep Gaussian processes. A direct result of this theorygives us tools to model uncertainty with dropout NNs -- extracting informationfrom existing models that has been thrown away so far. This mitigates theproblem of representing uncertainty in deep learning without sacrificing eithercomputational complexity or test accuracy. We perform an extensive study of theproperties of dropout's uncertainty. Various network architectures andnon-linearities are assessed on tasks of regression and classification, usingMNIST as an example. We show a considerable improvement in predictivelog-likelihood and RMSE compared to existing state-of-the-art methods, andfinish by using dropout's uncertainty in deep reinforcement learning."	Machine Learning (stat.ML)	Machine Learning (cs.LG)
fudoumyousan	宮島	191	162	(Google DeepMind) https://t.co/CJzMieRXO2 他者の心を類推し、理解する能力についての「心の理論」に基づいた振る舞いが出来るようなモデルを深層強化学習で実現．	2019/7/6 1:51	https://arxiv.org/abs/1802.07740	Machine Theory of Mind	"Theory of mind (ToM; Premack & Woodruff, 1978) broadly refers to humans'ability to represent the mental states of others, including their desires,beliefs, and intentions. We propose to train a machine to build such modelstoo. We design a Theory of Mind neural network -- a ToMnet -- which usesmeta-learning to build models of the agents it encounters, from observations oftheir behaviour alone. Through this process, it acquires a strong prior modelfor agents' behaviour, as well as the ability to bootstrap to richerpredictions about agents' characteristics and mental states using only a smallnumber of behavioural observations. We apply the ToMnet to agents behaving insimple gridworld environments, showing that it learns to model random,algorithmic, and deep reinforcement learning agents from varied populations,and that it passes classic ToM tasks such as the ""Sally-Anne"" test (Wimmer &Perner, 1983; Baron-Cohen et al., 1985) of recognising that others can holdfalse beliefs about the world. We argue that this system -- which autonomouslylearns how to model other agents in its world -- is an important step forwardfor developing multi-agent AI systems, for building intermediating technologyfor machine-human interaction, and for advancing the progress on interpretableAI."	Artificial Intelligence (cs.AI)	
tomonarimitiyam	この先、みてぃなりです	225	262	https://t.co/Po7yxk1EHK このシミュレーションやったという人がいた。世間は狭いのお。 https://t.co/63Oky9nzmf	2019/7/6 3:19	https://arxiv.org/abs/1907.00977	Rapid early coeval star formation and assembly of the most massive galaxies in the universe	"The current consensus on the formation and evolution of the brightest clustergalaxies is that their stellar mass forms early ($z \gtrsim 4$) in separategalaxies that then eventually assemble the main structure at late times ($z\lesssim 1$). However, advances in observational techniques have led to thediscovery of protoclusters out to $z \sim 7$, suggesting that the late-assemblypicture may not be fully complete. Using a combination of observationallyconstrained hydrodynamical and dark-matter-only simulations, we show that thestellar assembly time of a sub-set of brightest cluster galaxies occurs at highredshifts ($z > 3$) rather than at low redshifts ($z < 1$), as is commonlythough. We find that highly overdense protoclusters assemble their stellar massinto brightest cluster galaxies within $\sim 1$ $\mathrm{Gyr}$ of evolution --producing massive blue elliptical galaxies at high redshifts ($z \gtrsim 3$).We argue that there is a downsizing effect on the cluster scale wherein thebrightest cluster galaxies in the cores of the most-massive clusters assembleearlier than those in lower-mass clusters. The James Webb Space Telescope willbe able to detect and confirm our prediction in the near future, and we discussthe implications to constraining the value of $\sigma_\mathrm{8}$."	Astrophysics of Galaxies (astro-ph.GA)	
__dingdongbell	ロールパンナちゃん	"1,127"	549	https://t.co/SQ8T6kowp7 なんかよく分からんけど、力学次数は可算くらいしか可能性がないのに超越的なものもあるという話らしい。この可算集合の形が気になってきますね。	2019/7/6 3:57	https://arxiv.org/abs/1907.00675	A transcendental dynamical degree	We give an example of a dominant rational selfmap of the projective planewhose dynamical degree is a transcendental number.	Dynamical Systems (math.DS)	Algebraic Geometry (math.AG);Number Theory (math.NT)
mosaico	mosaico ioscinaga	569	86	Magnitude2019が終わりました。初めて会う人ばかりでした。前から気になっている数値実験 https://t.co/sMDRIc7Qqw について、Mさんから「あれは測度ではなくて超関数の枠組みでとらえるべきだ」という解釈を聞いて、一気に視界が開ける思いをしました。	2019/7/6 4:41	https://arxiv.org/abs/0910.5500	Heuristic and computer calculations for the magnitude of metric spaces	"The notion of the magnitude of a compact metric space was considered inarXiv:0908.1582 with Tom Leinster, where the magnitude was calculated for linesegments, circles and Cantor sets. In this paper more evidence is presented fora conjectured relationship with a geometric measure theoretic valuation.Firstly, a heuristic is given for deriving this valuation by considering'large' subspaces of Euclidean space and, secondly, numerical approximations tothe magnitude are calculated for squares, disks, cubes, annuli, tori andSierpinski gaskets. The valuation is seen to be very close to the magnitude forthe convex spaces considered and is seen to be 'asymptotically' close for someother spaces."	Metric Geometry (math.MG)	Category Theory (math.CT)
dakuton	Yuji Tokuda	339	217	Data AugmentationでCutoutとMixupのメリットを兼ね備えたCutMixの提案。分類、物体検出タスクでtop-1/top-5 errorに改善がみられた。ROC曲線で100.0(+89.6)とか評価カンストしてる笑 CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features https://t.co/Q5PloIjz7N	2019/7/6 6:11	https://arxiv.org/abs/1905.04899	CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features	"Regional dropout strategies have been proposed to enhance the performance ofconvolutional neural network classifiers. They have proved to be effective forguiding the model to attend on less discriminative parts of objects (\eg leg asopposed to head of a person), thereby letting the network generalize better andhave better object localization capabilities. On the other hand, currentmethods for regional dropout removes informative pixels on training images byoverlaying a patch of either black pixels or random noise. {Such removal is notdesirable because it leads to information loss and inefficiency duringtraining.} We therefore propose the CutMix augmentation strategy: patches arecut and pasted among training images where the ground truth labels are alsomixed proportionally to the area of the patches. By making efficient use oftraining pixels and \mbox{retaining} the regularization effect of regionaldropout, CutMix consistently outperforms the state-of-the-art augmentationstrategies on CIFAR and ImageNet classification tasks, as well as on theImageNet weakly-supervised localization task. Moreover, unlike previousaugmentation methods, our CutMix-trained ImageNet classifier, when used as apretrained model, results in consistent performance gains in Pascal detectionand MS-COCO image captioning benchmarks. We also show that CutMix improves themodel robustness against input corruptions and its out-of-distributiondetection performances."	Computer Vision and Pattern Recognition (cs.CV)	
cv2aaa	okayasu	32	51	Personlabらへんからそんなに手法変わってない? https://t.co/udd7VOdRaI #cvsaisentan	2019/7/6 16:26	https://arxiv.org/abs/1803.08225	"PersonLab: Person Pose Estimation and Instance Segmentation with a Bottom-Up, Part-Based, Geometric Embedding Model"	"We present a box-free bottom-up approach for the tasks of pose estimation andinstance segmentation of people in multi-person images using an efficientsingle-shot model. The proposed PersonLab model tackles both semantic-levelreasoning and object-part associations using part-based modeling. Our modelemploys a convolutional network which learns to detect individual keypoints andpredict their relative displacements, allowing us to group keypoints intoperson pose instances. Further, we propose a part-induced geometric embeddingdescriptor which allows us to associate semantic person pixels with theircorresponding person instance, delivering instance-level person segmentations.Our system is based on a fully-convolutional architecture and allows forefficient inference, with runtime essentially independent of the number ofpeople present in the scene. Trained on COCO data alone, our system achievesCOCO test-dev keypoint average precision of 0.665 using single-scale inferenceand 0.687 using multi-scale inference, significantly outperforming all previousbottom-up pose estimation systems. We are also the first bottom-up method toreport competitive results for the person class in the COCO instancesegmentation task, achieving a person category average precision of 0.417."	Computer Vision and Pattern Recognition (cs.CV)	
IxtlanJourney	ixtlan journey	48	422	BERTのアテンションが何を見ているのかを解析した論文。依存タイプの判別精度の表を見ると、まだだいぶ改善の余地があることが分かる。 What Does BERT Look At? An Analysis of BERT's Attention https://t.co/Ybt5rIBD6t	2019/7/6 17:44	https://arxiv.org/abs/1906.04341	What Does BERT Look At? An Analysis of BERT's Attention	"Large pre-trained neural networks such as BERT have had great recent successin NLP, motivating a growing body of research investigating what aspects oflanguage they are able to learn from unlabeled data. Most recent analysis hasfocused on model outputs (e.g., language model surprisal) or internal vectorrepresentations (e.g., probing classifiers). Complementary to these works, wepropose methods for analyzing the attention mechanisms of pre-trained modelsand apply them to BERT. BERT's attention heads exhibit patterns such asattending to delimiter tokens, specific positional offsets, or broadlyattending over the whole sentence, with heads in the same layer oftenexhibiting similar behaviors. We further show that certain attention headscorrespond well to linguistic notions of syntax and coreference. For example,we find heads that attend to the direct objects of verbs, determiners of nouns,objects of prepositions, and coreferent mentions with remarkably high accuracy.Lastly, we propose an attention-based probing classifier and use it to furtherdemonstrate that substantial syntactic information is captured in BERT'sattention."	Computation and Language (cs.CL)	
ririshida	いっし	189	334	これ完全理解したい Types and Forms of Emergence https://t.co/OXdfZOMje8	2019/7/6 20:15	https://arxiv.org/abs/nlin/0506028	[nlin/0506028] Types and Forms of Emergence	"The knowledge of the different types of emergence is essential if we want tounderstand and master complex systems in science and engineering, respectively.This paper specifies a universal taxonomy and comprehensive classification ofthe major types and forms of emergence in Multi-Agent Systems, from simpletypes of intentional and predictable emergence in machines to more complexforms of weak, multiple and strong emergence."	Adaptation and Self-Organizing Systems (nlin.AO)	Pattern Formation and Solitons (nlin.PS)
hrsma2i	ヒ??シです。	159	354	各タスクのlossの割合が均等になるように、自動で重みを決める。 https://t.co/aXmxGF5MwH	2019/7/6 21:21	https://arxiv.org/abs/1705.07115	Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics	"Numerous deep learning applications benefit from multi-task learning withmultiple regression and classification objectives. In this paper we make theobservation that the performance of such systems is strongly dependent on therelative weighting between each task's loss. Tuning these weights by hand is adifficult and expensive process, making multi-task learning prohibitive inpractice. We propose a principled approach to multi-task deep learning whichweighs multiple loss functions by considering the homoscedastic uncertainty ofeach task. This allows us to simultaneously learn various quantities withdifferent units or scales in both classification and regression settings. Wedemonstrate our model learning per-pixel depth regression, semantic andinstance segmentation from a monocular input image. Perhaps surprisingly, weshow our model can learn multi-task weightings and outperform separate modelstrained individually on each task."	Computer Vision and Pattern Recognition (cs.CV)	
tonagai	tomo	408	88	中心極限定理の間違った解説が話題ですが、超一般化中心極限定理というのもあったり。レヴィの安定分布が出てくる。 Super Generalized Central Limit Theorem: Limit distributions for sums of non-identical random variables with power-laws https://t.co/fGVBwU0iMC https://t.co/WpTioIznEL	2019/7/6 21:59	https://arxiv.org/abs/1702.02826	Super Generalized Central Limit Theorem: Limit distributions for sums of non-identical random variables with power-laws	"In nature or societies, the power-law is present ubiquitously, and then it isimportant to investigate the mathematical characteristics of power-laws in therecent era of big data. In this paper we prove the superposition ofnon-identical stochastic processes with power-laws converges in density to aunique stable distribution. This property can be used to explain theuniversality of stable laws such that the sums of the logarithmic return ofnon-identical stock price fluctuations follow stable distributions."	Statistics Theory (math.ST)	General Economics (econ.GN);Mathematical Physics (math-ph)
tov_glowlight	同志ぐろーらいと	175	204	科学用語についてのロ英辞典  https://t.co/XnrkfKEztF	2019/7/6 22:42	https://arxiv.org/abs/math/0609472	[math/0609472] English Russian Scientific Dictionary	English Russian and Russian English dictionaries presented in this paper arededicated to help translate a scientific text from one language to another. Ialso included the bilingual name index into this book.	History and Overview (math.HO)	
kuto_bopro	きょうへい	67	86	1本目はやはりこれ。 Goodfellow氏が2014年に出したGANの論文。  GANの数式的理解を今日初めてしたんだけれど、最適化のところが面白くて、比較的単純な目的関数でGとDが訓練できることに驚いたなぁ。  GANの基本となる部分をざっくりではあるものの理解できたのは進歩。  https://t.co/2lEs8WmT0G	2019/7/6 23:15	https://arxiv.org/abs/1406.2661	Generative Adversarial Networks	"We propose a new framework for estimating generative models via anadversarial process, in which we simultaneously train two models: a generativemodel G that captures the data distribution, and a discriminative model D thatestimates the probability that a sample came from the training data rather thanG. The training procedure for G is to maximize the probability of D making amistake. This framework corresponds to a minimax two-player game. In the spaceof arbitrary functions G and D, a unique solution exists, with G recovering thetraining data distribution and D equal to 1/2 everywhere. In the case where Gand D are defined by multilayer perceptrons, the entire system can be trainedwith backpropagation. There is no need for any Markov chains or unrolledapproximate inference networks during either training or generation of samples.Experiments demonstrate the potential of the framework through qualitative andquantitative evaluation of the generated samples."	Machine Learning (stat.ML)	Machine Learning (cs.LG)
taketo1024	さのたけと	"6,353"	248	"そろそろこれも読めるかな??  [1001.0354] Topological Quantum Information, Khovanov Homology and the Jones Polynomial https://t.co/TQ6aQgnIBW"	2019/7/6 23:58	https://arxiv.org/abs/1001.0354	"Topological Quantum Information, Khovanov Homology and the Jones Polynomial"	"In this paper we give a quantum statistical interpretation for the bracketpolynomial state sum <K> and for the Jones polynomial. We use this quantummechanical interpretation to give a new quantum algorithm for computing theJones polynomial. This algorithm is useful for its conceptual simplicity, andit applies to all values of the polynomial variable that lie on the unit circlein the complex plane. Letting C(K) denote the Hilbert space for this model,there is a natural unitary transformation U from C(K) to itself such that <K> =<F|U|F> where |F> is a sum over basis states for C(K). The quantum algorithmarises directly from this formula via the Hadamard Test. We then show that theframework for our quantum model for the bracket polynomial is a natural settingfor Khovanov homology. The Hilbert space C(K) of our model has basis inone-to-one correspondence with the enhanced states of the bracket statesummmation and is isomorphic with the chain complex for Khovanov homology withcoefficients in the complex numbers. We show that for the Khovanov boundaryoperator d defined on C(K) we have the relationship dU + Ud = 0. Consequently,the unitary operator U acts on the Khovanov homology, and we therefore obtain adirect relationship between Khovanov homology and this quantum algorithm forthe Jones polynomial. The formula for the Jones polynomial as a graded Eulercharacteristic is now expressed in terms of the eigenvalues of U and the Eulercharacteristics of the eigenspaces of U in the homology. The quantum algorithmgiven here is inefficient, and so it remains an open problem to determinebetter quantum algorithms that involve both the Jones polynomial and theKhovanov homology."	Geometric Topology (math.GT)	Mathematical Physics (math-ph)
azriel1rf	あずりえる	"1,380"	468	これ写真の識別タスクでAUC1.0なのかと思ったら、乱数から生成された画像セットのOOD検出でTNR at TPR0.95が1.0だった(AUCは0.997????)。  CutMixの論文に出てくるGaussianやUniformの意味はOOD検出の論文に書いてあった。 https://t.co/wQypbEuxKa https://t.co/Ntg8qLhNjY	2019/7/7 0:13	https://arxiv.org/abs/1802.04865	Learning Confidence for Out-of-Distribution Detection in Neural Networks	"Modern neural networks are very powerful predictive models, but they areoften incapable of recognizing when their predictions may be wrong. Closelyrelated to this is the task of out-of-distribution detection, where a networkmust determine whether or not an input is outside of the set on which it isexpected to safely perform. To jointly address these issues, we propose amethod of learning confidence estimates for neural networks that is simple toimplement and produces intuitively interpretable outputs. We demonstrate thaton the task of out-of-distribution detection, our technique surpasses recentlyproposed techniques which construct confidence based on the network's outputdistribution, without requiring any additional labels or access toout-of-distribution examples. Additionally, we address the problem ofcalibrating out-of-distribution detectors, where we demonstrate thatmisclassified in-distribution examples can be used as a proxy forout-of-distribution examples."	Machine Learning (stat.ML)	Machine Learning (cs.LG)
kinako_bourbon	きなこかすてら	23	55	重力は斉しく万物に働くが近年、この力はエントロピック力だと解釈する向きがある（2010のhttps://t.co/HwJtbIwt2a論文を見よ。）	2019/7/7 0:57	https://arxiv.org/abs/1001.0785	On the Origin of Gravity and the Laws of Newton	Starting from first principles and general assumptions Newton's law ofgravitation is shown to arise naturally and unavoidably in a theory in whichspace is emergent through a holographic scenario. Gravity is explained as anentropic force caused by changes in the information associated with thepositions of material bodies. A relativistic generalization of the presentedarguments directly leads to the Einstein equations. When space is emergent evenNewton's law of inertia needs to be explained. The equivalence principle leadsus to conclude that it is actually this law of inertia whose origin isentropic.	High Energy Physics - Theory (hep-th)	
sugar_underkey	さーたー	280	349	内容的にはこれと同じか https://t.co/ZPutfXrgFF  群ζ、ドストライクだ	2019/7/7 0:57	https://arxiv.org/abs/math/0011267	[math/0011267] Analytic properties of zeta functions and subgroup growth	"In this paper we introduce some new methods to understand the analyticbehaviour of the zeta function of a group. We can then combine this knowledgewith suitable Tauberian theorems to deduce results about the growth ofsubgroups in a nilpotent group. In order to state our results we introduce thefollowing notation. For \alpha a real number and N a nonnegative integer,defines_N^\alpha(G) = sum_{n=1}^N a_n(G)/n^\alpha.Main Theorem: Let G be a finitely generated nilpotent infinite group.(1) The abscissa of convergence \alpha(G) of \zeta_G(s) is a rational numberand \zeta_G(s) can be meromorphically continued to Re(s)>\alpha(G)-\delta forsome \delta >0. The continued function is holomorphic on the line \Re(s) =(\alpha)G except for a pole at s=\alpha(G).(2) There exist a nonnegative integer b(G) and some real numbers c,c' suchthats_{N}(G) ~ c N^{\alpha(G)}(\log N)^{b(G)}s_{N}^{\alpha(G)}(G) ~ c' (\log N)^{b(G)+1}for N\rightarrow \infty ."	Group Theory (math.GR)	
Spike23645	Spike	188	248	https://t.co/UtXEolkBJa  なんとなく面白そうな論文を見つけました。  Abstからすると、DLの原理を群論の視点から解説してるみたい。  読んでみよう。  ｢物理学とディープラーニング｣みたいに面白そうな話かも。	2019/7/7 1:47	https://arxiv.org/abs/1412.6621	Why does Deep Learning work? - A perspective from Group Theory	"Why does Deep Learning work? What representations does it capture? How dohigher-order representations emerge? We study these questions from theperspective of group theory, thereby opening a new approach towards a theory ofDeep learning.One factor behind the recent resurgence of the subject is a key algorithmicstep called pre-training: first search for a good generative model for theinput samples, and repeat the process one layer at a time. We show deeperimplications of this simple principle, by establishing a connection with theinterplay of orbits and stabilizers of group actions. Although the neuralnetworks themselves may not form groups, we show the existence of {\em shadow}groups whose elements serve as close approximations.Over the shadow groups, the pre-training step, originally introduced as amechanism to better initialize a network, becomes equivalent to a search forfeatures with minimal orbits. Intuitively, these features are in a way the {\emsimplest}. Which explains why a deep learning network learns simple featuresfirst. Next, we show how the same principle, when repeated in the deeperlayers, can capture higher order representations, and why representationcomplexity increases as the layers get deeper."	Machine Learning (cs.LG)	Neural and Evolutionary Computing (cs.NE);Machine Learning (stat.ML)
hackernewsj	Hacker News記事題日本語翻訳	609	4	C ++ソフトウェアフレームワークのモデルチェック、ケーススタディ https://t.co/fMgwqWjWb1	2019/7/7 2:36	https://arxiv.org/abs/1907.00172	"Model Checking a C++ Software Framework, a Case Study"	"This paper presents a case study on applying two model checkers, SPIN andDIVINE, to verify key properties of a C++ software framework, known as ADAPRO,originally developed at CERN. SPIN was used for verifying properties on thedesign level. DIVINE was used for verifying simple test applications thatinteracted with the implementation. Both model checkers were found to havetheir own respective sets of pros and cons, but the overall experience waspositive. Because both model checkers were used in a complementary manner, theyprovided valuable new insights into the framework, which would arguably havebeen hard to gain by traditional testing and analysis tools only. Translatingthe C++ source code into the modeling language of the SPIN model checker helpedto find flaws in the original design. With DIVINE, defects were found in partsof the code base that had already been subject to hundreds of hours of unittests, integration tests, and acceptance tests. Most importantly, modelchecking was found to be easy to integrate into the workflow of the softwareproject and bring added value, not only as verification, but also validationmethodology. Therefore, using model checking for developing library-level codeseems realistic and worth the effort."	Software Engineering (cs.SE)	
Spike23645	Spike	188	248	@Khronos2106 代数的構造で例をあげるなら、例えば商。群や環を可換群やイデアルで割って分解。  そんな発想に、機械学習でも似たのがある。  CNNっていう深層学習の1種(下画素)は、下みたいに画像の商を作っていく仕組みに見える面がある。  リンクは数学的に深層学習を読み解く論文。 https://t.co/UtXEolkBJa https://t.co/BAaVcch0MK	2019/7/7 3:30	https://arxiv.org/abs/1412.6621	Why does Deep Learning work? - A perspective from Group Theory	"Why does Deep Learning work? What representations does it capture? How dohigher-order representations emerge? We study these questions from theperspective of group theory, thereby opening a new approach towards a theory ofDeep learning.One factor behind the recent resurgence of the subject is a key algorithmicstep called pre-training: first search for a good generative model for theinput samples, and repeat the process one layer at a time. We show deeperimplications of this simple principle, by establishing a connection with theinterplay of orbits and stabilizers of group actions. Although the neuralnetworks themselves may not form groups, we show the existence of {\em shadow}groups whose elements serve as close approximations.Over the shadow groups, the pre-training step, originally introduced as amechanism to better initialize a network, becomes equivalent to a search forfeatures with minimal orbits. Intuitively, these features are in a way the {\emsimplest}. Which explains why a deep learning network learns simple featuresfirst. Next, we show how the same principle, when repeated in the deeperlayers, can capture higher order representations, and why representationcomplexity increases as the layers get deeper."	Machine Learning (cs.LG)	Neural and Evolutionary Computing (cs.NE);Machine Learning (stat.ML)
pcneko5	K-neko@秋M3 検討中	279	364	読んでおきたい https://t.co/iiEl1EpibW	2019/7/7 7:08	https://arxiv.org/abs/1406.2661	Generative Adversarial Networks	"We propose a new framework for estimating generative models via anadversarial process, in which we simultaneously train two models: a generativemodel G that captures the data distribution, and a discriminative model D thatestimates the probability that a sample came from the training data rather thanG. The training procedure for G is to maximize the probability of D making amistake. This framework corresponds to a minimax two-player game. In the spaceof arbitrary functions G and D, a unique solution exists, with G recovering thetraining data distribution and D equal to 1/2 everywhere. In the case where Gand D are defined by multilayer perceptrons, the entire system can be trainedwith backpropagation. There is no need for any Markov chains or unrolledapproximate inference networks during either training or generation of samples.Experiments demonstrate the potential of the framework through qualitative andquantitative evaluation of the generated samples."	Machine Learning (stat.ML)	Machine Learning (cs.LG)
masahiro_sakai	Masahiro Sakai	"1,794"	"1,333"	AI Feynman: a Physics-Inspired Method for Symbolic Regression https://t.co/MV8HnkShrU データからの帰納的プログラム合成で物理法則を見つける話。次元解析やNNを代理モデルに用いての対称性や分割可能性の発見などを通じた単純化に工夫があり、遺伝的アルゴリズムを用いるEureqaよりも優れた性能	2019/7/7 10:46	https://arxiv.org/abs/1905.11481	AI Feynman: a Physics-Inspired Method for Symbolic Regression	"A core challenge for both physics and artificial intellicence (AI) issymbolic regression: finding a symbolic expression that matches data from anunknown function. Although this problem is likely to be NP-hard in principle,functions of practical interest often exhibit symmetries, separability,compositionality and other simplifying properties. In this spirit, we develop arecursive multidimensional symbolic regression algorithm that combines neuralnetwork fitting with a suite of physics-inspired techniques. We apply it to 100equations from the Feynman Lectures on Physics, and it discovers all of them,while previous publicly available software cracks only 71; for a more difficulttest set, we improve the state of the art success rate from 15% to 90%."	Computational Physics (physics.comp-ph)	Artificial Intelligence (cs.AI);Machine Learning (cs.LG);High Energy Physics - Theory (hep-th)
Kurahashi16	Taishi Kurahashi	194	43	数日前ですが、新しい論文を arXiv に投稿しました。 神戸大学の岩田君との共著です。 Fixed-point properties for predicate modal logics https://t.co/6a05yBx1Fc  ResearchGate にもおいてあります。 https://t.co/CoE6zKzLMR	2019/7/7 13:45	https://arxiv.org/abs/1907.00306	Fixed-point properties for predicate modal logics	"It is well known that the propositional modal logic $\mathbf{GL}$ ofprovability satisfies the de Jongh-Sambin fixed-point property. On the otherhand, Montagna showed that the predicate modal system $\mathbf{QGL}$, which isthe natural variant of $\mathbf{GL}$, loses the fixed-point property. In thispaper, we discuss some versions of the fixed-point property for predicate modallogics. First, we prove that several extensions of $\mathbf{QGL}$ including$\mathbf{NQGL}$ do not have the fixed-point property. Secondly, we prove thefixed-point theorem for the logic $\mathbf{QK} + \Box^{n+1} \bot$. As aconsequence, we obtain that the class $\mathsf{BL}$ of Kripke frames which aretransitive and of bounded length satisfies the fixed-point property locally. Wealso show that the failure of the Craig interpolation property for$\mathbf{NQGL}$ follows from our results. Finally, we give a sufficientcondition for formulas to have a fixed-point in $\mathbf{QGL}$."	Logic (math.LO)	
tentenianbundl2	てん	118	147	観念してFock-Rosly https://t.co/7VEIEnEys6 を眺めるか(読めない)	2019/7/7 14:08	https://arxiv.org/abs/math/9802054	[math/9802054] Poisson structure on moduli of flat connections on Riemann surfaces and $r$-matrix	We consider the space of graph connections (lattice gauge fields) which canbe endowed with a Poisson structure in terms of a ciliated fat graph. (Aciliated fat graph is a graph with a fixed linear order of ends of edges ateach vertex.) Our aim is however to study the Poisson structure on the modulispace of locally flat vector bundles on a Riemann surface with holes (i.e. withboundary). It is shown that this moduli space can be obtained as a quotient ofthe space of graph connections by the Poisson action of a lattice gauge groupendowed with a Poisson-Lie structure. The present paper contains as a part anupdated version of a 1992 preprint ITEP-72-92 which we decided still deservespublishing. We have removed some obsolete inessential remarks and added somenewer ones.	Quantum Algebra (math.QA)	High Energy Physics - Theory (hep-th);Group Theory (math.GR);Representation Theory (math.RT)
dakuton	Yuji Tokuda	339	217	"@azriel1rf ありがとうございます。OODをCIFAR-10,100で優劣つけるのはもう難しく、少し規模大きいもの使う必要あるのかなという印象です。下記論文のほうみてたので追加で読んでみます。 A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks https://t.co/FdfdGi1fbd"	2019/7/7 14:14	https://arxiv.org/abs/1807.03888	A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks	"Detecting test samples drawn sufficiently far away from the trainingdistribution statistically or adversarially is a fundamental requirement fordeploying a good classifier in many real-world machine learning applications.However, deep neural networks with the softmax classifier are known to producehighly overconfident posterior distributions even for such abnormal samples. Inthis paper, we propose a simple yet effective method for detecting any abnormalsamples, which is applicable to any pre-trained softmax neural classifier. Weobtain the class conditional Gaussian distributions with respect to (low- andupper-level) features of the deep models under Gaussian discriminant analysis,which result in a confidence score based on the Mahalanobis distance. Whilemost prior methods have been evaluated for detecting either out-of-distributionor adversarial samples, but not both, the proposed method achieves thestate-of-the-art performances for both cases in our experiments. Moreover, wefound that our proposed method is more robust in harsh cases, e.g., when thetraining dataset has noisy labels or small number of samples. Finally, we showthat the proposed method enjoys broader usage by applying it toclass-incremental learning: whenever out-of-distribution samples are detected,our classification rule can incorporate new classes well without furthertraining deep models."	Machine Learning (stat.ML)	Cryptography and Security (cs.CR);Machine Learning (cs.LG)
KSKSKSKS2	katsugeneration	178	445	推論の計算のみで、識別器がどこを見て画像のラベルを識別しているかを判定する Response-Based Visual Explanationのタスクで、CNNの識別精度を低下させず、既存の一般的なモデルや様々なタスクに簡単に応用できるVisual Explanation手法を提案 https://t.co/SmLegmmwfV	2019/7/7 15:05	https://arxiv.org/abs/1812.10025	Attention Branch Network: Learning of Attention Mechanism for Visual Explanation	"Visual explanation enables human to understand the decision making of DeepConvolutional Neural Network (CNN), but it is insufficient to contribute theperformance improvement. In this paper, we focus on the attention map forvisual explanation, which represents high response value as the importantregion in image recognition. This region significantly improves the performanceof CNN by introducing an attention mechanism that focuses on a specific regionin an image. In this work, we propose Attention Branch Network (ABN), whichextends the top-down visual explanation model by introducing a branch structurewith an attention mechanism. ABN can be applicable to several image recognitiontasks by introducing a branch for attention mechanism and is trainable for thevisual explanation and image recognition in end-to-end manner. We evaluate ABNon several image recognition tasks such as image classification, fine-grainedrecognition, and multiple facial attributes recognition. Experimental resultsshow that ABN can outperform the accuracy of baseline models on these imagerecognition tasks while generating an attention map for visual explanation. Ourcode is available atthis https URL."	Computer Vision and Pattern Recognition (cs.CV)	
tmaehara	? ??	"6,885"	718	アルゴリズム系に出すときは断らず alphabetical にしていて ( https://t.co/G8tbhMQf0Q )，機械学習系に出すときはだいたい contribution 順にしてる．ただし alphabetical order にすることもあって，そういうときは明記してる ( https://t.co/GUAFNtyFIr )	2019/7/7 16:27	"https://arxiv.org/abs/1807.04575, https://arxiv.org/abs/1901.08291"	"Algorithmic Meta-Theorems for Monotone Submodular Maximization, Pretending Fair Decisions via Stealthily Biased Sampling"	"We consider a monotone submodular maximization problem whose constraint isdescribed by a logic formula on a graph. Formally, we prove the following three`algorithmic metatheorems.'(1) If the constraint is specified by a monadic second-order logic on a graphof bounded treewidth, the problem is solved in $n^{O(1)}$ time with anapproximation factor of $O(\log n)$.(2) If the constraint is specified by a first-order logic on a graph of lowdegree, the problem is solved in $O(n^{1 + \epsilon})$ time for any $\epsilon >0$ with an approximation factor of $2$.(3) If the constraint is specified by a first-order logic on a graph ofbounded expansion, the problem is solved in $n^{O(\log k)}$ time with anapproximation factor of $O(\log k)$, where $k$ is the number of variables and$O(\cdot)$ suppresses only constants independent of $k$., Fairness by decision-makers is believed to be auditable by third parties. Inthis study, we show that this is not always true.We consider the following scenario. Imagine a decision-maker who discloses asubset of his dataset with decisions to make his decisions auditable. If he iscorrupt, and he deliberately selects a subset that looks fair even though theoverall decision is unfair, can we identify this decision-maker's fraud?We answer this question negatively. We first propose a sampling method thatproduces a subset whose distribution is biased from the original (to pretend tobe fair); however, its differentiation from uniform sampling is difficult. Wecall such a sampling method as stealthily biased sampling, which is formulatedas a Wasserstein distance minimization problem, and is solved through aminimum-cost flow computation. We proved that the stealthily biased samplingminimizes an upper-bound of the indistinguishability. We conducted experimentsto see that the stealthily biased sampling is, in fact, difficult to detect."	"Data Structures and Algorithms (cs.DS), Machine Learning (stat.ML)"	", Cryptography and Security (cs.CR);Machine Learning (cs.LG)"
rkakamilan	rkakamilan	591	578	Prediction of Small Molecule Kinase Inhibitors for Chemotherapy Using Deep Learning  色々組み合わせも試しましたと言う話 https://t.co/XpOloHNhAI	2019/7/7 17:00	https://arxiv.org/abs/1907.00329	Prediction of Small Molecule Kinase Inhibitors for Chemotherapy Using Deep Learning	"The current state of cancer therapeutics has been moving away fromone-size-fits-all cytotoxic chemotherapy, and towards a more individualized andspecific approach involving the targeting of each tumor's geneticvulnerabilities. Different tumors, even of the same type, may be more relianton certain cellular pathways more than others. With modern advancements in ourunderstanding of cancer genome sequencing, these pathways can be discovered.Investigating each of the millions of possible small molecule inhibitors foreach kinase in vitro, however, would be extremely expensive and time consuming.This project focuses on predicting the inhibition activity of small moleculestargeting 8 different kinases using multiple deep learning models. We trainedfingerprint-based MLPs and simplified molecular-input line-entry specification(SMILES)-based recurrent neural networks (RNNs) and molecular graphconvolutional networks (GCNs) to accurately predict inhibitory activitytargeting these 8 kinases."	Biomolecules (q-bio.BM)	Machine Learning (cs.LG)
ksasao	ミクミンP/Kazuhiro Sasao	"7,779"	"2,632"	UMAPの論文ながめた。 https://t.co/b8QdAsOLkl 解釈性が重要なときはPCAとかのほうがいいとか、アルゴリズム的に500件以下のデータセットでつかうときは気をつけろとか書いてあってよかった。Pythonで簡単に使える。 https://t.co/ADUJJjF9lt	2019/7/7 18:24	https://arxiv.org/abs/1802.03426	UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction	"UMAP (Uniform Manifold Approximation and Projection) is a novel manifoldlearning technique for dimension reduction. UMAP is constructed from atheoretical framework based in Riemannian geometry and algebraic topology. Theresult is a practical scalable algorithm that applies to real world data. TheUMAP algorithm is competitive with t-SNE for visualization quality, andarguably preserves more of the global structure with superior run timeperformance. Furthermore, UMAP has no computational restrictions on embeddingdimension, making it viable as a general purpose dimension reduction techniquefor machine learning."	Machine Learning (stat.ML)	Computational Geometry (cs.CG);Machine Learning (cs.LG)
asakura_nazuna	朝桜なづな	23	23	@Spike23645 Bayesian CycleGANは一応あるみたいです(私の勉強不足で中身は理解できていませんが…)  https://t.co/coN7CCVxdt	2019/7/7 21:04	https://arxiv.org/abs/1811.07465	Bayesian CycleGAN via Marginalizing Latent Sampling	"Recent techniques built on Generative Adversarial Networks (GANs) likeCycleGAN are able to learn mappings between domains from unpaired datasetsthrough min-max optimization games between generators and discriminators.However, it remains challenging to stabilize training process and diversifygenerated results. To address these problems, we present a Bayesian extensionof cyclic model and an integrated cyclic framework for inter-domain mappings.The proposed method stimulated by Bayesian GAN explores the full posteriors ofBayesian cyclic model (with latent sampling) and optimizes the model withmaximum a posteriori (MAP) estimation. Hence, we name it {\tt BayesianCycleGAN}. We perform the proposed Bayesian CycleGAN on multiple benchmarkdatasets, including Cityscapes, Maps, and Monet2photo. The quantitative andqualitative evaluations demonstrate the proposed method can achieve more stabletraining, superior performance and diversified images generating."	Machine Learning (cs.LG)	Computer Vision and Pattern Recognition (cs.CV);Machine Learning (stat.ML)
candidusflumen	Toshihico　Shiracawa	"1,503"	"2,015"	「Detecting problematic transactions in a consumer-to-consumer e-commerce network」 eコマースのネットワークについて分析した研究のようだ → https://t.co/EMIQbgsC5b	2019/7/7 22:00	https://arxiv.org/abs/1906.07974	Detecting problematic transactions in a consumer-to-consumer e-commerce network	"Providers of online marketplaces are constantly combatting againstproblematic transactions, such as selling illegal items and posting fictiveitems, exercised by some of their users. A typical approach to detect fraudactivity has been to analyze registered user profiles, user's behavior, andtexts attached to individual transactions and the user. However, thistraditional approach may be limited because malicious users can easily concealtheir information. Given this background, network indices have been exploitedfor detecting frauds in various online transaction platforms. In the presentstudy, we analyzed networks of users of an online consumer-to-consumermarketplace in which a seller and the corresponding buyer of a transaction areconnected by a directed edge. We constructed egocentric networks of each ofseveral hundreds of fraudulent users and those of a similar number of normalusers. We calculated eight local network indices based on up to connectivitybetween the neighbors of the focal node. Based on the present descriptiveanalysis of these network indices, we fed twelve features that we constructedfrom the eight network indices to random forest classifiers with the aim ofdistinguishing between normal users and fraudulent users engaged in each one ofthe four types of problematic transactions. We found that the classifieraccurately distinguished the fraudulent users from normal users and that theclassification performance did not depend on the type of problematictransaction."	Social and Information Networks (cs.SI)	
asakura_nazuna	朝桜なづな	23	23	@Spike23645 DNNも隠れ層のノードが無限のとき、ガウス過程として表現できるようですよ  https://t.co/vzK8iD4ZCC	2019/7/7 22:04	https://arxiv.org/abs/1711.00165	Deep Neural Networks as Gaussian Processes	"It has long been known that a single-layer fully-connected neural networkwith an i.i.d. prior over its parameters is equivalent to a Gaussian process(GP), in the limit of infinite network width. This correspondence enables exactBayesian inference for infinite width neural networks on regression tasks bymeans of evaluating the corresponding GP. Recently, kernel functions whichmimic multi-layer random neural networks have been developed, but only outsideof a Bayesian framework. As such, previous work has not identified that thesekernels can be used as covariance functions for GPs and allow fully Bayesianprediction with a deep neural network.In this work, we derive the exact equivalence between infinitely wide deepnetworks and GPs. We further develop a computationally efficient pipeline tocompute the covariance function for these GPs. We then use the resulting GPs toperform Bayesian inference for wide deep neural networks on MNIST and CIFAR-10.We observe that trained neural network accuracy approaches that of thecorresponding GP with increasing layer width, and that the GP uncertainty isstrongly correlated with trained network prediction error. We further find thattest performance increases as finite-width trained networks are made wider andmore similar to a GP, and thus that GP predictions typically outperform thoseof finite-width networks. Finally we connect the performance of these GPs tothe recent theory of signal propagation in random neural networks."	Machine Learning (stat.ML)	Machine Learning (cs.LG)
KSKSKSKS2	katsugeneration	178	445	誇張した表現の人物画であるカリカチュアを写真から生成するタスクで、Style Transfer的なテクスチャで表現されるスタイルの適用だけでなく、各パーツのジオメトリックな変換も学習により獲得し、任意の特徴を持つカリカチュアのスタイルを画像に適用し変換できる手法を提案 https://t.co/M2d4x9qCQ8	2019/7/7 22:04	https://arxiv.org/abs/1811.10100	WarpGAN: Automatic Caricature Generation	"We propose, WarpGAN, a fully automatic network that can generate caricaturesgiven an input face photo. Besides transferring rich texture styles, WarpGANlearns to automatically predict a set of control points that can warp the photointo a caricature, while preserving identity. We introduce anidentity-preserving adversarial loss that aids the discriminator to distinguishbetween different subjects. Moreover, WarpGAN allows customization of thegenerated caricatures by controlling the exaggeration extent and the visualstyles. Experimental results on a public domain dataset, WebCaricature, showthat WarpGAN is capable of generating a diverse set of caricatures whilepreserving the identities. Five caricature experts suggest that caricaturesgenerated by WarpGAN are visually similar to hand-drawn ones and only prominentfacial features are exaggerated."	Computer Vision and Pattern Recognition (cs.CV)	
kuto_bopro	きょうへい	67	86	2本目はKaggleでも現在使用しているDCGANの論文。GANの不安定性を解決するためにCNNやバッチ正則化などを用いた例。  潜在変数Zで生成する画像の特徴を変えれるのが面白い。  潜在空間の内部探索の理解がいまいちなのでそれはまた追々。 https://t.co/ZNKWPNCzX9	2019/7/7 22:36	https://arxiv.org/abs/1511.06434	Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks	"In recent years, supervised learning with convolutional networks (CNNs) hasseen huge adoption in computer vision applications. Comparatively, unsupervisedlearning with CNNs has received less attention. In this work we hope to helpbridge the gap between the success of CNNs for supervised learning andunsupervised learning. We introduce a class of CNNs called deep convolutionalgenerative adversarial networks (DCGANs), that have certain architecturalconstraints, and demonstrate that they are a strong candidate for unsupervisedlearning. Training on various image datasets, we show convincing evidence thatour deep convolutional adversarial pair learns a hierarchy of representationsfrom object parts to scenes in both the generator and discriminator.Additionally, we use the learned features for novel tasks - demonstrating theirapplicability as general image representations."	Machine Learning (cs.LG)	Computer Vision and Pattern Recognition (cs.CV)
raven_0717	烏（からす）	105	281	2012年、Physical Review Lettersに『ポニーテールの形状と髪の繊維束の統計物理』というタイトルの論文が発表された。 https://t.co/RhOZctSpeG ポニーテールは量子力学を凌駕し、サイエンステクノロジーを開拓し、もはや人類の英知として存在する。ようするにポニテばんじゃーい ∩(・ω・)∩	2019/7/7 23:59	https://arxiv.org/abs/1204.0371v1	[1204.0371v1] The shape of a ponytail and the statistical physics of hair fiber bundles	"A general continuum theory for the distribution of hairs in a bundle isdeveloped, treating individual fibers as elastic filaments with randomintrinsic curvatures. Applying this formalism to the iconic problem of theponytail, the combined effects of bending elasticity, gravity, andorientational disorder are recast as a differential equation for the envelopeof the bundle, in which the compressibility enters through an 'equation ofstate'. From this, we identify the balance of forces in various regions of theponytail, extract a remarkably simple equation of state from laboratorymeasurements of human ponytails, and relate the pressure to the measured randomcurvatures of individual hairs."	Statistical Mechanics (cond-mat.stat-mech)	Soft Condensed Matter (cond-mat.soft)
ssk_nozmi	ssk	30	67	ツイッタで知ったマクスウェルの悪魔の倒し方が載ってるらしい資料 https://t.co/yydXHp375Y	2019/7/8 0:01	https://arxiv.org/abs/1110.4732	Maxwell's Demon and Data Compression	"In an asymmetric Szilard engine model of Maxwell's demon, we show theequivalence between information theoretical and thermodynamic entropies whenthe demon erases information optimally. The work gain by the engine can beexactly canceled out by the work necessary to reset demon's memory afteroptimal data compression a la Shannon before the erasure."	Classical Physics (physics.class-ph)	Statistical Mechanics (cond-mat.stat-mech);History and Philosophy of Physics (physics.hist-ph)
maomaocyucyu	まおきゅ	592	560	@udoooom @import_godiva 初心者なので間違っていたら恐縮ですが、テスト云々という部分はネタ元のhttps://t.co/71ckU3PHCxが、学習後別に推論を走らせて出力を見るテストをしている関係で出てきた記載でGAN一般の話ではないかもです。ご指摘ありがとうございます！関連する実装は以下です https://t.co/uQVdutPswO	2019/7/8 1:00	https://arxiv.org/abs/1611.07004	Image-to-Image Translation with Conditional Adversarial Networks	"We investigate conditional adversarial networks as a general-purpose solutionto image-to-image translation problems. These networks not only learn themapping from input image to output image, but also learn a loss function totrain this mapping. This makes it possible to apply the same generic approachto problems that traditionally would require very different loss formulations.We demonstrate that this approach is effective at synthesizing photos fromlabel maps, reconstructing objects from edge maps, and colorizing images, amongother tasks. Indeed, since the release of the pix2pix software associated withthis paper, a large number of internet users (many of them artists) have postedtheir own experiments with our system, further demonstrating its wideapplicability and ease of adoption without the need for parameter tweaking. Asa community, we no longer hand-engineer our mapping functions, and this worksuggests we can achieve reasonable results without hand-engineering our lossfunctions either."	Computer Vision and Pattern Recognition (cs.CV)	
hackernewsj	Hacker News記事題日本語翻訳	609	4	構成性における7つのスケッチ：応用カテゴリー理論への招待 https://t.co/QISoDV5LiY	2019/7/8 5:00	https://arxiv.org/abs/1803.05316	Seven Sketches in Compositionality: An Invitation to Applied Category Theory	"This book is an invitation to discover advanced topics in category theorythrough concrete, real-world examples. It aims to give a tour: a gentle, quickintroduction to guide later exploration. The tour takes place over sevensketches, each pairing an evocative application, such as databases, electriccircuits, or dynamical systems, with the exploration of a categoricalstructure, such as adjoint functors, enriched categories, or toposes.No prior knowledge of category theory is assumed.A feedback form for typos, comments, questions, and suggestions is availablehere:this https URL"	Category Theory (math.CT)	
pasj_jp	日本加速器学会	115	11	KEKの大谷将士さんらの論文がプレプリントサーバで公開されました。 ミュオン加速用のバンチャー空洞について。 https://t.co/RTp8Dtq3O2 #加速器 https://t.co/lU8czgTcig	2019/7/8 6:10	https://arxiv.org/abs/1907.02235	Compact buncher cavity for muons accelerated by a radio-frequency quadrupole	"A buncher cavity has been developed for the muons accelerated by aradio-frequency quadrupole linac (RFQ). The buncher cavity is designed for$\beta=v/c=0.04$ at an operational frequency of 324 MHz. It employs adouble-gap structure operated in the TEM mode for the required effectivevoltage with compact dimensions, in order to account for the limited space ofthe experiment. The measured resonant frequency and unloaded quality factor are323.95 MHz and $3.06\times10^3$, respectively. The buncher cavity wassuccessfully operated for longitudinal bunch size measurement of the muonsaccelerated by the RFQ."	Accelerator Physics (physics.acc-ph)	High Energy Physics - Experiment (hep-ex)
hrsma2i	ヒ??シです。	159	354	衣服の自動折りたたみロボットの目。位置の推定とキーポイントの推定をCNNで同時に学習。 https://t.co/KZcV3kID5G https://t.co/iiQlReJngM	2019/7/8 8:20	https://arxiv.org/abs/1907.00408	GarmNet: Improving Global with Local Perception for Robotic Laundry Folding	"Developing autonomous assistants to help with domestic tasks is a vital topicin robotics research. Among these tasks, garment folding is one of them that isstill far from being achieved mainly due to the large number of possibleconfigurations that a crumpled piece of clothing may exhibit. Research has beendone on either estimating the pose of the garment as a whole or detecting thelandmarks for grasping separately. However, such works constrain the capabilityof the robots to perceive the states of the garment by limiting therepresentations for one single task. In this paper, we propose a novelend-to-end deep learning model named GarmNet that is able to simultaneouslylocalize the garment and detect landmarks for grasping. The localization of thegarment represents the global information for recognising the category of thegarment, whereas the detection of landmarks can facilitate subsequent graspingactions. We train and evaluate our proposed GarmNet model using the CloPeMaGarment dataset that contains 3,330 images of different garment types indifferent poses. The experiments show that the inclusion of landmark detection(GarmNet-B) can largely improve the garment localization, with an error rate of24.7% lower. Solutions as ours are important for robotics applications, asthese offer scalable to many classes, memory and processing efficientsolutions."	Robotics (cs.RO)	Computer Vision and Pattern Recognition (cs.CV)
jaguring1	小猫遊りょう（たかにゃし・りょう）	"2,601"	191	甘利先生が途中でしてるのは、Jacotたちのこの論文の話だと思う Neural Tangent Kernel: Convergence and Generalization in Neural Networks https://t.co/EDEB1BPkSB	2019/7/8 10:41	https://arxiv.org/abs/1806.07572	Neural Tangent Kernel: Convergence and Generalization in Neural Networks	"At initialization, artificial neural networks (ANNs) are equivalent toGaussian processes in the infinite-width limit, thus connecting them to kernelmethods. We prove that the evolution of an ANN during training can also bedescribed by a kernel: during gradient descent on the parameters of an ANN, thenetwork function $f_\theta$ (which maps input vectors to output vectors)follows the kernel gradient of the functional cost (which is convex, incontrast to the parameter cost) w.r.t. a new kernel: the Neural Tangent Kernel(NTK). This kernel is central to describe the generalization features of ANNs.While the NTK is random at initialization and varies during training, in theinfinite-width limit it converges to an explicit limiting kernel and it staysconstant during training. This makes it possible to study the training of ANNsin function space instead of parameter space. Convergence of the training canthen be related to the positive-definiteness of the limiting NTK. We prove thepositive-definiteness of the limiting NTK when the data is supported on thesphere and the non-linearity is non-polynomial.We then focus on the setting of least-squares regression and show that in theinfinite-width limit, the network function $f_\theta$ follows a lineardifferential equation during training. The convergence is fastest along thelargest kernel principal components of the input data with respect to the NTK,hence suggesting a theoretical motivation for early stopping.Finally we study the NTK numerically, observe its behavior for wide networks,and compare it to the infinite-width limit."	Machine Learning (cs.LG)	Neural and Evolutionary Computing (cs.NE);Probability (math.PR);Machine Learning (stat.ML)
ZFPhalanx	phalanx	"1,489"	414	多分これ DDFlow: Learning Optical Flow with Unlabeled Data Distillation https://t.co/ZHajtFHMmm	2019/7/8 12:22	https://arxiv.org/abs/1902.09145	DDFlow: Learning Optical Flow with Unlabeled Data Distillation	"We present DDFlow, a data distillation approach to learning optical flowestimation from unlabeled data. The approach distills reliable predictions froma teacher network, and uses these predictions as annotations to guide a studentnetwork to learn optical flow. Unlike existing work relying on hand-craftedenergy terms to handle occlusion, our approach is data-driven, and learnsoptical flow for occluded pixels. This enables us to train our model with amuch simpler loss function, and achieve a much higher accuracy. We conduct arigorous evaluation on the challenging Flying Chairs, MPI Sintel, KITTI 2012and 2015 benchmarks, and show that our approach significantly outperforms allexisting unsupervised learning methods, while running at real time."	Computer Vision and Pattern Recognition (cs.CV)	
miwamaya_3	Maya3	22	193	https://t.co/15wqcWHxsE ACGAN はクラス間の overap を考慮しないのでクラス数が増えると生成の多様性が損なわれる欠陥がある． ACGAN の構造に新たにもう一つの分類器を追加するアイデアを提案． 追加の分類器は Fake のペアのみで学習し，クラス間のJS-divを最小化することで多様性の劣化を防ぐ． https://t.co/CiV2xolYPj	2019/7/8 13:43	https://arxiv.org/abs/1907.02690v1	[1907.02690v1] Twin Auxiliary Classifiers GAN	"Conditional generative models enjoy remarkable progress over the past fewyears. One of the popular conditional models is Auxiliary Classifier GAN(AC-GAN), which generates highly discriminative images by extending the lossfunction of GAN with an auxiliary classifier. However, the diversity of thegenerated samples by AC-GAN tends to decrease as the number of classesincreases, hence limiting its power on large-scale data. In this paper, weidentify the source of the low diversity issue theoretically and propose apractical solution to solve the problem. We show that the auxiliary classifierin AC-GAN imposes perfect separability, which is disadvantageous when thesupports of the class distributions have significant overlap. To address theissue, we propose Twin Auxiliary Classifiers Generative Adversarial Net(TAC-GAN) that further benefits from a new player that interacts with otherplayers (the generator and the discriminator) in GAN. Theoretically, wedemonstrate that TAC-GAN can effectively minimize the divergence between thegenerated and real-data distributions. Extensive experimental results show thatour TAC-GAN can successfully replicate the true data distributions on simulateddata, and significantly improves the diversity of class-conditional imagegeneration on real datasets."	Machine Learning (cs.LG)	Machine Learning (stat.ML)
komiya_atsushi	KOMIYA Atsushi	"1,575"	125	転置インデックスの圧縮表現に使える新しいアルゴリズムだ。 https://t.co/NKck7I0b8y	2019/7/8 13:45	https://arxiv.org/abs/1907.01032	On Slicing Sorted Integer Sequences	"Representing sorted integer sequences in small space is a central problem forlarge-scale retrieval systems such as Web search engines. Efficient queryresolution, e.g., intersection or random access, is achieved by carefullypartitioning the sequences. In this work we describe and compare two differentpartitioning paradigms: partitioning by cardinality and partitioning byuniverse. Although the ideas behind such paradigms have been known in thecoding and algorithmic community since many years, inverted index compressionhas extensively adopted the former paradigm, whereas the latter has receivedonly little attention. As a result, an experimental comparison between thesetwo is missing for the setting of inverted index compression. We also proposeand implement a solution that recursively slices the universe of representationof a sequence to achieve compact storage and attain to fast query execution.Albeit larger than some state-of-the-art representations, this slicing approachsubstantially improves the performance of list intersections and unions whileoperating in compressed space, thus offering an excellent space/time trade-offfor the problem."	Information Retrieval (cs.IR)	Data Structures and Algorithms (cs.DS)
hiroosa	"OSAWA, Hirotaka /WoD"	"1,612"	919	機械学習における進化計算の影響。ここ2年の成果で、ぜんぶarXivってのが分野のスピードを感じさせる  https://t.co/8bV2gH06C0 https://t.co/Q4SAAUDbt0 https://t.co/j5DpnzHRF7	2019/7/8 14:16	"https://arxiv.org/abs/1703.03864, https://arxiv.org/abs/1712.06567, https://arxiv.org/abs/1803.07055"	"Evolution Strategies as a Scalable Alternative to Reinforcement Learning, Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning, Simple random search provides a competitive approach to reinforcement learning"	"We explore the use of Evolution Strategies (ES), a class of black boxoptimization algorithms, as an alternative to popular MDP-based RL techniquessuch as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari showthat ES is a viable solution strategy that scales extremely well with thenumber of CPUs available: By using a novel communication strategy based oncommon random numbers, our ES implementation only needs to communicate scalars,making it possible to scale to over a thousand parallel workers. This allows usto solve 3D humanoid walking in 10 minutes and obtain competitive results onmost Atari games after one hour of training. In addition, we highlight severaladvantages of ES as a black box optimization technique: it is invariant toaction frequency and delayed rewards, tolerant of extremely long horizons, anddoes not need temporal discounting or value function approximation., Deep artificial neural networks (DNNs) are typically trained viagradient-based learning algorithms, namely backpropagation. Evolutionstrategies (ES) can rival backprop-based algorithms such as Q-learning andpolicy gradients on challenging deep reinforcement learning (RL) problems.However, ES can be considered a gradient-based algorithm because it performsstochastic gradient descent via an operation similar to a finite-differenceapproximation of the gradient. That raises the question of whethernon-gradient-based evolutionary algorithms can work at DNN scales. Here wedemonstrate they can: we evolve the weights of a DNN with a simple,gradient-free, population-based genetic algorithm (GA) and it performs well onhard deep RL problems, including Atari and humanoid locomotion. The Deep GAsuccessfully evolves networks with over four million free parameters, thelargest neural networks ever evolved with a traditional evolutionary algorithm.These results (1) expand our sense of the scale at which GAs can operate, (2)suggest intriguingly that in some cases following the gradient is not the bestchoice for optimizing performance, and (3) make immediately available themultitude of neuroevolution techniques that improve performance. We demonstratethe latter by showing that combining DNNs with novelty search, which encouragesexploration on tasks with deceptive or sparse reward functions, can solve ahigh-dimensional problem on which reward-maximizing algorithms (e.g.\ DQN, A3C,ES, and the GA) fail. Additionally, the Deep GA is faster than ES, A3C, and DQN(it can train Atari in ${\raise.17ex\hbox{$\scriptstyle\sim$}}$4 hours on onedesktop or ${\raise.17ex\hbox{$\scriptstyle\sim$}}$1 hour distributed on 720cores), and enables a state-of-the-art, up to 10,000-fold compact encodingtechnique., A common belief in model-free reinforcement learning is that methods based onrandom search in the parameter space of policies exhibit significantly worsesample complexity than those that explore the space of actions. We dispel suchbeliefs by introducing a random search method for training static, linearpolicies for continuous control problems, matching state-of-the-art sampleefficiency on the benchmark MuJoCo locomotion tasks. Our method also finds anearly optimal controller for a challenging instance of the Linear QuadraticRegulator, a classical problem in control theory, when the dynamics are notknown. Computationally, our random search algorithm is at least 15 times moreefficient than the fastest competing model-free methods on these benchmarks. Wetake advantage of this computational efficiency to evaluate the performance ofour method over hundreds of random seeds and many different hyperparameterconfigurations for each benchmark task. Our simulations highlight a highvariability in performance in these benchmark tasks, suggesting that commonlyused estimations of sample efficiency do not adequately evaluate theperformance of RL algorithms."	"Machine Learning (stat.ML), Neural and Evolutionary Computing (cs.NE), Machine Learning (cs.LG)"	"Artificial Intelligence (cs.AI);Machine Learning (cs.LG);Neural and Evolutionary Computing (cs.NE), Machine Learning (cs.LG), Artificial Intelligence (cs.AI);Optimization and Control (math.OC);Machine Learning (stat.ML)"
Quantum_Zen	全卓樹	"1,629"	98	"そおいえば守先生の新論文 https://t.co/Syuezqreir、Physical Review Eにもう掲載されますねえ。批評１（表面的的）：おもしろいイイ論文ですよこれ。  ""Voter model on networks and the multivariate beta distribution"" S. Mori, M. Hisakado, and K. Nakayama https://t.co/Cdr8PPKhOv"	2019/7/8 16:51	https://arxiv.org/abs/1810.05643	A voter model on networks and multivariate beta distribution	"In elections, the vote shares or turnout rates show a strong spatialcorrelation. The logarithmic decay with distance suggests that a 2D noisydiffusive equation describes the system. Based on the study of U.S.presidential elections data, it was determined that the fluctuations of voteshares also exhibit a strong and long-range spatial correlation. Previously, itwas considered difficult to induce strong and long-range spatial correlation ofthe vote shares without breaking the empirically observed narrow distribution.We demonstrate that a voter model on networks shows such a behavior. In themodel, there are many voters in a node who are affected by the agents in thenode and by the agents in the linked nodes. A multivariate Wright-Fisherdiffusion equation for the joint probability density of the vote shares isderived. The stationary distribution is a multivariate generalization of thebeta distribution. In addition, we also estimate the equilibrium values and thecovariance matrix of the vote shares and obtain a correspondence with amultivariate normal distribution. This approach largely simplifies thecalibration of the parameters in the modeling of elections."	Physics and Society (physics.soc-ph)	Applications (stat.AP)
colomatico	ｺﾛﾏﾁｺ	152	312	[1811.03792v1] Rigorous analytical formula for freeform singlet lens design free of spherical aberration  あーかいぶ https://t.co/qu4JkJWcit	2019/7/8 17:39	https://arxiv.org/abs/1811.03792v1	[1811.03792v1] Rigorous analytical formula for freeform singlet lens design free of spherical aberration	"An analytical closed-form formula for the design of freeform lenses free ofspherical aberration is presented. Given the equation of the freeform inputsurface, the formula gives the equation of the second surface in order tocorrect the spherical aberration. The derivation is based on the formalapplication of the variational Fermat principle under the standard geometricaloptics approximation."	Optics (physics.optics)	
naoki_shigehisa	しげ@プログラミング勉強中	59	165	https://t.co/3nAsD64Kj1 読んでみる。 ((英語苦手...	2019/7/8 18:04	https://arxiv.org/abs/1703.06870v1	[1703.06870v1] Mask R-CNN	"We present a conceptually simple, flexible, and general framework for objectinstance segmentation. Our approach efficiently detects objects in an imagewhile simultaneously generating a high-quality segmentation mask for eachinstance. The method, called Mask R-CNN, extends Faster R-CNN by adding abranch for predicting an object mask in parallel with the existing branch forbounding box recognition. Mask R-CNN is simple to train and adds only a smalloverhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy togeneralize to other tasks, e.g., allowing us to estimate human poses in thesame framework. We show top results in all three tracks of the COCO suite ofchallenges, including instance segmentation, bounding-box object detection, andperson keypoint detection. Without tricks, Mask R-CNN outperforms all existing,single-model entries on every task, including the COCO 2016 challenge winners.We hope our simple and effective approach will serve as a solid baseline andhelp ease future research in instance-level recognition. Code will be madeavailable."	Computer Vision and Pattern Recognition (cs.CV)	
Kazk1018	Kazk1018	317	294	アルゴリズムによる採用候補者のスクリーニングにおけるバイアスに関する論文  https://t.co/tn3CwX6geP	2019/7/8 18:31	https://arxiv.org/abs/1906.09208v1	[1906.09208v1] Mitigating Bias in Algorithmic Employment Screening: Evaluating Claims and Practices	"There has been rapidly growing interest in the use of algorithms foremployment assessment, especially as a means to address or mitigate bias inhiring. Yet, to date, little is known about how these methods are being used inpractice. How are algorithmic assessments built, validated, and examined forbias? In this work, we document and assess the claims and practices ofcompanies offering algorithms for employment assessment, using a methodologythat can be applied to evaluate similar applications and issues of bias inother domains. In particular, we identify vendors of algorithmic pre-employmentassessments (i.e., algorithms to screen candidates), document what they havedisclosed about their development and validation procedures, and evaluate theirtechniques for detecting and mitigating bias. We find that companies'formulation of ""bias"" varies, as do their approaches to dealing with it. Wealso discuss the various choices vendors make regarding data collection andprediction targets, in light of the risks and trade-offs that these choicespose. We consider the implications of these choices and we raise a number oftechnical and legal considerations."	Computers and Society (cs.CY)	Artificial Intelligence (cs.AI);Machine Learning (cs.LG)
masashi162	masashi16	83	129	[論文メモ] GraphStar:?https://t.co/o4vci6bhVP https://t.co/o82hYoIqR2 GNNが層を重ね過ぎると、表現が一様になってしまう問題に対して、大域的な情報を持つstar(ノード)を導入。GNNは局所的な情報しか取り込まないが、starを通して、大域的な情報を取り込むことを提案。複数のタスクでSOTA。	2019/7/8 19:18	https://arxiv.org/abs/1906.12330	Graph Star Net for Generalized Multi-Task Learning	"In this work, we present graph star net (GraphStar), a novel and unifiedgraph neural net architecture which utilizes message-passing relay andattention mechanism for multiple prediction tasks - node classification, graphclassification and link prediction. GraphStar addresses many earlier challengesfacing graph neural nets and achieves non-local representation withoutincreasing the model depth or bearing heavy computational costs. We alsopropose a new method to tackle topic-specific sentiment analysis based on nodeclassification and text classification as graph classification. Our work showsthat 'star nodes' can learn effective graph-data representation and improve oncurrent methods for the three tasks. Specifically, for graph classification andlink prediction, GraphStar outperforms the current state-of-the-art models by2-5% on several key benchmarks."	Social and Information Networks (cs.SI)	Computation and Language (cs.CL);Machine Learning (cs.LG)
masashi162	masashi16	83	129	PFNが以前出してた論文(https://t.co/XDDZwTmqrM)との違いって何なんだろう。考え方はとても似ている気がする。 Deep Graph Infomaxもそうだったけど、グローバルな情報をGNNにどのようにして付与するかが重要な気がする。	2019/7/8 19:19	https://arxiv.org/abs/1902.01020	Graph Warp Module: an Auxiliary Module for Boosting the Power of Graph Neural Networks in Molecular Graph Analysis	"Graph Neural Network (GNN) is a popular architecture for the analysis ofchemical molecules, and it has numerous applications in material and medicinalscience. Current lines of GNNs developed for molecular analysis, however, donot fit well on the training set, and their performance does not scale wellwith the complexity of the network. In this paper, we propose an auxiliarymodule to be attached to a GNN that can boost the representation power of themodel without hindering with the original GNN architecture. Our auxiliarymodule can be attached to a wide variety of GNNs, including those that are usedcommonly in biochemical applications. With our auxiliary architecture, theperformances of many GNNs used in practice improve more consistently, achievingthe state-of-the-art performance on popular molecular graph datasets."	Machine Learning (cs.LG)	Machine Learning (stat.ML)
Ay18OS18	まな板の上の鱸	55	51	action！ってこと？  [1907.02550] 4321... axion! https://t.co/ZAk4q1Z5QH	2019/7/8 19:51	https://arxiv.org/abs/1907.02550	4321... axion!	"We analyze the strong CP problem and the implications for axion physics inthe context of $U_1$ vector leptoquark models, recently put forward as anelegant solution to the hints of lepton flavor universality violation inB-meson decays. It is shown that in minimal gauge models containing the $U_1$as a gauge boson, the Peccei-Quinn solution of the strong CP problem requiresthe introduction of two axions. Characteristic predictions for the associatedaxions can be deduced from the model parameter space hinted by B-physics,allowing the new axion sector to account for the dark matter of the Universe.We also provide a specific ultraviolet completion of the axion sector thatconnects the Peccei-Quinn mechanism to the generation of neutrino masses."	High Energy Physics - Phenomenology (hep-ph)	
re_hako_moon	はこつき＠VR	50	57	https://t.co/BN4UAOUONM Quantization-interval-learningの提案。NNの量子化を学習可能にすることで、精度を維持したまま省ビットなネットワークを実現した。入力の変化に応じた量子化間隔＆変化が激しい箇所に量子化の中心を移動するように学習する。	2019/7/8 20:39	https://arxiv.org/abs/1808.05779	Learning to Quantize Deep Networks by Optimizing Quantization Intervals with Task Loss	"Reducing bit-widths of activations and weights of deep networks makes itefficient to compute and store them in memory, which is crucial in theirdeployments to resource-limited devices, such as mobile phones. However,decreasing bit-widths with quantization generally yields drastically degradedaccuracy. To tackle this problem, we propose to learn to quantize activationsand weights via a trainable quantizer that transforms and discretizes them.Specifically, we parameterize the quantization intervals and obtain theiroptimal values by directly minimizing the task loss of the network. Thisquantization-interval-learning (QIL) allows the quantized networks to maintainthe accuracy of the full-precision (32-bit) networks with bit-width as low as4-bit and minimize the accuracy degeneration with further bit-width reduction(i.e., 3 and 2-bit). Moreover, our quantizer can be trained on a heterogeneousdataset, and thus can be used to quantize pretrained networks without access totheir training data. We demonstrate the effectiveness of our trainablequantizer on ImageNet dataset with various network architectures such asResNet-18, -34 and AlexNet, on which it outperforms existing methods to achievethe state-of-the-art accuracy."	Computer Vision and Pattern Recognition (cs.CV)	
kuto_bopro	きょうへい	67	86	1日1論文の3本目 Improved Technique for Training GANs  GANを効果的に学習するためのテクニックがいくつか紹介されており非常に参考になる論文  理解度は半分くらい。  https://t.co/yFNLgLdXRa	2019/7/8 21:17	https://arxiv.org/abs/1606.03498	Improved Techniques for Training GANs	"We present a variety of new architectural features and training proceduresthat we apply to the generative adversarial networks (GANs) framework. We focuson two applications of GANs: semi-supervised learning, and the generation ofimages that humans find visually realistic. Unlike most work on generativemodels, our primary goal is not to train a model that assigns high likelihoodto test data, nor do we require the model to be able to learn well withoutusing any labels. Using our new techniques, we achieve state-of-the-art resultsin semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generatedimages are of high quality as confirmed by a visual Turing test: our modelgenerates MNIST samples that humans cannot distinguish from real data, andCIFAR-10 samples that yield a human error rate of 21.3%. We also presentImageNet samples with unprecedented resolution and show that our methods enablethe model to learn recognizable features of ImageNet classes."	Machine Learning (cs.LG)	Computer Vision and Pattern Recognition (cs.CV);Neural and Evolutionary Computing (cs.NE)
myaunraitau	まうん	242	258	代名詞コンペの1stソリューションのACL論文が公開されてたので読んでる https://t.co/cK0GPqLNoo	2019/7/8 23:31	https://arxiv.org/abs/1906.00839	Gendered Ambiguous Pronouns Shared Task: Boosting Model Confidence by Evidence Pooling	"This paper presents a strong set of results for resolving gendered ambiguouspronouns on the Gendered Ambiguous Pronouns shared task. The model presentedhere draws upon the strengths of state-of-the-art language and coreferenceresolution models, and introduces a novel evidence-based deep learningarchitecture. Injecting evidence from the coreference models compliments thebase architecture, and analysis shows that the model is not hindered by theirweaknesses, specifically gender bias. The modularity and simplicity of thearchitecture make it very easy to extend for further improvement and applicableto other NLP problems. Evaluation on GAP test data results in astate-of-the-art performance at 92.5% F1 (gender bias of 0.97), edging closerto the human performance of 96.6%. The end-to-end solution presented hereplaced 1st in the Kaggle competition, winning by a significant lead. The codeis available at this https URL."	Computation and Language (cs.CL)	
cygnusgm	アルミニ	367	901	@kafukanoochan @UFOprofessor @gigazine arXivのプレプリント Submitted on 9 Nov 2018 https://t.co/DZ9p1JZB2W  Applied Optics誌も2018年11月号なので、内容はほぼ変わってないのかな？ Gigazineに載っている、あの凄まじい数式は見当たりません。	2019/7/8 23:41	https://arxiv.org/abs/1811.03792	Rigorous analytical formula for freeform singlet lens design free of spherical aberration	"An analytical closed-form formula for the design of freeform lenses free ofspherical aberration is presented. Given the equation of the freeform inputsurface, the formula gives the equation of the second surface in order tocorrect the spherical aberration. The derivation is based on the formalapplication of the variational Fermat principle under the standard geometricaloptics approximation."	Optics (physics.optics)	
IxtlanJourney	ixtlan journey	48	422	バニラLSTMのgateの値は、実は0から1の間にブロードに分布している。そこで、gateにGumbel-Softmaxを用いて0か1に近づく様にする。精度が落ちず、圧縮が容易になる。  Towards Binary-Valued Gates for Robust LSTM Training https://t.co/bbJ0FYscB6	2019/7/8 23:56	https://arxiv.org/abs/1806.02988	Towards Binary-Valued Gates for Robust LSTM Training	"Long Short-Term Memory (LSTM) is one of the most widely used recurrentstructures in sequence modeling. It aims to use gates to control informationflow (e.g., whether to skip some information or not) in the recurrentcomputations, although its practical implementation based on soft gates onlypartially achieves this goal. In this paper, we propose a new way for LSTMtraining, which pushes the output values of the gates towards 0 or 1. By doingso, we can better control the information flow: the gates are mostly open orclosed, instead of in a middle state, which makes the results moreinterpretable. Empirical studies show that (1) Although it seems that werestrict the model capacity, there is no performance drop: we achieve better orcomparable performances due to its better generalization ability; (2) Theoutputs of gates are not sensitive to their inputs: we can easily compress theLSTM unit in multiple ways, e.g., low-rank approximation and low-precisionapproximation. The compressed models are even better than the baseline modelswithout compression."	Machine Learning (cs.LG)	Computation and Language (cs.CL);Machine Learning (stat.ML)
takekujira_	野口篤史	368	92	おおー。 https://t.co/yq26oz2Z60	2019/7/9 0:11	https://arxiv.org/abs/1907.02554	Fault-tolerant thresholds for the surface code in excess of 5% under biased noise	"Noise in quantum computing is countered with quantum error correction.Achieving optimal performance will require tailoring codes and decodingalgorithms to account for features of realistic noise, such as the commonsituation where the noise is biased towards dephasing. Here we introduce anefficient high-threshold decoder for a noise-tailored surface code based onminimum-weight perfect matching. The decoder exploits the symmetries of itssyndrome under the action of biased noise and generalises to the fault-tolerantregime where measurements are unreliable. Using this decoder, we obtainfault-tolerant thresholds in excess of $6\%$ for a phenomenological noise modelin the limit where dephasing dominates. These gains persist even for modestnoise biases: we find a threshold of $\sim 5\%$ in an experimentally relevantregime where dephasing errors occur at a rate one hundred times greater thanbit-flip errors."	Quantum Physics (quant-ph)	Strongly Correlated Electrons (cond-mat.str-el)
KSKSKSKS2	katsugeneration	178	445	文字やウォーターマークなどが挿入されている画像から、どのような物体が挿入されているかの情報無しで元画像を復元するBlind Motif Removalのタスクで、半透明なモチーフや複数のモチーフの除去を行える手法を提案。 https://t.co/iDrfYntLUz https://t.co/G4ovg1vmL5	2019/7/9 0:16	https://arxiv.org/abs/1904.02756	Blind Visual Motif Removal from a Single Image	"Many images shared over the web include overlaid objects, or visual motifs,such as text, symbols or drawings, which add a description or decoration to theimage. For example, decorative text that specifies where the image was taken,repeatedly appears across a variety of different images. Often, the reoccurringvisual motif, is semantically similar, yet, differs in location, style andcontent (e.g. text placement, font and letters). This work proposes a deeplearning based technique for blind removal of such objects. In the blindsetting, the location and exact geometry of the motif are unknown. Our approachsimultaneously estimates which pixels contain the visual motif, and synthesizesthe underlying latent image. It is applied to a single input image, without anyuser assistance in specifying the location of the motif, achievingstate-of-the-art results for blind removal of both opaque and semi-transparentvisual motifs."	Computer Vision and Pattern Recognition (cs.CV)	Graphics (cs.GR);Machine Learning (cs.LG)
phys27_	うわばき	153	127	[gr-qc/9405057] General relativity as an effective field theory: The leading quantum corrections  これですかね https://t.co/bXNZDPKgEl	2019/7/9 0:36	https://arxiv.org/abs/gr-qc/9405057	[gr-qc/9405057] General relativity as an effective field theory: The leading quantum corrections	"I describe the treatment of gravity as a quantum effective field theory. Thisallows a natural separation of the (known) low energy quantum effects from the(unknown) high energy contributions. Within this framework, gravity is a wellbehaved quantum field theory at ordinary energies. In studying the class ofquantum corrections at low energy, the dominant effects at large distance canbe isolated, as these are due to the propagation of the massless particles(including gravitons) of the theory and are manifested in thenonlocal/nonanalytic contributions to vertex functions and propagators. Theseleading quantum corrections are parameter-free and represent necessaryconsequences of quantum gravity. The methodology is illustrated by acalculation of the leading quantum corrections to the gravitational interactionof two heavy masses."	General Relativity and Quantum Cosmology (gr-qc)	High Energy Physics - Phenomenology (hep-ph);High Energy Physics - Theory (hep-th)
i4mwh4ti4m	たつお	312	489	一応当該論文投げとく https://t.co/oPnhDjwgy4	2019/7/9 2:58	https://arxiv.org/abs/1907.01376	Multi-scale GANs for Memory-efficient Generation of High Resolution Medical Images	"Currently generative adversarial networks (GANs) are rarely applied tomedical images of large sizes, especially 3D volumes, due to their largecomputational demand. We propose a novel multi-scale patch-based GAN approachto generate large high resolution 2D and 3D images. Our key idea is to firstlearn a low-resolution version of the image and then generate patches ofsuccessively growing resolutions conditioned on previous scales. In a domaintranslation use-case scenario, 3D thorax CTs of size 512x512x512 and thoraxX-rays of size 2048x2048 are generated and we show that, due to the constantGPU memory demand of our method, arbitrarily large images of high resolutioncan be generated. Moreover, compared to common patch-based approaches, ourmulti-resolution scheme enables better image quality and prevents patchartifacts."	Image and Video Processing (eess.IV)	Computer Vision and Pattern Recognition (cs.CV)
GenerateTaiyaki	taiyaki	14	0	"BigBiGAN https://t.co/AaqGCYFuwN BigGANと教師なし表現学習手法であるBiGANの組合せ.識別器には画像or潜在変数単独でのスコアを追加することで学習が安定化.教師なし表現学習やImageNetの条件なし生成でsota.強い生成モデルは表現学習に有用である上,良い特徴抽出モデルは生成器の性能を向上させる. https://t.co/6VDXqYM2Lf"	2019/7/9 3:19	https://arxiv.org/abs/1907.02544	Large Scale Adversarial Representation Learning	"Adversarially trained generative models (GANs) have recently achievedcompelling image synthesis results. But despite early successes in using GANsfor unsupervised representation learning, they have since been superseded byapproaches based on self-supervision. In this work we show that progress inimage generation quality translates to substantially improved representationlearning performance. Our approach, BigBiGAN, builds upon the state-of-the-artBigGAN model, extending it to representation learning by adding an encoder andmodifying the discriminator. We extensively evaluate the representationlearning and generation capabilities of these BigBiGAN models, demonstratingthat these generation-based models achieve the state of the art in unsupervisedrepresentation learning on ImageNet, as well as in unconditional imagegeneration."	Computer Vision and Pattern Recognition (cs.CV)	Machine Learning (cs.LG);Machine Learning (stat.ML)
icoxfog417	piqcy	"8,906"	127	画像の一部をDropするCutoutと、画像を合成するMixupを複合させて、Dropさせた箇所に別サンプルの画像をはめ込むCutMixという手法を提案。Cutoutは重要な特徴を落としてしまう可能性がある、Mixupは合成画像が不自然になるという双方の課題を克服し、双方を上回る精度を達成  https://t.co/BNqZPG3tS4	2019/7/9 8:26	https://arxiv.org/abs/1905.04899	CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features	"Regional dropout strategies have been proposed to enhance the performance ofconvolutional neural network classifiers. They have proved to be effective forguiding the model to attend on less discriminative parts of objects (\eg leg asopposed to head of a person), thereby letting the network generalize better andhave better object localization capabilities. On the other hand, currentmethods for regional dropout removes informative pixels on training images byoverlaying a patch of either black pixels or random noise. {Such removal is notdesirable because it leads to information loss and inefficiency duringtraining.} We therefore propose the CutMix augmentation strategy: patches arecut and pasted among training images where the ground truth labels are alsomixed proportionally to the area of the patches. By making efficient use oftraining pixels and \mbox{retaining} the regularization effect of regionaldropout, CutMix consistently outperforms the state-of-the-art augmentationstrategies on CIFAR and ImageNet classification tasks, as well as on theImageNet weakly-supervised localization task. Moreover, unlike previousaugmentation methods, our CutMix-trained ImageNet classifier, when used as apretrained model, results in consistent performance gains in Pascal detectionand MS-COCO image captioning benchmarks. We also show that CutMix improves themodel robustness against input corruptions and its out-of-distributiondetection performances."	Computer Vision and Pattern Recognition (cs.CV)	
shunk031	しゅんけー	"1,706"	668	特許データ分析やってたからこういう論文は夢があって良いなぁと思う / Patent Claim Generation by Fine-Tuning OpenAI GPT-2. (arXiv:1907.02052v1 [https://t.co/w0CRTvevrb])  https://t.co/qrqdWY3YGz	2019/7/9 8:47	https://arxiv.org/abs/1907.02052	Patent Claim Generation by Fine-Tuning OpenAI GPT-2	"In this work, we focus on fine-tuning an OpenAI GPT-2 pre-trained model forgenerating patent claims. GPT-2 has demonstrated impressive efficacy ofpre-trained language models on various tasks, particularly coherent textgeneration. Patent claim language itself has rarely been explored in the pastand poses a unique challenge. We are motivated to generate coherent patentclaims automatically so that augmented inventing might be viable someday. Inour implementation, we identified a unique language structure in patent claimsand leveraged its implicit human annotations. We investigated the fine-tuningprocess by probing the first 100 steps and observing the generated text at eachstep. Based on both conditional and unconditional random sampling, we analyzethe overall quality of generated patent claims. Our contributions include: (1)being the first to generate patent claims by machines and being the first toapply GPT-2 to patent claim generation, (2) providing various experimentresults for qualitative analysis and future research, (3) proposing a newsampling approach for text generation, and (4) building an e-mail bot forfuture researchers to explore the fine-tuned GPT-2 model further."	Computation and Language (cs.CL)	Machine Learning (cs.LG);Machine Learning (stat.ML)
yoshikoba113	小林良彦（原子核物理・科学コミュニケーション）	104	25	今日（7月9日）はジョン・ホイーラー博士（1911～2008）が生まれた日。一般相対性理論や量子重力理論の研究で多くの功績を残した物理学者。ニールス・ボーア博士と核分裂の研究も行った。画像は https://t.co/ANpI6MbIL1 より。こちら（https://t.co/o9zDwsNVek）はキップ・ソーン博士による回想録。 https://t.co/EdCVqax0Ed	2019/7/9 9:36	https://arxiv.org/abs/1901.06623	John Archibald Wheeler: A Biographical Memoir	"John Archibald Wheeler was a theoretical physicist who worked on bothdown-to-earth projects and highly speculative ideas, and always emphasized theimportance of experiment and observation, even when speculating wildly. Hisresearch and insights had large impacts on nuclear and particle physics, thedesign of nuclear weapons, general relativity and relativistic astrophysics,and quantum gravity and quantum information. But his greatest impacts werethrough the students, postdocs, and mature physicists whom he educated andinspired.He was guided by what he called the principle of radical conservatism,inspired by Niels Bohr: base your research on well established physical laws(be conservative), but push them into the most extreme conceivable domains (beradical). He often pushed far beyond the boundaries of well understood physics,speculating in prescient ways that inspired future generations of physicists.After completing his PhD with Karl Herzfeld at Johns Hopkins University(1933), Wheeler embarked on a postdoctoral year with Gregory Breit at NYU andanother with Niels Bohr in Copenhagen. He then moved to a three-year assistantprofessorship at the University of North Carolina (1935-37), followed by a 40year professorial career at Princeton University (1937-1976) and then ten yearsas a professor at the University of Texas, Austin (1976-1987). He returned toPrinceton in retirement but remained actively and intensely engaged withphysics right up to his death at age 96."	History and Philosophy of Physics (physics.hist-ph)	High Energy Astrophysical Phenomena (astro-ph.HE);General Relativity and Quantum Cosmology (gr-qc);High Energy Physics - Theory (hep-th);Nuclear Theory (nucl-th)
L_H_Sullivan	ふー??じん??	368	320	Pseudo-Spin Versus Magnetic Dipole Moment Ordering in the Isosceles Triangular Lattice Material K3Er(VO4)2 https://t.co/NNKjF7eMRc 薄い結晶	2019/7/9 9:51	https://arxiv.org/abs/1907.03016	Pseudo-Spin Versus Magnetic Dipole Moment Ordering in the Isosceles Triangular Lattice Material K$_3$Er(VO$_4$)$_2$	"Spin-1/2 antiferromagnetic triangular lattice models are paradigms ofgeometrical frustration, revealing very different ground states and quantumeffects depending on the nature of anisotropies in the model. Due to strongspin orbit coupling and crystal field effects, rare-earth ions can formpseudo-spin-1/2 magnetic moments with anisotropic single-ion and exchangeproperties. Thus, rare-earth based triangular lattices enable the explorationof this interplay between frustration and anisotropy. Here we study one suchcase, the rare-earth double vanadate glaserite material K$_3$Er(VO$_4$)$_2$,which is a quasi-2D isosceles triangular antiferromagnet. Our specific heat andneutron powder diffraction data from K$_3$Er(VO$_4$)$_2$ reveal a transition tolong range magnetic order at 155 $\pm$ 5 mK which accounts for all R$\ln$2entropy. The quasi-2D magnetic order leads to anisotropic Warren-like Braggpeak profiles, and is best described by alternating layers of b-axis alignedantiferromagnetism and zero moment layers. Our magnetic susceptibility datareveal that Er$^{3+}$ takes on a strong XY single-ion anisotropy inK$_3$Er(VO$_4$)$_2$, leading to vanishing moments when pseudo-spins areoriented along c. Thus, the magnetic structure, when considered from thepseudo-spin point of view comprises alternating layers of b-axis and c-axisaligned antiferromagnetism."	Strongly Correlated Electrons (cond-mat.str-el)	
NIIIDR	NII IDR	266	57	「楽天データセット」に新規データを追加しました。https://t.co/AYbHL7BAWl 今回はRakuten Franceに掲載の書籍情報と，その一部に正規化した著者名表記を付加したデータです。「Who wrote this book? A challenge for e-commerce」の論文で使用されているものです。 https://t.co/88lUWahQXB	2019/7/9 10:49	https://arxiv.org/abs/1905.01973	Who wrote this book? A challenge for e-commerce	"Modern e-commerce catalogs contain millions of references, associated withtextual and visual information that is of paramount importance for the productsto be found via search or browsing. Of particular significance is the bookcategory, where the author name(s) field poses a significant challenge. Indeed,books written by a given author (such as F. Scott Fitzgerald) might be listedwith different authors' names in a catalog due to abbreviations and spellingvariants and mistakes, among others. To solve this problem at scale, we designa composite system involving open data sources for books as well as machinelearning components leveraging deep learning-based techniques for naturallanguage processing. In particular, we use Siamese neural networks for anapproximate match with known author names, and direct correction of theprovided author's name using sequence-to-sequence learning with neuralnetworks. We evaluate this approach on product data from the e-commerce websiteRakuten France, and find that the top proposal of the system is the normalizedauthor name with 72% accuracy."	Computation and Language (cs.CL)	Information Retrieval (cs.IR);Machine Learning (cs.LG);Machine Learning (stat.ML)
sei_shinagawa	Seitaro Shinagawa	"1,644"	"1,809"	Unsupervised Image Captioning (CVPR2019) https://t.co/owGOtKN67U image--textのcycle系crazy論文じゃん。読むか	2019/7/9 11:00	https://arxiv.org/abs/1811.10787	Unsupervised Image Captioning	"Deep neural networks have achieved great successes on the image captioningtask. However, most of the existing models depend heavily on pairedimage-sentence datasets, which are very expensive to acquire. In this paper, wemake the first attempt to train an image captioning model in an unsupervisedmanner. Instead of relying on manually labeled image-sentence pairs, ourproposed model merely requires an image set, a sentence corpus, and an existingvisual concept detector. The sentence corpus is used to teach the captioningmodel how to generate plausible sentences. Meanwhile, the knowledge in thevisual concept detector is distilled into the captioning model to guide themodel to recognize the visual concepts in an image. In order to furtherencourage the generated captions to be semantically consistent with the image,the image and caption are projected into a common latent space so that they canreconstruct each other. Given that the existing sentence corpora are mainlydesigned for linguistic research and are thus with little reference to imagecontents, we crawl a large-scale image description corpus of two millionnatural sentences to facilitate the unsupervised image captioning scenario.Experimental results show that our proposed model is able to produce quitepromising results without any caption annotations."	Computer Vision and Pattern Recognition (cs.CV)	
sei_shinagawa	Seitaro Shinagawa	"1,644"	"1,809"	"What's to know? Uncertainty as a Guide to Asking Goal-oriented Questions (CVPR2019) Ehsan Abbasnejad, Qi Wu, Javen Shi, Anton van den Hengel https://t.co/J9BrrZvi5a これ良さそう"	2019/7/9 11:18	https://arxiv.org/abs/1812.06401	What's to know? Uncertainty as a Guide to Asking Goal-oriented Questions	"One of the core challenges in Visual Dialogue problems is asking the questionthat will provide the most useful information towards achieving the requiredobjective. Encouraging an agent to ask the right questions is difficult becausewe don't know a-priori what information the agent will need to achieve itstask, and we don't have an explicit model of what it knows already. We proposea solution to this problem based on a Bayesian model of the uncertainty in theimplicit model maintained by the visual dialogue agent, and in the functionused to select an appropriate output. By selecting the question that minimisesthe predicted regret with respect to this implicit model the agent activelyreduces ambiguity. The Bayesian model of uncertainty also enables a principledmethod for identifying when enough information has been acquired, and an actionshould be selected. We evaluate our approach on two goal-oriented dialoguedatasets, one for visual-based collaboration task and the other for anegotiation-based task. Our uncertainty-aware information-seeking modeloutperforms its counterparts in these two challenging problems."	Artificial Intelligence (cs.AI)	Computation and Language (cs.CL);Machine Learning (cs.LG)
ElectronNest	NaN	125	34	"“Statistics &gt; Machine Learning To prune, or not to prune: exploring the efficacy of pruning for model compression” https://t.co/VMPMMKQm7g 式(1)が分からん。第一項がs_{t}でないとつじつまが合わない気がするけどどうなんじゃろ？"	2019/7/9 11:42	https://arxiv.org/abs/1710.01878	"To prune, or not to prune: exploring the efficacy of pruning for model compression"	"Model pruning seeks to induce sparsity in a deep neural network's variousconnection matrices, thereby reducing the number of nonzero-valued parametersin the model. Recent reports (Han et al., 2015; Narang et al., 2017) prune deepnetworks at the cost of only a marginal loss in accuracy and achieve a sizablereduction in model size. This hints at the possibility that the baseline modelsin these experiments are perhaps severely over-parameterized at the outset anda viable alternative for model compression might be to simply reduce the numberof hidden units while maintaining the model's dense connection structure,exposing a similar trade-off in model size and accuracy. We investigate thesetwo distinct paths for model compression within the context of energy-efficientinference in resource-constrained environments and propose a new gradualpruning technique that is simple and straightforward to apply across a varietyof models/datasets with minimal tuning and can be seamlessly incorporatedwithin the training process. We compare the accuracy of large, but prunedmodels (large-sparse) and their smaller, but dense (small-dense) counterpartswith identical memory footprint. Across a broad range of neural networkarchitectures (deep CNNs, stacked LSTM, and seq2seq LSTM models), we findlarge-sparse models to consistently outperform small-dense models and achieveup to 10x reduction in number of non-zero parameters with minimal loss inaccuracy."	Machine Learning (stat.ML)	Machine Learning (cs.LG)
